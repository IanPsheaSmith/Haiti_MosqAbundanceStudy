---
title: "Haiti_MosqAbundance"
author: "Ian Pshea-Smith"
date: "`r Sys.Date()`"
output: html_document
---


```{r Loading required libraries}

  # spatial hurdle libraries
  library(dplyr)
  library(ggplot2)
  library(inlabru)
  library(terra)
  library(sf)
  library(RColorBrewer)
  library(magrittr)
  library(patchwork)
  library(parallel)
  library(sp)
  library(gstat)
  library(MuMIn)
  library(parallel)
  library(viridis)
  library(RColorBrewer)
  library(readr)
  library(ggcorrplot)
  library(corrplot)
  library(gridExtra)
  library(ggtext)
  library(kableExtra)
  library(leaflet)

```



```{r Loading in Data}

  ##### A note about the data import and below code #####
  # Data processing and appending covariates is available as a seperate set of
    # code (HaitiCountModels.Rmd, available upon request to 
    # ian.smith.gh@gmail.com). Below is import code for the processed dataset,
    # including both the cleaned abundance data and the covariate data
    # already extracted from Bioclim & WorldPop.

  # Define GitHub base URL for raw files
    base_url <- "https://raw.githubusercontent.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/main/"

  # Define dataset names
    datasets <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq", 
                  "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")
  
  # Initialize an empty list to store data
    dataset_list <- list()
  
  # Download and read each dataset directly into R
    for (dataset in datasets) {
      file_url <- paste0(base_url, dataset, ".csv")
      
      # Read CSV directly into R env
      dataset_list[[dataset]] <- read.csv(file_url, stringsAsFactors = FALSE)
      
      # Assign dataset to global environment
      assign(dataset, dataset_list[[dataset]], envir = .GlobalEnv)
      
      message(paste("Loaded:", dataset))
    }

  # Test for Aeae
    head(HCM_Full_Aeae)

  # Download Shapefiles for the map(s)
    zip_url <- "https://github.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/raw/main/Haiti_Shapefiles.zip"
    zip_dest <- tempfile(fileext = ".zip")
    unzip_dir <- tempfile()
    download.file(zip_url, destfile = zip_dest, mode = "wb")
    unzip(zip_dest, exdir = unzip_dir)

  # read in the shapefiles
    all_files <- list.files(unzip_dir, recursive = TRUE, full.names = TRUE)
    adm2_path <- all_files[grepl("adm2.*\\.shp$", all_files)]
    adm3_path <- all_files[grepl("adm3.*\\.shp$", all_files)]
    Haiti_adm2 <- st_read(adm2_path)
    Haiti_adm3 <- st_read(adm3_path)
    
  # Base URL for raw GitHub files
    base_url <- "https://raw.githubusercontent.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/main/Rasters/"
  
  # Set Layer Names
    layer_names <- c("Precip", "TMean", "WindMean", "Elevation", "LC_trees", 
                 "LC_shrubs", "LC_grassland", "LC_cropland", "LC_built")

    
  # Load AverageStack raster data
    AverageStack <- stack(paste0(base_url, "AverageStack.tif"))
    names(AverageStack) <- layer_names
    
  # Load MonthlyStacks raster data
    month_names <- c("January", "February", "March", "April", "May", "June",
                     "July", "August", "September", "October", "November", "December")
    
  MonthlyStacks <- setNames(
    lapply(month_names, function(month) {
      stack_obj <- stack(paste0(base_url, month, "_Stack.tif"))
      names(stack_obj) <- layer_names
      stack_obj
    }),
    month_names
  )

```



```{r Figure 1 - Study Area Map}

# Convert HCM_Full_Aeae to sf object
  HCM_Full_Aeae_sf <- st_as_sf(HCM_Full_Aeae,
                                coords = c("Longitude", "Latitude"),
                                crs = 4326)
  
  # Identify the ADM2 polygons (communes) that contain sample points
  adm2_flagged <- Haiti_adm2[
    lengths(st_intersects(Haiti_adm2, HCM_Full_Aeae_sf)) > 0,
  ]
  
  # Plot all communes in light grey
  Haiti_StudySiteCommunes <- ggplot() +
    # all communes (ADM2) in light grey
    geom_sf(
      data  = Haiti_adm2,
      fill  = "white",
      color = "grey",
      size  = 0.05
    ) +
    # communes intersecting sample points
    geom_sf(
      data  = adm2_flagged,
      fill  = "grey",
      color = "black",
      size  = 0.05
    ) +
    theme_minimal() +
    labs(
      title = "",
      x     = "",
      y     = ""
    )
  
  # Count observations per location
  HCM_counts <- HCM_Full_Aeae %>%
    group_by(Latitude, Longitude) %>%
    summarise(n_obs = n(), .groups = "drop") %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326)
  
  # Plot the study sites alone with graduated points
  Haiti_StudySite <- ggplot() +
    geom_sf(
      data  = adm2_flagged,
      fill  = "white",
      color = "black",
      size  = 0.05
    ) +
    geom_sf(
      data = HCM_counts,
      aes(size = n_obs),
      alpha = 0.6,
      color = "#7851A9"
    ) +
    scale_size_continuous(name = "# Observations") +
    theme_minimal()
  
  # Print the figures
  print(Haiti_StudySiteCommunes)
  print(Haiti_StudySite)

```



```{r Interactive Map of Data}

  # Aggregate data by location with species counts
    HCM_map_data <- HCM_Full_Aeae %>%
      group_by(Latitude, Longitude) %>%
      summarise(
        n_obs = n(),
        Quinx = sum(Quinx, na.rm = TRUE),
        Aeae = sum(Aeae, na.rm = TRUE),
        Aealb = sum(Aealb, na.rm = TRUE),
        Aem = sum(Aem, na.rm = TRUE),
        Cxn = sum(Cxn, na.rm = TRUE),
        Psc = sum(Psc, na.rm = TRUE),
        .groups = "drop"
      )
  
  # Create leaflet map
    leaflet(HCM_map_data) %>%
      addTiles(group = "OpenStreetMap") %>%
      addProviderTiles("Esri.WorldImagery", group = "Satellite") %>%
      addProviderTiles("Esri.WorldShadedRelief", group = "Elevation") %>%
      addCircleMarkers(
        lng = ~Longitude,
        lat = ~Latitude,
        radius = ~sqrt(n_obs) * 2,
        popup = ~paste0("Collection Events: ", n_obs, "<br>",
                        "<i>Cx. quinquefasciatus</i>: ", Quinx, "<br>",
                        "<i>Ae. aegypti</i>: ", Aeae, "<br>",
                        "<i>Ae. albopictus</i>: ", Aealb, "<br>",
                        "<i>Ae. mediovittatus</i>: ", Aem, "<br>",
                        "<i>Cx. nigripalpus</i>: ", Cxn, "<br>",
                        "<i>Ps. columbiae</i>: ", Psc)
      ) %>%
      addLayersControl(
        baseGroups = c("OpenStreetMap", "Satellite", "Elevation"),
        options = layersControlOptions(collapsed = FALSE)
      )

```



```{r Basic Descriptive Tables & Visualizations}

  # Renaming covariates
  HCM_Full_Aeae_renamed <- HCM_Full_Aeae %>%
    rename(
      Precipitation = Precip,
      Temperature = TMean,
      `Wind Speed` = WindMean,
      `Night Lights` = nightlight
    )
  
  # Selecting only the necessary columns for the correlation matrix
  cor_data <- HCM_Full_Aeae_renamed %>%
    dplyr::select(Precipitation, Temperature, `Wind Speed`, `Night Lights`, Elevation)
  
  # Selecting only the necessary columns for the correlation matrix
  cor_data <- HCM_Full_Aeae_renamed %>%
    dplyr::select(Precipitation, Temperature, `Wind Speed`, `Night Lights`, Elevation)
  
  # Calculating the correlation matrix
  cor_matrix <- cor(cor_data, use = "complete.obs")
  
  # Define the custom color ramp palette from yellow to pink
  yellow_pink_colors <- c("#FFF44A", "#FF9D82", "#FF769F", "#FF51BD")
  
  # Plotting the correlation matrix using ggcorrplot with a gradient color scale
  ggcorrplot(cor_matrix, 
             hc.order = TRUE, 
             type = "lower", 
             lab = TRUE, 
             lab_col = "black", 
             outline.col = "white", 
             ggtheme = ggplot2::theme_minimal()) +
    scale_fill_gradientn(colors = yellow_pink_colors) +
    ggtitle("Correlation Matrix")
  

  
  # Define the path to save the combined plot
  output_path <- "REPLACE WITH YOUR FOLDER PATH"
  
  # Define the variables and their respective titles
  variables <- c("Quinx", "Aeae", "Aealb")
  titles <- c(
    "Counts of *Culex quinquefasciatus*",
    "Counts of *Aedes aegypti*",
    "Counts of *Aedes albopictus*"
  )
  
  # Define the colors for each plot
  colors <- c("lightpink", "orchid", "mediumpurple")
  
  # Define a function to create a histogram with a specific color and title
  create_histogram <- function(data, variable, title, color) {
    ggplot(data, aes_string(variable)) +
      geom_histogram(fill = color, color = "black", bins = 30) +
      labs(title = title, x = variable, y = "Count") +
      theme_minimal() +
      theme(
        plot.title = element_markdown(),
        plot.background = element_rect(fill = "transparent", color = NA)
      )
  }
  
  # Create histograms
  histograms <- lapply(seq_along(variables), function(i) {
    create_histogram(HCM_Full_Aeae_renamed, variables[i], titles[i], colors[i])
  })
  
  # Find the maximum y-axis limit to use the same for all plots
  max_y <- max(sapply(histograms, function(p) {
    ggplot_build(p)$layout$panel_params[[1]]$y.range[2]
  }))
  
  # Update histograms to have the same y-axis limit
  histograms <- lapply(histograms, function(p) {
    p + ylim(0, max_y)
  })
  
  # Combine histograms side-by-side
  combined_plot <- grid.arrange(grobs = histograms, ncol = 3)
  
  # Save the combined plot as a PNG with a transparent background
  ggsave(
    filename = file.path(output_path, "combined_histograms.png"),
    plot = combined_plot,
    device = "png",
    bg = "transparent",
    width = 24,  # Adjust width as needed
    height = 8,  # Adjust height as needed
    units = "in"
  )
  
  # Save individual histograms as PNGs with transparent backgrounds
  for (i in seq_along(histograms)) {
    ggsave(
      filename = file.path(output_path, paste0(variables[i], "_histogram.png")),
      plot = histograms[[i]],
      device = "png",
      bg = "transparent",
      width = 8,  # Adjust width as needed
      height = 8,  # Adjust height as needed
      units = "in"
    )
  }
  
    # Summary statistics calculation
    summary_table <- HCM_Full_Aeae_renamed %>%
      group_by(Trap_Type) %>%
      summarise(
        Total_Aedes_aegypti = sum(Aeae),
        Mean_Aedes_aegypti = round(mean(Aeae), 2),
        Median_Aedes_aegypti = round(median(Aeae), 2),
        Total_Aedes_albopictus = sum(Aealb),
        Mean_Aedes_albopictus = round(mean(Aealb), 2),
        Median_Aedes_albopictus = round(median(Aealb), 2),
        Total_Culex_quinquefasciatus = sum(Quinx),
        Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
        Median_Culex_quinquefasciatus = round(median(Quinx), 2),
        Total_Culex_nigripalpus = sum(Cxn),
        Mean_Culex_nigripalpus = round(mean(Cxn), 2),
        Median_Culex_nigripalpus = round(median(Cxn), 2),
        Total_Aedes_mediovittatus = sum(Aem),
        Mean_Aedes_mediovittatus = round(mean(Aem), 2),
        Median_Aedes_mediovittatus = round(median(Aem), 2),
        Total_Psorophora_columbiae = sum(Psc),
        Mean_Psorophora_columbiae = round(mean(Psc), 2),
        Median_Psorophora_columbiae = round(median(Psc), 2)
      )
    
    # Calculate overall totals, means, and medians
    total_row <- HCM_Full_Aeae_renamed %>%
      summarise(
        Trap_Type = "Total",
        Total_Aedes_aegypti = sum(Aeae),
        Mean_Aedes_aegypti = round(mean(Aeae), 2),
        Median_Aedes_aegypti = round(median(Aeae), 2),
        Total_Aedes_albopictus = sum(Aealb),
        Mean_Aedes_albopictus = round(mean(Aealb), 2),
        Median_Aedes_albopictus = round(median(Aealb), 2),
        Total_Culex_quinquefasciatus = sum(Quinx),
        Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
        Median_Culex_quinquefasciatus = round(median(Quinx), 2),
        Total_Culex_nigripalpus = sum(Cxn),
        Mean_Culex_nigripalpus = round(mean(Cxn), 2),
        Median_Culex_nigripalpus = round(median(Cxn), 2),
        Total_Aedes_mediovittatus = sum(Aem),
        Mean_Aedes_mediovittatus = round(mean(Aem), 2),
        Median_Aedes_mediovittatus = round(median(Aem), 2),
        Total_Psorophora_columbiae = sum(Psc),
        Mean_Psorophora_columbiae = round(mean(Psc), 2),
        Median_Psorophora_columbiae = round(median(Psc), 2)
      )
  
  
  # Combine summary table with total row
  final_table <- bind_rows(summary_table, total_row)
  
  # Create a beautiful table
  kable(final_table, format = "html", escape = FALSE, col.names = c(
    "Trap Type", 
    "Total", "Mean", "Median", 
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median"
  )) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                  full_width = F) %>%
    add_header_above(c(" " = 1, 
                       "<i>Aedes aegypti</i>" = 3, 
                       "<i>Aedes albopictus</i>" = 3, 
                       "<i>Culex quinquefasciatus</i>" = 3,
                       "<i>Culex nigripalpus</i>" = 3,
                       "<i>Aedes mediovittatus</i>" = 3,
                       "<i>Psorophora columbiae</i>" = 3), escape = FALSE) %>%
    row_spec(nrow(final_table), bold = TRUE, background = "lightgray")
  
  
  # Add a new variable for the total counts of all species per observation
  HCM_Full_Aeae_renamed <- HCM_Full_Aeae_renamed %>%
    mutate(Total_Counts = Aeae + Aealb + Quinx + Cxn + Aem + Psc)
  
  # Summary statistics calculation for each species and the new total column
  summary_table <- HCM_Full_Aeae_renamed %>%
    group_by(Trap_Type) %>%
    summarise(
      Total_Aedes_aegypti = sum(Aeae),
      Mean_Aedes_aegypti = round(mean(Aeae), 2),
      Median_Aedes_aegypti = round(median(Aeae), 2),
      Total_Aedes_albopictus = sum(Aealb),
      Mean_Aedes_albopictus = round(mean(Aealb), 2),
      Median_Aedes_albopictus = round(median(Aealb), 2),
      Total_Culex_quinquefasciatus = sum(Quinx),
      Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
      Median_Culex_quinquefasciatus = round(median(Quinx), 2),
      Total_Culex_nigripalpus = sum(Cxn),
      Mean_Culex_nigripalpus = round(mean(Cxn), 2),
      Median_Culex_nigripalpus = round(median(Cxn), 2),
      Total_Aedes_mediovittatus = sum(Aem),
      Mean_Aedes_mediovittatus = round(mean(Aem), 2),
      Median_Aedes_mediovittatus = round(median(Aem), 2),
      Total_Psorophora_columbiae = sum(Psc),
      Mean_Psorophora_columbiae = round(mean(Psc), 2),
      Median_Psorophora_columbiae = round(median(Psc), 2),
      Total_All_Species = sum(Total_Counts),
      Mean_All_Species = round(mean(Total_Counts), 2),
      Median_All_Species = round(median(Total_Counts), 2)
    ) %>%
    pivot_longer(cols = -Trap_Type, names_to = "Species_Metric", values_to = "Value") %>%
    separate(Species_Metric, into = c("Metric", "Species"), sep = "_", extra = "merge") %>%
    pivot_wider(names_from = c(Trap_Type, Metric), values_from = Value)
  
  # Calculate overall totals, means, and medians across all trap types for each species
  total_row <- HCM_Full_Aeae_renamed %>%
    summarise(
      Species = "All Species",
      Total_Aedes_aegypti = sum(Aeae),
      Mean_Aedes_aegypti = round(mean(Aeae), 2),
      Median_Aedes_aegypti = round(median(Aeae), 2),
      Total_Aedes_albopictus = sum(Aealb),
      Mean_Aedes_albopictus = round(mean(Aealb), 2),
      Median_Aedes_albopictus = round(median(Aealb), 2),
      Total_Culex_quinquefasciatus = sum(Quinx),
      Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
      Median_Culex_quinquefasciatus = round(median(Quinx), 2),
      Total_Culex_nigripalpus = sum(Cxn),
      Mean_Culex_nigripalpus = round(mean(Cxn), 2),
      Median_Culex_nigripalpus = round(median(Cxn), 2),
      Total_Aedes_mediovittatus = sum(Aem),
      Mean_Aedes_mediovittatus = round(mean(Aem), 2),
      Median_Aedes_mediovittatus = round(median(Aem), 2),
      Total_Psorophora_columbiae = sum(Psc),
      Mean_Psorophora_columbiae = round(mean(Psc), 2),
      Median_Psorophora_columbiae = round(median(Psc), 2),
      Total_All_Species = sum(Total_Counts),
      Mean_All_Species = round(mean(Total_Counts), 2),
      Median_All_Species = round(median(Total_Counts), 2)
    ) %>%
    pivot_longer(cols = -Species, names_to = "Metric_Species", values_to = "Value") %>%
    separate(Metric_Species, into = c("Metric", "Species"), sep = "_", extra = "merge") %>%
    pivot_wider(names_from = Metric, values_from = Value)
  
  # Combine summary table with total row
  final_table <- bind_rows(summary_table, total_row)
  
  # Create a beautiful table with species as rows and trap types as columns
  kable(final_table, format = "html", escape = FALSE, col.names = c(
    "Species",
    rep(c("Total", "Mean", "Median"), times = 4)  # Adjusted to 4 for three trap types + overall
  )) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                  full_width = F) %>%
    add_header_above(c(" " = 1, 
                       "BG Sentinel" = 3, 
                       "CDC Light Trap" = 3, 
                       "Gravid Trap" = 3,
                       "Total" = 3)) %>%
    row_spec(nrow(final_table), bold = TRUE, background = "lightgray") %>%
    column_spec(1, bold = TRUE, italic = TRUE)

```



```{r VIF Test}

  GLM_Full <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + grassland + cropland + built + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_FullVIF <- car::vif(GLM_Full)
  print(GLM_FullVIF)
  max(GLM_FullVIF)

  # Remove Built (VIF > 50K)
  GLM_Step2 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + grassland + cropland + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step2VIF <- car::vif(GLM_Step2)
  print(GLM_Step2VIF)
  max(GLM_Step2VIF)
  
  # Remove Grassland (VIF > 50)
  GLM_Step3 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step3VIF <- car::vif(GLM_Step3)
  print(GLM_Step3VIF)
  max(GLM_Step3VIF)
  
  # Remove Water (VIF > 30)
  GLM_Step4 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step4VIF <- car::vif(GLM_Step4)
  print(GLM_Step4VIF)
  max(GLM_Step4VIF)

  # Remove NDVI (VIF > 10)    
    GLM_Step5 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + cropland + wetland + WindMean, data = HCM_Full_Aealb)
  GLM_Step5VIF <- car::vif(GLM_Step5)
  print(GLM_Step5VIF)
  max(GLM_Step5VIF)
  
    AeaeHurd <- pscl::hurdle(
      Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland | Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )
    
    AealbHurd <- pscl::hurdle(
      Aealb ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland | Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )
    
    summary(AeaeHurd)
    summary(AealbHurd)
```



```{r Code for boosted regression trees}
# =============================================================================
# BOOTSTRAP BRT MODELING FOR ROBUST UNCERTAINTY ESTIMATION
# =============================================================================
# 100 bootstrap replicates for permutation-based model metrics
# Provides true prediction uncertainty with 95% confidence intervals
# =============================================================================

library(pROC)
library(caret)
library(purrr)
library(dplyr)
library(dismo)
library(gbm)
library(parallel)

cat("\n=======================================================================\n")
cat("  BOOTSTRAP BRT MODELING SYSTEM (100 REPLICATES)\n")
cat("  For Robust Uncertainty Estimation\n")
cat("=======================================================================\n\n")

# ---------------------------
# Configuration
# ---------------------------

base_covariates <- c("Precip", "TMean", "WindMean", "Elevation")
all_lc_variables <- c("LC_trees", "LC_shrubs", "LC_grassland", "LC_cropland", 
                      "LC_wetland", "LC_built")

n_bootstrap <- 100
use_parallel <- TRUE
n_cores <- max(1, floor(parallel::detectCores() * 2/3))

species_list <- c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc")
dataset_names <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq",
                   "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")

cat("Bootstrap settings:\n")
cat("  Iterations:", n_bootstrap, "\n")
cat("  Parallel processing:", use_parallel, "\n")
cat("  Cores:", n_cores, "(2/3 of", parallel::detectCores(), "available)\n\n")

# ---------------------------
# Helper Functions
# ---------------------------

get_tree_complexity <- function(n_present) {
  if (n_present < 100) return(2)
  else if (n_present < 300) return(3)
  else return(5)
}

get_covariates_for_dataset <- function(dataset_name, stack_name = "AverageStack_updated") {
  df <- get(dataset_name, envir = .GlobalEnv)
  dataset_vars <- names(df)
  
  stack <- tryCatch(
    get(stack_name, envir = .GlobalEnv),
    error = function(e) NULL
  )
  
  if (is.null(stack)) {
    return(intersect(c(base_covariates, all_lc_variables), dataset_vars))
  }
  
  stack_vars <- names(stack)
  dataset_lc <- intersect(all_lc_variables, dataset_vars)
  stack_lc <- intersect(all_lc_variables, stack_vars)
  usable_lc <- intersect(dataset_lc, stack_lc)
  
  all_covariates <- c(base_covariates, usable_lc)
  final_covariates <- intersect(all_covariates, dataset_vars)
  final_covariates <- intersect(final_covariates, stack_vars)
  
  return(final_covariates)
}

# =============================================================================
# SINGLE BOOTSTRAP ITERATION WITH METRICS
# =============================================================================

fit_single_bootstrap_brt <- function(species, dataset, covariates, 
                                     iteration, family = "bernoulli") {
  
  if (family == "bernoulli") {
    data_full <- dataset %>%
      dplyr::mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
      dplyr::select(SpeciesBin, dplyr::all_of(covariates)) %>%
      na.omit()
    response_var <- "SpeciesBin"
  } else {
    data_full <- dataset %>%
      dplyr::filter(.data[[species]] >= 1) %>%
      dplyr::select(dplyr::all_of(species), dplyr::all_of(covariates)) %>%
      na.omit()
    response_var <- species
  }
  
  n <- nrow(data_full)
  boot_indices <- sample(1:n, size = n, replace = TRUE)
  oob_indices <- setdiff(1:n, unique(boot_indices))
  
  data_boot <- data_full[boot_indices, ]
  data_oob <- if (length(oob_indices) > 10) data_full[oob_indices, ] else NULL
  
  if (family == "bernoulli") {
    n_present <- sum(data_boot[[response_var]] == 1)
  } else {
    n_present <- nrow(data_boot)
  }
  tree_comp <- get_tree_complexity(n_present)
  
  model <- tryCatch({
    gbm.step(
      data = data_boot,
      gbm.x = covariates,
      gbm.y = response_var,
      family = family,
      tree.complexity = tree_comp,
      learning.rate = 0.01,
      bag.fraction = 0.75,
      silent = TRUE,
      plot.main = FALSE
    )
  }, error = function(e) NULL)
  
  if (is.null(model)) return(NULL)
  
  # Calculate OOB metrics
  oob_metrics <- NULL
  if (!is.null(data_oob) && nrow(data_oob) > 10) {
    oob_pred <- predict(model, data_oob, n.trees = model$gbm.call$best.trees, type = "response")
    
    if (family == "bernoulli") {
      oob_actual <- data_oob[[response_var]]
      if (length(unique(oob_actual)) == 2) {
        roc_obj <- tryCatch(pROC::roc(oob_actual, oob_pred, quiet = TRUE), error = function(e) NULL)
        if (!is.null(roc_obj)) {
          oob_auc <- as.numeric(pROC::auc(roc_obj))
          coords_best <- pROC::coords(roc_obj, "best", best.method = "youden")
          threshold <- as.numeric(coords_best$threshold[1])
          sens <- as.numeric(coords_best$sensitivity[1])
          spec <- as.numeric(coords_best$specificity[1])
          
          pred_class <- ifelse(oob_pred >= threshold, 1, 0)
          accuracy <- mean(pred_class == oob_actual)
          
          oob_metrics <- list(
            auc = oob_auc,
            threshold = threshold,
            sensitivity = sens,
            specificity = spec,
            accuracy = accuracy
          )
        }
      }
    } else {
      oob_actual <- data_oob[[response_var]]
      oob_metrics <- list(
        correlation = cor(oob_actual, oob_pred, use = "complete.obs"),
        rmse = sqrt(mean((oob_actual - oob_pred)^2)),
        mae = mean(abs(oob_actual - oob_pred))
      )
    }
  }
  
  var_imp <- summary(model, plotit = FALSE)
  
  return(list(
    model = model,
    oob_metrics = oob_metrics,
    var_importance = var_imp
  ))
}

# =============================================================================
# BOOTSTRAP ENSEMBLE FOR ONE SPECIES
# =============================================================================

fit_bootstrap_ensemble <- function(species, dataset_name, 
                                   n_boot = n_bootstrap,
                                   family = "bernoulli") {
  
  cat("\n=======================================================================\n")
  cat("  BOOTSTRAP ENSEMBLE:", species, "(", family, ")\n")
  cat("=======================================================================\n\n")
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  covariates <- get_covariates_for_dataset(dataset_name)
  
  if (family == "bernoulli") {
    n_present <- sum(dataset[[species]] >= 1)
  } else {
    n_present <- sum(dataset[[species]] >= 1)
  }
  
  cat("Sample size:", n_present, "presences\n")
  cat("Covariates:", paste(covariates, collapse = ", "), "\n")
  
  if (n_present < 20) {
    cat("SKIPPED: Insufficient data\n")
    return(NULL)
  }
  
  cat("Fitting", n_boot, "bootstrap models...\n")
  
  start_time <- Sys.time()
  
  if (use_parallel && n_cores > 1) {
    cl <- parallel::makeCluster(n_cores)
    
    parallel::clusterExport(cl, c("fit_single_bootstrap_brt", "get_tree_complexity",
                                  "species", "dataset", "covariates", "family"),
                            envir = environment())
    parallel::clusterEvalQ(cl, {
      library(dismo)
      library(gbm)
      library(dplyr)
      library(pROC)
    })
    
    bootstrap_results <- parallel::parLapply(cl, 1:n_boot, function(i) {
      fit_single_bootstrap_brt(species, dataset, covariates, i, family)
    })
    
    parallel::stopCluster(cl)
  } else {
    bootstrap_results <- lapply(1:n_boot, function(i) {
      if (i %% 25 == 0) cat("  Iteration", i, "/", n_boot, "\n")
      fit_single_bootstrap_brt(species, dataset, covariates, i, family)
    })
  }
  
  successful <- !sapply(bootstrap_results, is.null)
  bootstrap_results <- bootstrap_results[successful]
  n_successful <- length(bootstrap_results)
  
  elapsed <- difftime(Sys.time(), start_time, units = "secs")
  
  cat("\nBootstrap complete:\n")
  cat("  Successful models:", n_successful, "/", n_boot, "\n")
  cat("  Time:", round(elapsed, 1), "seconds\n")
  cat("  Average per model:", round(elapsed / n_boot, 2), "seconds\n")
  
  if (n_successful < n_boot * 0.5) {
    cat("  WARNING: Low success rate (<50%)\n")
  }
  
  # Extract models
  bootstrap_models <- lapply(bootstrap_results, function(x) x$model)
  
  # Aggregate OOB metrics with CI
  oob_metrics_list <- lapply(bootstrap_results, function(x) x$oob_metrics)
  oob_metrics_list <- oob_metrics_list[!sapply(oob_metrics_list, is.null)]
  
  aggregated_metrics <- NULL
  if (length(oob_metrics_list) > 10) {
    if (family == "bernoulli") {
      auc_vals <- sapply(oob_metrics_list, function(x) x$auc)
      sens_vals <- sapply(oob_metrics_list, function(x) x$sensitivity)
      spec_vals <- sapply(oob_metrics_list, function(x) x$specificity)
      acc_vals <- sapply(oob_metrics_list, function(x) x$accuracy)
      thresh_vals <- sapply(oob_metrics_list, function(x) x$threshold)
      
      aggregated_metrics <- data.frame(
        metric = c("AUC", "Sensitivity", "Specificity", "Accuracy", "Threshold"),
        mean = c(mean(auc_vals, na.rm = TRUE), mean(sens_vals, na.rm = TRUE),
                 mean(spec_vals, na.rm = TRUE), mean(acc_vals, na.rm = TRUE),
                 mean(thresh_vals, na.rm = TRUE)),
        sd = c(sd(auc_vals, na.rm = TRUE), sd(sens_vals, na.rm = TRUE),
               sd(spec_vals, na.rm = TRUE), sd(acc_vals, na.rm = TRUE),
               sd(thresh_vals, na.rm = TRUE)),
        lower_ci = c(quantile(auc_vals, 0.025, na.rm = TRUE),
                     quantile(sens_vals, 0.025, na.rm = TRUE),
                     quantile(spec_vals, 0.025, na.rm = TRUE),
                     quantile(acc_vals, 0.025, na.rm = TRUE),
                     quantile(thresh_vals, 0.025, na.rm = TRUE)),
        upper_ci = c(quantile(auc_vals, 0.975, na.rm = TRUE),
                     quantile(sens_vals, 0.975, na.rm = TRUE),
                     quantile(spec_vals, 0.975, na.rm = TRUE),
                     quantile(acc_vals, 0.975, na.rm = TRUE),
                     quantile(thresh_vals, 0.975, na.rm = TRUE))
      )
    } else {
      cor_vals <- sapply(oob_metrics_list, function(x) x$correlation)
      rmse_vals <- sapply(oob_metrics_list, function(x) x$rmse)
      mae_vals <- sapply(oob_metrics_list, function(x) x$mae)
      
      aggregated_metrics <- data.frame(
        metric = c("Correlation", "RMSE", "MAE"),
        mean = c(mean(cor_vals, na.rm = TRUE), mean(rmse_vals, na.rm = TRUE),
                 mean(mae_vals, na.rm = TRUE)),
        sd = c(sd(cor_vals, na.rm = TRUE), sd(rmse_vals, na.rm = TRUE),
               sd(mae_vals, na.rm = TRUE)),
        lower_ci = c(quantile(cor_vals, 0.025, na.rm = TRUE),
                     quantile(rmse_vals, 0.025, na.rm = TRUE),
                     quantile(mae_vals, 0.025, na.rm = TRUE)),
        upper_ci = c(quantile(cor_vals, 0.975, na.rm = TRUE),
                     quantile(rmse_vals, 0.975, na.rm = TRUE),
                     quantile(mae_vals, 0.975, na.rm = TRUE))
      )
    }
    
    cat("\nOOB Performance Metrics (Mean ± SD [95% CI]):\n")
    apply(aggregated_metrics, 1, function(row) {
      cat(sprintf("  %s: %.3f ± %.3f [%.3f, %.3f]\n",
                  row["metric"], as.numeric(row["mean"]), as.numeric(row["sd"]),
                  as.numeric(row["lower_ci"]), as.numeric(row["upper_ci"])))
    })
  }
  
  # Consensus variable importance with CI
  var_imp_list <- lapply(bootstrap_results, function(x) x$var_importance)
  all_vars <- unique(unlist(lapply(var_imp_list, function(x) x$var)))
  
  consensus_imp <- data.frame(var = all_vars, stringsAsFactors = FALSE)
  
  imp_matrix <- sapply(var_imp_list, function(vi) {
    sapply(all_vars, function(v) {
      idx <- which(vi$var == v)
      if (length(idx) > 0) vi$rel.inf[idx] else 0
    })
  })
  
  consensus_imp$mean <- apply(imp_matrix, 1, mean)
  consensus_imp$sd <- apply(imp_matrix, 1, sd)
  consensus_imp$lower_ci <- apply(imp_matrix, 1, quantile, probs = 0.025)
  consensus_imp$upper_ci <- apply(imp_matrix, 1, quantile, probs = 0.975)
  consensus_imp$cv <- consensus_imp$sd / consensus_imp$mean
  
  consensus_imp <- consensus_imp[order(-consensus_imp$mean), ]
  
  cat("\nConsensus Variable Importance (Mean ± SD [95% CI]):\n")
  apply(consensus_imp, 1, function(row) {
    cat(sprintf("  %s: %.2f%% ± %.2f%% [%.2f%%, %.2f%%]\n",
                row["var"], as.numeric(row["mean"]), as.numeric(row["sd"]),
                as.numeric(row["lower_ci"]), as.numeric(row["upper_ci"])))
  })
  
  result <- list(
    species = species,
    family = family,
    models = bootstrap_models,
    n_bootstrap = n_boot,
    n_successful = n_successful,
    success_rate = n_successful / n_boot,
    covariates = covariates,
    consensus_importance = consensus_imp,
    aggregated_metrics = aggregated_metrics,
    oob_metrics_raw = oob_metrics_list
  )
  
  class(result) <- c("bootstrap_brt", class(result))
  
  return(result)
}

# =============================================================================
# PREDICT WITH BOOTSTRAP ENSEMBLE
# =============================================================================

predict_bootstrap_ensemble <- function(bootstrap_ensemble, newdata, 
                                       type = "response") {
  
  if (is.null(bootstrap_ensemble) || bootstrap_ensemble$n_successful == 0) {
    return(NULL)
  }
  
  models <- bootstrap_ensemble$models
  n_models <- length(models)
  
  # Parallel prediction if large dataset
  if (nrow(newdata) > 10000 && use_parallel && n_cores > 1) {
    cl <- parallel::makeCluster(n_cores)
    parallel::clusterExport(cl, c("models", "newdata", "type"), envir = environment())
    parallel::clusterEvalQ(cl, library(gbm))
    
    predictions_list <- parallel::parLapply(cl, models, function(m) {
      predict(m, newdata, n.trees = m$gbm.call$best.trees, type = type)
    })
    
    parallel::stopCluster(cl)
    predictions_matrix <- do.call(cbind, predictions_list)
  } else {
    predictions_matrix <- sapply(models, function(m) {
      predict(m, newdata, n.trees = m$gbm.call$best.trees, type = type)
    })
  }
  
  pred_mean <- rowMeans(predictions_matrix, na.rm = TRUE)
  pred_sd <- apply(predictions_matrix, 1, sd, na.rm = TRUE)
  pred_lower <- apply(predictions_matrix, 1, quantile, probs = 0.025, na.rm = TRUE)
  pred_upper <- apply(predictions_matrix, 1, quantile, probs = 0.975, na.rm = TRUE)
  pred_cv <- pred_sd / (pred_mean + 1e-10)
  
  # Model agreement (proportion within 0.1 of mean)
  pred_agreement <- apply(predictions_matrix, 1, function(row) {
    mean(abs(row - mean(row, na.rm = TRUE)) < 0.1, na.rm = TRUE)
  })
  
  result <- list(
    mean = pred_mean,
    sd = pred_sd,
    lower_ci = pred_lower,
    upper_ci = pred_upper,
    cv = pred_cv,
    agreement = pred_agreement,
    n_models = n_models,
    all_predictions = predictions_matrix
  )
  
  return(result)
}

# =============================================================================
# FIT ALL BOOTSTRAP ENSEMBLES
# =============================================================================

cat("\n=======================================================================\n")
cat("  FITTING BOOTSTRAP ENSEMBLES FOR ALL SPECIES\n")
cat("=======================================================================\n\n")

set.seed(1999)

cat("STEP 1: BINARY (PRESENCE/ABSENCE) MODELS\n")
cat("-----------------------------------------------------------------------\n")

BRT_Bootstrap_Binary <- purrr::map2(species_list, dataset_names, 
                                    ~fit_bootstrap_ensemble(.x, .y, n_bootstrap, "bernoulli")) %>%
  purrr::set_names(species_list)

cat("\n\nSTEP 2: COUNT (ABUNDANCE) MODELS\n")
cat("-----------------------------------------------------------------------\n")

BRT_Bootstrap_Count <- purrr::map2(species_list, dataset_names,
                                   ~fit_bootstrap_ensemble(.x, .y, n_bootstrap, "poisson")) %>%
  purrr::set_names(species_list)

# =============================================================================
# COMPREHENSIVE SUMMARY WITH CI
# =============================================================================

cat("\n=======================================================================\n")
cat("  BOOTSTRAP ENSEMBLE SUMMARY (100 REPLICATES)\n")
cat("=======================================================================\n\n")

# Model fitting summary
summary_table <- data.frame(
  Species = species_list,
  Binary_Success = sapply(BRT_Bootstrap_Binary, function(x) {
    if (is.null(x)) "FAILED" else paste0(x$n_successful, "/", x$n_bootstrap)
  }),
  Count_Success = sapply(BRT_Bootstrap_Count, function(x) {
    if (is.null(x)) "FAILED" else paste0(x$n_successful, "/", x$n_bootstrap)
  })
)

cat("MODEL FITTING SUCCESS:\n")
print(summary_table, row.names = FALSE)

# Binary model performance with CI
cat("\n\nBINARY MODEL PERFORMANCE (OOB Metrics with 95% CI):\n")
cat("-----------------------------------------------------------------------\n")

binary_perf_table <- purrr::map_dfr(names(BRT_Bootstrap_Binary), function(sp) {
  ens <- BRT_Bootstrap_Binary[[sp]]
  if (is.null(ens) || is.null(ens$aggregated_metrics)) {
    return(data.frame(
      Species = sp,
      AUC = NA, AUC_CI = NA,
      Sensitivity = NA, Sens_CI = NA,
      Specificity = NA, Spec_CI = NA,
      stringsAsFactors = FALSE
    ))
  }
  
  metrics <- ens$aggregated_metrics
  
  get_metric <- function(name) {
    row <- metrics[metrics$metric == name, ]
    if (nrow(row) == 0) return(list(mean = NA, ci = NA))
    list(
      mean = round(row$mean, 3),
      ci = paste0("[", round(row$lower_ci, 3), ", ", round(row$upper_ci, 3), "]")
    )
  }
  
  auc <- get_metric("AUC")
  sens <- get_metric("Sensitivity")
  spec <- get_metric("Specificity")
  
  data.frame(
    Species = sp,
    AUC = auc$mean, AUC_CI = auc$ci,
    Sensitivity = sens$mean, Sens_CI = sens$ci,
    Specificity = spec$mean, Spec_CI = spec$ci,
    stringsAsFactors = FALSE
  )
})

print(binary_perf_table, row.names = FALSE)

# Count model performance with CI
cat("\n\nCOUNT MODEL PERFORMANCE (OOB Metrics with 95% CI):\n")
cat("-----------------------------------------------------------------------\n")

count_perf_table <- purrr::map_dfr(names(BRT_Bootstrap_Count), function(sp) {
  ens <- BRT_Bootstrap_Count[[sp]]
  if (is.null(ens) || is.null(ens$aggregated_metrics)) {
    return(data.frame(
      Species = sp,
      Correlation = NA, Cor_CI = NA,
      RMSE = NA, RMSE_CI = NA,
      MAE = NA, MAE_CI = NA,
      stringsAsFactors = FALSE
    ))
  }
  
  metrics <- ens$aggregated_metrics
  
  get_metric <- function(name, digits = 3) {
    row <- metrics[metrics$metric == name, ]
    if (nrow(row) == 0) return(list(mean = NA, ci = NA))
    list(
      mean = round(row$mean, digits),
      ci = paste0("[", round(row$lower_ci, digits), ", ", round(row$upper_ci, digits), "]")
    )
  }
  
  cor_m <- get_metric("Correlation")
  rmse_m <- get_metric("RMSE", 2)
  mae_m <- get_metric("MAE", 2)
  
  data.frame(
    Species = sp,
    Correlation = cor_m$mean, Cor_CI = cor_m$ci,
    RMSE = rmse_m$mean, RMSE_CI = rmse_m$ci,
    MAE = mae_m$mean, MAE_CI = mae_m$ci,
    stringsAsFactors = FALSE
  )
})

print(count_perf_table, row.names = FALSE)

# Variable importance summary
cat("\n\nVARIABLE IMPORTANCE SUMMARY (Mean ± SD across 100 bootstraps):\n")
cat("-----------------------------------------------------------------------\n")

purrr::walk(names(BRT_Bootstrap_Binary), function(sp) {
  ens <- BRT_Bootstrap_Binary[[sp]]
  if (is.null(ens)) return()
  
  cat("\n", sp, " (Binary Model):\n", sep = "")
  imp <- ens$consensus_importance
  
  apply(imp[1:min(5, nrow(imp)), ], 1, function(row) {
    cat(sprintf("  %s: %.1f%% ± %.1f%% [%.1f%%, %.1f%%]\n",
                row["var"], as.numeric(row["mean"]), as.numeric(row["sd"]),
                as.numeric(row["lower_ci"]), as.numeric(row["upper_ci"])))
  })
})

cat("\n=======================================================================\n")
cat("  BOOTSTRAP MODELING COMPLETE\n")
cat("=======================================================================\n\n")

cat("Objects created:\n")
cat("  - BRT_Bootstrap_Binary: List of", length(BRT_Bootstrap_Binary), "bootstrap ensembles\n")
cat("  - BRT_Bootstrap_Count: List of", length(BRT_Bootstrap_Count), "bootstrap ensembles\n\n")

cat("Each ensemble contains:\n")
cat("  - models: List of", n_bootstrap, "bootstrap BRT models\n")
cat("  - consensus_importance: Variable importance with 95% CI\n")
cat("  - aggregated_metrics: OOB performance metrics with 95% CI\n")
cat("  - oob_metrics_raw: Raw metrics from each bootstrap iteration\n\n")

cat("Use predict_bootstrap_ensemble() for predictions with uncertainty.\n")
cat("Returns: mean, SD, 95% CI, CV, and model agreement for each prediction.\n\n")

```



```{r Code for BRT Predictions}
# =============================================================================
# BOOTSTRAP BRT ENSEMBLE PREDICTIONS - OPTIMIZED (SEQUENTIAL)
# =============================================================================
# Key finding: Parallel overhead >> prediction time for gbm models
# Sequential prediction: ~35 seconds for 100 models
# matrixStats for row operations: ~10 seconds
# Total per prediction: ~1-2 minutes (vs 50+ minutes with parallelization)
# =============================================================================

library(raster)
library(dismo)
library(gbm)
library(matrixStats)
library(dplyr)
library(purrr)

cat("\n=======================================================================\n")
cat("  BOOTSTRAP ENSEMBLE PREDICTIONS - SEQUENTIAL OPTIMIZED\n")
cat("  ~2 min per prediction (vs 50+ min with parallel overhead)\n")
cat("=======================================================================\n\n")

# =============================================================================
# CONFIGURATION
# =============================================================================

output_base <- "Predictions"

dir.create(output_base, recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Baseline"), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Monthly"), recursive = TRUE, showWarnings = FALSE)

month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

species_mapping <- c(
  Aeae = "Aedes_aegypti",
  Aealb = "Aedes_albopictus", 
  Quinx = "Culex_quinquefasciatus",
  Aem = "Aedes_mediovittatus",
  Cxn = "Culex_nigripalpus",
  Psc = "Psorophora_columbiae"
)

cat("Output directory:", output_base, "\n\n")

# =============================================================================
# CORE PREDICTION FUNCTION - SEQUENTIAL + matrixStats
# =============================================================================

predict_ensemble_fast <- function(bootstrap_ensemble, 
                                  raster_stack,
                                  calc_full_uncertainty = TRUE,
                                  verbose = TRUE) {
  
  if (is.null(bootstrap_ensemble) || bootstrap_ensemble$n_successful == 0) {
    if (verbose) cat("    ERROR: No valid models in ensemble\n")
    return(NULL)
  }
  
  models <- bootstrap_ensemble$models
  n_models <- length(models)
  covariates <- bootstrap_ensemble$covariates
  
  if (verbose) {
    cat("    Models:", n_models, "| Covariates:", length(covariates), "\n")
  }
  
  # Verify covariates
 stack_names <- names(raster_stack)
  missing_covs <- setdiff(covariates, stack_names)
  if (length(missing_covs) > 0) {
    if (verbose) cat("    ERROR: Missing covariates:", paste(missing_covs, collapse = ", "), "\n")
    return(NULL)
  }
  
  # Subset and extract values
  pred_stack <- raster::subset(raster_stack, covariates)
  all_vals <- raster::getValues(pred_stack)
  n_cells <- nrow(all_vals)
  
  # Valid cells mask
  valid_mask <- complete.cases(all_vals)
  n_valid <- sum(valid_mask)
  
  if (verbose) {
    cat("    Cells:", format(n_valid, big.mark = ","), "valid /", 
        format(n_cells, big.mark = ","), "total\n")
  }
  
  if (n_valid == 0) {
    if (verbose) cat("    ERROR: No valid cells\n")
    return(NULL)
  }
  
  # Prepare prediction data
  valid_df <- as.data.frame(all_vals[valid_mask, , drop = FALSE])
  names(valid_df) <- covariates
  rm(all_vals)
  
  # Sequential prediction - FAST without parallel overhead
  if (verbose) cat("    Predicting (sequential)...")
  pred_start <- Sys.time()
  
  pred_matrix <- sapply(models, function(m) {
    predict(m, valid_df, n.trees = m$gbm.call$best.trees, type = "response")
  })
  
  pred_time <- difftime(Sys.time(), pred_start, units = "secs")
  if (verbose) cat(" ", round(pred_time, 1), "sec\n")
  
  # Calculate statistics with matrixStats
  if (verbose) cat("    Computing statistics...")
  stats_start <- Sys.time()
  
  pred_mean_valid <- matrixStats::rowMeans2(pred_matrix)
  pred_sd_valid <- matrixStats::rowSds(pred_matrix)
  
  if (calc_full_uncertainty) {
    quantiles_valid <- matrixStats::rowQuantiles(pred_matrix, probs = c(0.025, 0.975))
    pred_lower_valid <- quantiles_valid[, 1]
    pred_upper_valid <- quantiles_valid[, 2]
    
    deviations <- abs(sweep(pred_matrix, 1, pred_mean_valid, "-"))
    pred_agreement_valid <- matrixStats::rowMeans2(deviations < 0.1)
    rm(deviations, quantiles_valid)
  }
  
  rm(pred_matrix)
  
  stats_time <- difftime(Sys.time(), stats_start, units = "secs")
  if (verbose) cat(" ", round(stats_time, 1), "sec\n")
  
  # Create output rasters
  template <- pred_stack[[1]]
  
  pred_mean_full <- rep(NA_real_, n_cells)
  pred_sd_full <- rep(NA_real_, n_cells)
  pred_mean_full[valid_mask] <- pred_mean_valid
  pred_sd_full[valid_mask] <- pred_sd_valid
  
  result <- list(
    mean = raster::setValues(template, pred_mean_full),
    sd = raster::setValues(template, pred_sd_full),
    n_models = n_models
  )
  names(result$mean) <- "mean"
  names(result$sd) <- "sd"
  
  if (calc_full_uncertainty) {
    pred_lower_full <- rep(NA_real_, n_cells)
    pred_upper_full <- rep(NA_real_, n_cells)
    pred_agreement_full <- rep(NA_real_, n_cells)
    
    pred_lower_full[valid_mask] <- pred_lower_valid
    pred_upper_full[valid_mask] <- pred_upper_valid
    pred_agreement_full[valid_mask] <- pred_agreement_valid
    
    result$lower_ci <- raster::setValues(template, pred_lower_full)
    result$upper_ci <- raster::setValues(template, pred_upper_full)
    result$agreement <- raster::setValues(template, pred_agreement_full)
    
    names(result$lower_ci) <- "lower_95ci"
    names(result$upper_ci) <- "upper_95ci"
    names(result$agreement) <- "agreement"
  }
  
  return(result)
}

# =============================================================================
# BASELINE PREDICTION FUNCTION
# =============================================================================

predict_baseline_species <- function(species_code, 
                                     binary_ensemble,
                                     count_ensemble = NULL,
                                     average_stack,
                                     output_dir = output_base) {
  
  species_name <- species_mapping[species_code]
  
  cat("\n-----------------------------------------------------------------------\n")
  cat("  BASELINE:", species_name, "\n")
  cat("-----------------------------------------------------------------------\n")
  
  if (is.null(binary_ensemble)) {
    cat("  ERROR: No binary ensemble\n")
    return(NULL)
  }
  
  species_dir <- file.path(output_dir, "Baseline", species_code)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  start_time <- Sys.time()
  
  # Presence predictions
  cat("\n  PRESENCE MODEL:\n")
  presence_preds <- predict_ensemble_fast(binary_ensemble, average_stack,
                                          calc_full_uncertainty = TRUE)
  
  if (!is.null(presence_preds)) {
    cat("    Saving rasters...\n")
    
    writeRaster(presence_preds$mean, 
                file.path(species_dir, paste0(species_code, "_Presence_Mean.tif")),
                overwrite = TRUE)
    writeRaster(presence_preds$sd,
                file.path(species_dir, paste0(species_code, "_Presence_SD.tif")),
                overwrite = TRUE)
    writeRaster(presence_preds$lower_ci,
                file.path(species_dir, paste0(species_code, "_Presence_Lower95.tif")),
                overwrite = TRUE)
    writeRaster(presence_preds$upper_ci,
                file.path(species_dir, paste0(species_code, "_Presence_Upper95.tif")),
                overwrite = TRUE)
    writeRaster(presence_preds$agreement,
                file.path(species_dir, paste0(species_code, "_Presence_Agreement.tif")),
                overwrite = TRUE)
    
    cat("    Mean prob:", round(cellStats(presence_preds$mean, mean, na.rm = TRUE), 4), "\n")
  }
  
  # Abundance predictions
  if (!is.null(count_ensemble)) {
    cat("\n  ABUNDANCE MODEL:\n")
    abundance_preds <- predict_ensemble_fast(count_ensemble, average_stack,
                                             calc_full_uncertainty = TRUE)
    
    if (!is.null(abundance_preds)) {
      writeRaster(abundance_preds$mean,
                  file.path(species_dir, paste0(species_code, "_Abundance_Mean.tif")),
                  overwrite = TRUE)
      writeRaster(abundance_preds$sd,
                  file.path(species_dir, paste0(species_code, "_Abundance_SD.tif")),
                  overwrite = TRUE)
      writeRaster(abundance_preds$lower_ci,
                  file.path(species_dir, paste0(species_code, "_Abundance_Lower95.tif")),
                  overwrite = TRUE)
      writeRaster(abundance_preds$upper_ci,
                  file.path(species_dir, paste0(species_code, "_Abundance_Upper95.tif")),
                  overwrite = TRUE)
      
      # Combined metric
      combined_mean <- presence_preds$mean * abundance_preds$mean
      combined_sd <- sqrt(
        (presence_preds$mean^2 * abundance_preds$sd^2) +
        (abundance_preds$mean^2 * presence_preds$sd^2) +
        (presence_preds$sd^2 * abundance_preds$sd^2)
      )
      
      writeRaster(combined_mean,
                  file.path(species_dir, paste0(species_code, "_Combined_Mean.tif")),
                  overwrite = TRUE)
      writeRaster(combined_sd,
                  file.path(species_dir, paste0(species_code, "_Combined_SD.tif")),
                  overwrite = TRUE)
      
      cat("    Mean abundance:", round(cellStats(abundance_preds$mean, mean, na.rm = TRUE), 2), "\n")
      
      rm(abundance_preds, combined_mean, combined_sd)
    }
  }
  
  rm(presence_preds)
  gc(verbose = FALSE)
  
  elapsed <- difftime(Sys.time(), start_time, units = "mins")
  cat("\n  Baseline complete:", round(elapsed, 2), "min\n")
  
  return(species_dir)
}

# =============================================================================
# MONTHLY PREDICTION FUNCTION
# =============================================================================

predict_monthly_species <- function(species_code,
                                    binary_ensemble,
                                    count_ensemble = NULL,
                                    monthly_stacks,
                                    output_dir = output_base) {
  
  species_name <- species_mapping[species_code]
  
  cat("\n-----------------------------------------------------------------------\n")
  cat("  MONTHLY:", species_name, "\n")
  cat("-----------------------------------------------------------------------\n\n")
  
  if (is.null(binary_ensemble)) {
    cat("  ERROR: No binary ensemble\n")
    return(NULL)
  }
  
  species_dir <- file.path(output_dir, "Monthly", species_code)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  start_time <- Sys.time()
  
  for (i in seq_along(month_names)) {
    month <- month_names[i]
    cat("  [", i, "/12] ", month, "\n", sep = "")
    
    month_stack <- monthly_stacks[[month]]
    if (is.null(month_stack)) {
      cat("    WARNING: No stack for", month, "\n")
      next
    }
    
    # Presence (mean and SD only for monthly)
    cat("    Presence: ")
    pres_pred <- predict_ensemble_fast(binary_ensemble, month_stack,
                                       calc_full_uncertainty = FALSE, verbose = FALSE)
    
    if (!is.null(pres_pred)) {
      writeRaster(pres_pred$mean,
                  file.path(species_dir, paste0(species_code, "_", month, "_Presence.tif")),
                  overwrite = TRUE)
      writeRaster(pres_pred$sd,
                  file.path(species_dir, paste0(species_code, "_", month, "_Presence_SD.tif")),
                  overwrite = TRUE)
      cat("mean =", round(cellStats(pres_pred$mean, mean, na.rm = TRUE), 4), "\n")
      rm(pres_pred)
    }
    
    # Abundance
    if (!is.null(count_ensemble)) {
      cat("    Abundance: ")
      abund_pred <- predict_ensemble_fast(count_ensemble, month_stack,
                                          calc_full_uncertainty = FALSE, verbose = FALSE)
      
      if (!is.null(abund_pred)) {
        writeRaster(abund_pred$mean,
                    file.path(species_dir, paste0(species_code, "_", month, "_Abundance.tif")),
                    overwrite = TRUE)
        cat("mean =", round(cellStats(abund_pred$mean, mean, na.rm = TRUE), 2), "\n")
        rm(abund_pred)
      }
    }
    
    gc(verbose = FALSE)
  }
  
  elapsed <- difftime(Sys.time(), start_time, units = "mins")
  cat("\n  Monthly complete:", round(elapsed, 1), "min\n")
  
  return(species_dir)
}

# =============================================================================
# BATCH PROCESSING FUNCTION
# =============================================================================

predict_all_species <- function(binary_ensembles,
                                count_ensembles = NULL,
                                species_list,
                                average_stack,
                                monthly_stacks = NULL,
                                output_dir = output_base,
                                do_baseline = TRUE,
                                do_monthly = TRUE) {
  
  cat("\n=======================================================================\n")
  cat("  BATCH PREDICTIONS - ALL SPECIES\n")
  cat("=======================================================================\n\n")
  
  cat("Species:", length(species_list), "\n")
  cat("Baseline:", do_baseline, "\n")
  cat("Monthly:", do_monthly, "\n\n")
  
  start_time <- Sys.time()
  
  results <- list()
  
  for (i in seq_along(species_list)) {
    sp <- species_list[i]
    
    cat("\n***************************************************************\n")
    cat("  SPECIES", i, "/", length(species_list), ":", species_mapping[sp], "\n")
    cat("***************************************************************\n")
    
    binary_ens <- binary_ensembles[[sp]]
    count_ens <- if (!is.null(count_ensembles)) count_ensembles[[sp]] else NULL
    
    if (is.null(binary_ens)) {
      cat("  No binary ensemble - skipping\n")
      next
    }
    
    result <- list(species = sp)
    
    if (do_baseline) {
      result$baseline <- predict_baseline_species(
        species_code = sp,
        binary_ensemble = binary_ens,
        count_ensemble = count_ens,
        average_stack = average_stack,
        output_dir = output_dir
      )
    }
    
    if (do_monthly && !is.null(monthly_stacks)) {
      result$monthly <- predict_monthly_species(
        species_code = sp,
        binary_ensemble = binary_ens,
        count_ensemble = count_ens,
        monthly_stacks = monthly_stacks,
        output_dir = output_dir
      )
    }
    
    results[[sp]] <- result
    gc(verbose = FALSE)
  }
  
  elapsed <- difftime(Sys.time(), start_time, units = "mins")
  
  cat("\n=======================================================================\n")
  cat("  ALL PREDICTIONS COMPLETE\n")
  cat("=======================================================================\n\n")
  
  cat("Total time:", round(elapsed, 1), "minutes\n")
  cat("Average per species:", round(elapsed / length(species_list), 1), "minutes\n\n")
  
  return(results)
}


# Run all predictions
results <- predict_all_species(
  binary_ensembles = BRT_Bootstrap_Binary,
  count_ensembles = BRT_Bootstrap_Count,
  species_list = c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc"),
  average_stack = AverageStack,
  monthly_stacks = MonthlyStacks,
  do_baseline = TRUE,
  do_monthly = TRUE
)


```



```{r Code for HTML Maps}
# =============================================================================
# INTERACTIVE LEAFLET MAPS WITH ZONAL STATISTICS
# =============================================================================

library(raster)
library(terra)
library(sf)
library(exactextractr)
library(leaflet)
library(leaflet.extras)
library(htmltools)
library(htmlwidgets)
library(viridis)
library(dplyr)

# =============================================================================
# CONFIGURATION
# =============================================================================

prediction_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"
output_dir <- file.path(prediction_base, "Interactive_Maps")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

species_mapping <- c(
  "Aedes_aegypti" = "Aeae",
  "Aedes_albopictus" = "Aealb",
  "Aedes_mediovittatus" = "Aem",
  "Culex_nigripalpus" = "Cxn",
  "Culex_quinquefasciatus" = "Quinx",
  "Psorophora_columbiae" = "Psc"
)

# =============================================================================
# CUSTOM LEGEND FUNCTION
# =============================================================================

create_legend <- function(title = "Value", 
                          min_val = 0, 
                          max_val = 1,
                          n_breaks = 5,
                          decimals = 2) {
  
  colors <- viridis::plasma(100)
  gradient_colors <- paste(colors, collapse = ", ")
  
  # Generate breaks with consistent formatting
 breaks <- seq(min_val, max_val, length.out = n_breaks)
  breaks_formatted <- sprintf(paste0("%.", decimals, "f"), breaks)
  
  legend_html <- tags$div(
    class = "info legend",
    style = "padding: 6px 8px; background: rgba(255,255,255,0.9);
             border-radius: 5px; box-shadow: 0 0 15px rgba(0,0,0,0.2);
             font: 12px/1.4 Arial, sans-serif; color: #555;",
    
    # Title
    tags$div(
      style = "text-align: center; margin-bottom: 5px; font-weight: bold;",
      HTML(title)
    ),
    
    # Legend body
    tags$div(
      style = "display: flex; align-items: center; justify-content: center;",
      
      # Gradient (bottom to top = low to high)
      tags$div(
        style = paste0(
          "width: 18px; height: 90px; ",
          "background: linear-gradient(to top, ", gradient_colors, "); ",
          "margin-right: 5px;"
        )
      ),
      
      # Labels (high to low, top to bottom)
      tags$div(
        style = "display: flex; flex-direction: column; justify-content: space-between; 
                 height: 90px; font-size: 11px;",
        tags$span(breaks_formatted[5]),
        tags$span(breaks_formatted[4]),
        tags$span(breaks_formatted[3]),
        tags$span(breaks_formatted[2]),
        tags$span(breaks_formatted[1])
      )
    )
  )
  
  return(legend_html)
}

# =============================================================================
# EXTRACT BASELINE STATISTICS
# =============================================================================

extract_baseline_stats <- function(species_name, shapefile) {
  
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Baseline", dir_name)
  
  stats_df <- data.frame(
    ADM3_EN = shapefile$ADM3_EN,
    ADM3_PCODE = shapefile$ADM3_PCODE,
    ADM2_EN = shapefile$ADM2_EN,
    ADM1_EN = shapefile$ADM1_EN
  )
  
  # Presence mean
  presence_mean_path <- file.path(species_dir, paste0(dir_name, "_Presence_Mean.tif"))
  r <- rast(presence_mean_path)
  stats_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                          "mean", progress = FALSE)
  
  # Presence SD
  presence_sd_path <- file.path(species_dir, paste0(dir_name, "_Presence_SD.tif"))
  if (file.exists(presence_sd_path)) {
    r <- rast(presence_sd_path)
    stats_df$presence_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                          "mean", progress = FALSE)
  }
  
  # Presence CI
  presence_lower_path <- file.path(species_dir, paste0(dir_name, "_Presence_Lower95.tif"))
  if (file.exists(presence_lower_path)) {
    r <- rast(presence_lower_path)
    stats_df$presence_lower <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                             "mean", progress = FALSE)
  }
  
  presence_upper_path <- file.path(species_dir, paste0(dir_name, "_Presence_Upper95.tif"))
  if (file.exists(presence_upper_path)) {
    r <- rast(presence_upper_path)
    stats_df$presence_upper <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                             "mean", progress = FALSE)
  }
  
  # Abundance
  abundance_mean_path <- file.path(species_dir, paste0(dir_name, "_Abundance_Mean.tif"))
  if (file.exists(abundance_mean_path)) {
    r <- rast(abundance_mean_path)
    stats_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                             "mean", progress = FALSE)
    
    abundance_sd_path <- file.path(species_dir, paste0(dir_name, "_Abundance_SD.tif"))
    if (file.exists(abundance_sd_path)) {
      r <- rast(abundance_sd_path)
      stats_df$abundance_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                             "mean", progress = FALSE)
    }
  }
  
  return(stats_df)
}

# =============================================================================
# EXTRACT MONTHLY STATISTICS
# =============================================================================

extract_monthly_stats <- function(species_name, shapefile) {
  
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Monthly", dir_name)
  
  if (!dir.exists(species_dir)) return(NULL)
  
  monthly_stats <- lapply(month_names, function(month) {
    presence_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Presence.tif"))
    if (!file.exists(presence_path)) return(NULL)
    
    month_df <- data.frame(
      ADM3_EN = shapefile$ADM3_EN,
      ADM3_PCODE = shapefile$ADM3_PCODE,
      ADM2_EN = shapefile$ADM2_EN,
      ADM1_EN = shapefile$ADM1_EN,
      month = month
    )
    
    r <- rast(presence_path)
    month_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
    
    # Abundance if available
    abundance_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Abundance.tif"))
    if (file.exists(abundance_path)) {
      r <- rast(abundance_path)
      month_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                               "mean", progress = FALSE)
    }
    
    return(month_df)
  })
  
  names(monthly_stats) <- month_names
  monthly_stats <- monthly_stats[!sapply(monthly_stats, is.null)]
  
  return(monthly_stats)
}

# =============================================================================
# CREATE INTERACTIVE MAP
# =============================================================================

create_interactive_map <- function(species_name, shapefile, baseline_stats,
                                   monthly_stats, output_path) {
  
  # Join baseline to shapefile
  map_data <- shapefile %>%
    left_join(baseline_stats, by = c("ADM3_EN", "ADM3_PCODE"))
  
  # Global max abundance for consistent scaling
  max_abundance_baseline <- if("abundance_mean" %in% names(map_data)) {
    max(map_data$abundance_mean, na.rm = TRUE)
  } else { 0 }
  
  max_abundance_monthly <- 0
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    monthly_maxes <- sapply(monthly_stats, function(m) {
      if ("abundance_mean" %in% names(m)) max(m$abundance_mean, na.rm = TRUE) else 0
    })
    max_abundance_monthly <- max(monthly_maxes, na.rm = TRUE)
  }
  
  max_abundance_global <- max(max_abundance_baseline, max_abundance_monthly, na.rm = TRUE)
  if (is.infinite(max_abundance_global) || max_abundance_global == 0) {
    max_abundance_global <- 1
  }
  
  # Color palettes
  presence_pal <- colorNumeric("plasma", domain = c(0, 1), na.color = "transparent")
  has_abundance <- "abundance_mean" %in% names(map_data) && !all(is.na(map_data$abundance_mean))
  if (has_abundance) {
    abundance_pal <- colorNumeric("plasma", domain = c(0, max_abundance_global), na.color = "transparent")
  }
  
  # Initialize map
  map <- leaflet(map_data) %>%
    addProviderTiles(providers$CartoDB.Positron, group = "Light") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "Satellite") %>%
    setView(lng = -72.3, lat = 19, zoom = 8)
  
  # Baseline Presence
  map <- map %>%
    addPolygons(
      fillColor = ~presence_pal(presence_mean),
      fillOpacity = 0.7,
      color = "#666666",
      weight = 1,
      opacity = 0.5,
      smoothFactor = 0.5,
      layerId = ~ADM3_PCODE,
      group = "Baseline: Presence",
      highlightOptions = highlightOptions(weight = 2, color = "#333", 
                                          fillOpacity = 0.9, bringToFront = TRUE),
      popup = ~paste0(
        "<div style='font-family: Arial; font-size: 12px;'>",
        "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
        "<span style='color: #666;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
        "<hr style='margin: 5px 0;'/>",
        "<b>Presence Probability:</b> ", sprintf("%.2f", presence_mean),
        if("presence_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", sprintf("%.2f", presence_sd)) else "",
        if("presence_lower" %in% names(map_data)) paste0("<br/><b>95% CI:</b> [", 
           sprintf("%.2f", presence_lower), ", ", sprintf("%.2f", presence_upper), "]") else "",
        "</div>"
      )
    ) %>%
    addControl(
      html = create_legend(title = "Presence<br/>Probability", min_val = 0, max_val = 1, 
                           n_breaks = 5, decimals = 2),
      position = "bottomright",
      className = "legend-presence-baseline"
    )
  
  # Baseline Abundance
  if (has_abundance) {
    map <- map %>%
      addPolygons(
        data = map_data,
        fillColor = ~abundance_pal(abundance_mean),
        fillOpacity = 0.7,
        color = "#666666",
        weight = 1,
        opacity = 0.5,
        smoothFactor = 0.5,
        layerId = ~paste0(ADM3_PCODE, "_abund"),
        group = "Baseline: Abundance",
        highlightOptions = highlightOptions(weight = 2, color = "#333",
                                            fillOpacity = 0.9, bringToFront = TRUE),
        popup = ~paste0(
          "<div style='font-family: Arial; font-size: 12px;'>",
          "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
          "<span style='color: #666;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
          "<hr style='margin: 5px 0;'/>",
          "<b>Expected Abundance:</b> ", sprintf("%.1f", abundance_mean),
          if("abundance_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", sprintf("%.1f", abundance_sd)) else "",
          "</div>"
        )
      )
  }
  
  # Monthly Layers
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    for (month in names(monthly_stats)) {
      month_data <- monthly_stats[[month]]
      month_map_data <- shapefile %>%
        left_join(month_data, by = c("ADM3_EN", "ADM3_PCODE"))
      
      has_monthly_abundance <- "abundance_mean" %in% names(month_map_data)
      
      # Monthly Presence
      map <- map %>%
        addPolygons(
          data = month_map_data,
          fillColor = ~presence_pal(presence_mean),
          fillOpacity = 0.7,
          color = "#666666",
          weight = 1,
          opacity = 0.5,
          smoothFactor = 0.5,
          layerId = ~paste0(ADM3_PCODE, "_", month, "_pres"),
          group = paste0("Monthly Presence: ", month),
          highlightOptions = highlightOptions(weight = 2, color = "#333",
                                              fillOpacity = 0.9, bringToFront = TRUE),
          popup = ~paste0(
            "<div style='font-family: Arial; font-size: 12px;'>",
            "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
            "<span style='color: #666;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
            "<b style='color: #e67e22;'>", month, "</b>",
            "<hr style='margin: 5px 0;'/>",
            "<b>Presence Probability:</b> ", sprintf("%.2f", presence_mean),
            "</div>"
          )
        )
      
      # Monthly Abundance
      if (has_monthly_abundance) {
        map <- map %>%
          addPolygons(
            data = month_map_data,
            fillColor = ~abundance_pal(abundance_mean),
            fillOpacity = 0.7,
            color = "#666666",
            weight = 1,
            opacity = 0.5,
            smoothFactor = 0.5,
            layerId = ~paste0(ADM3_PCODE, "_", month, "_abund"),
            group = paste0("Monthly Abundance: ", month),
            highlightOptions = highlightOptions(weight = 2, color = "#333",
                                                fillOpacity = 0.9, bringToFront = TRUE),
            popup = ~paste0(
              "<div style='font-family: Arial; font-size: 12px;'>",
              "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
              "<span style='color: #666;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
              "<b style='color: #e67e22;'>", month, "</b>",
              "<hr style='margin: 5px 0;'/>",
              "<b>Expected Abundance:</b> ", sprintf("%.1f", abundance_mean),
              "</div>"
            )
          )
      }
    }
  }
  
  # Layer Controls
  base_groups <- c("Baseline: Presence")
  if (has_abundance) base_groups <- c(base_groups, "Baseline: Abundance")
  
  monthly_presence_groups <- paste0("Monthly Presence: ", names(monthly_stats))
  monthly_abundance_groups <- paste0("Monthly Abundance: ", names(monthly_stats))
  all_groups <- c(base_groups, monthly_presence_groups, monthly_abundance_groups)
  
  map <- map %>%
    addLayersControl(
      baseGroups = c("Light", "Satellite"),
      overlayGroups = all_groups,
      options = layersControlOptions(collapsed = FALSE),
      position = "topright"
    ) %>%
    hideGroup(c(monthly_presence_groups, monthly_abundance_groups)) %>%
    hideGroup(if(has_abundance) "Baseline: Abundance" else NULL)
  
  # Title
  species_formatted <- gsub("_", " ", species_name)
  title_control <- tags$div(
    style = "margin: 10px; padding: 12px 20px; background: white;
             border-radius: 5px; box-shadow: 0 2px 6px rgba(0,0,0,0.2);",
    tags$h3(style = "margin: 0; font-size: 18px; font-style: italic;", species_formatted)
  )
  
  map <- map %>% addControl(title_control, position = "topleft")
  
  # Save
  saveWidget(map, output_path, selfcontained = TRUE)
  
  return(map)
}

# =============================================================================
# PROCESS ALL SPECIES
# =============================================================================

cat("\n=== GENERATING INTERACTIVE MAPS ===\n\n")

for (i in seq_along(species_mapping)) {
  species_name <- names(species_mapping)[i]
  cat("[", i, "/", length(species_mapping), "] ", species_name, "...\n", sep = "")
  
  # Extract statistics
  baseline_stats <- extract_baseline_stats(species_name, Haiti_adm3)
  monthly_stats <- extract_monthly_stats(species_name, Haiti_adm3)
  
  # Create map
    output_file <- file.path(output_dir, paste0(species_mapping[species_name], "Map.html"))
  create_interactive_map(
    species_name = species_name,
    shapefile = Haiti_adm3,
    baseline_stats = baseline_stats,
    monthly_stats = monthly_stats,
    output_path = output_file
  )
  
  cat("    Saved:", basename(output_file), "\n")
}

cat("\n=== COMPLETE ===\n")
cat("Output:", output_dir, "\n")
cat("Species processed:", length(species_mapping), "\n")
```



```{r Study-site Prediction Maps}
# =============================================================================
# BASELINE PREDICTION MAPS - STUDY SITES (6 SPECIES)
# =============================================================================
# Generates 4 figures:
#   1. Presence Probability (Mean)
#   2. Presence Probability (SD)
#   3. Expected Abundance (Mean)
#   4. Expected Abundance (SD)
# =============================================================================
library(terra)
library(sf)
library(ggplot2)
library(viridis)
library(patchwork)
sf_use_s2(FALSE)
# Configuration
prediction_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"
species_info <- list(
  Aeae  = list(dir = "Aeae",  label = "Aedes aegypti"),
  Aealb = list(dir = "Aealb", label = "Aedes albopictus"),
  Aem   = list(dir = "Aem",   label = "Aedes mediovittatus"),
  Cxn   = list(dir = "Cxn",   label = "Culex nigripalpus"),
  Quinx = list(dir = "Quinx", label = "Culex quinquefasciatus"),
  Psc   = list(dir = "Psc",   label = "Psorophora columbiae")
)
# Spatial setup
study_area <- vect(adm2_flagged)
study_area_buffered <- buffer(study_area, width = 1000)
# =============================================================================
# HELPER FUNCTIONS
# =============================================================================
load_and_process_raster <- function(species_dir, file_suffix) {
  raster_path <- file.path(prediction_base, "Baseline", species_dir,
                           paste0(species_dir, file_suffix))
  if (!file.exists(raster_path)) return(NULL)
  r <- rast(raster_path)
  r_crop <- crop(r, study_area_buffered)
  # Fill edge gaps
r_filled <- focal(r_crop, w = 3, fun = "mean", na.policy = "only", na.rm = TRUE)
  r_filled <- focal(r_filled, w = 5, fun = "mean", na.policy = "only", na.rm = TRUE)
  mask(r_filled, study_area)
}
raster_to_df <- function(r) {
  if (is.null(r)) return(NULL)
  as.data.frame(r, xy = TRUE, na.rm = TRUE)
}
make_panel <- function(df, species_label, max_val, legend_title, show_legend = FALSE) {
  if (is.null(df) || nrow(df) == 0) {
    return(ggplot() + annotate("text", x = 0.5, y = 0.5, label = "No data") + theme_void())
  }
  val_col <- names(df)[3]
  ggplot() +
    geom_raster(data = df, aes(x = x, y = y, fill = .data[[val_col]])) +
    geom_sf(data = adm2_flagged, fill = NA, color = "white", linewidth = 0.8) +
    geom_sf(data = adm2_flagged, fill = NA, color = "black", linewidth = 0.5) +
    scale_fill_viridis_c(option = "plasma", limits = c(0, max_val), name = legend_title) +
    coord_sf(expand = FALSE) +
    theme_minimal() +
    theme(
      axis.text = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      panel.grid = element_blank(),
      plot.title = element_text(face = "italic", size = 10, hjust = 0.5),
      legend.position = if(show_legend) "right" else "none",
      panel.background = element_rect(fill = "white", color = NA)
    ) +
    labs(title = species_label)
}
build_6panel_figure <- function(panels, fig_title) {
  (panels$Aeae | panels$Aealb | panels$Aem) /
  (panels$Cxn | panels$Quinx | panels$Psc) +
    plot_annotation(
      title = fig_title,
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
}
# =============================================================================
# LOAD ALL RASTERS
# =============================================================================
cat("Loading rasters...\n")
rasters <- list(
  presence_mean = list(),
  presence_sd = list(),
  abundance_mean = list(),
  abundance_sd = list()
)
for (sp in names(species_info)) {
  cat("  ", species_info[[sp]]$label, "\n")
  rasters$presence_mean[[sp]] <- load_and_process_raster(species_info[[sp]]$dir, "_Presence_Mean.tif")
  rasters$presence_sd[[sp]] <- load_and_process_raster(species_info[[sp]]$dir, "_Presence_SD.tif")
  rasters$abundance_mean[[sp]] <- load_and_process_raster(species_info[[sp]]$dir, "_Abundance_Mean.tif")
  rasters$abundance_sd[[sp]] <- load_and_process_raster(species_info[[sp]]$dir, "_Abundance_SD.tif")
}
# Calculate global max values for consistent scaling
get_global_max <- function(raster_list) {
  max(sapply(raster_list, function(r) {
    if (is.null(r)) return(0)
    max(values(r), na.rm = TRUE)
  }), na.rm = TRUE)
}
max_presence_sd <- get_global_max(rasters$presence_sd)
max_abundance_mean <- get_global_max(rasters$abundance_mean)
max_abundance_sd <- get_global_max(rasters$abundance_sd)
cat("Max values - Presence SD:", round(max_presence_sd, 3),
    "| Abundance Mean:", round(max_abundance_mean, 2),
    "| Abundance SD:", round(max_abundance_sd, 2), "\n")
# =============================================================================
# FIGURE 1: PRESENCE PROBABILITY (MEAN)
# =============================================================================
cat("\nGenerating Presence Mean figure...\n")
panels_pres_mean <- lapply(names(species_info), function(sp) {
  df <- raster_to_df(rasters$presence_mean[[sp]])
  make_panel(df, species_info[[sp]]$label, max_val = 1,
             legend_title = "Presence\nProbability", show_legend = (sp == "Psc"))
})
names(panels_pres_mean) <- names(species_info)
fig_presence_mean <- build_6panel_figure(panels_pres_mean,
                                          "Baseline Presence Probability - Study Sites")
print(fig_presence_mean)
# =============================================================================
# FIGURE 2: PRESENCE PROBABILITY (SD)
# =============================================================================
cat("Generating Presence SD figure...\n")
panels_pres_sd <- lapply(names(species_info), function(sp) {
  df <- raster_to_df(rasters$presence_sd[[sp]])
  make_panel(df, species_info[[sp]]$label, max_val = max_presence_sd,
             legend_title = "Presence\nSD", show_legend = (sp == "Psc"))
})
names(panels_pres_sd) <- names(species_info)
fig_presence_sd <- build_6panel_figure(panels_pres_sd,
                                        "Baseline Presence Probability Uncertainty (SD) - Study Sites")
print(fig_presence_sd)
# =============================================================================
# FIGURE 3: EXPECTED ABUNDANCE (MEAN)
# =============================================================================
cat("Generating Abundance Mean figure...\n")
panels_abund_mean <- lapply(names(species_info), function(sp) {
  df <- raster_to_df(rasters$abundance_mean[[sp]])
  make_panel(df, species_info[[sp]]$label, max_val = max_abundance_mean,
             legend_title = "Expected\nAbundance", show_legend = (sp == "Psc"))
})
names(panels_abund_mean) <- names(species_info)
fig_abundance_mean <- build_6panel_figure(panels_abund_mean,
                                           "Baseline Expected Abundance - Study Sites")
print(fig_abundance_mean)
# =============================================================================
# FIGURE 4: EXPECTED ABUNDANCE (SD)
# =============================================================================
cat("Generating Abundance SD figure...\n")
panels_abund_sd <- lapply(names(species_info), function(sp) {
  df <- raster_to_df(rasters$abundance_sd[[sp]])
  make_panel(df, species_info[[sp]]$label, max_val = max_abundance_sd,
             legend_title = "Abundance\nSD", show_legend = (sp == "Psc"))
})
names(panels_abund_sd) <- names(species_info)
fig_abundance_sd <- build_6panel_figure(panels_abund_sd,
                                         "Baseline Expected Abundance Uncertainty (SD) - Study Sites")
print(fig_abundance_sd)
cat("\n=== All figures generated ===\n")
```



```{r BRT Plots}

# =============================================================================
# AVERAGED PARTIAL DEPENDENCY PLOTS FROM BOOTSTRAP BRT ENSEMBLES
# =============================================================================
# Creates consensus partial dependency plots averaged across 100 bootstrap models
# Separate plots for each species, model type (presence/abundance), and variable
# Uses plasma color scheme with different colors per variable
# =============================================================================

library(dismo)
library(gbm)
library(ggplot2)
library(viridis)
library(dplyr)
library(purrr)

cat("\n=======================================================================\n")
cat("  PARTIAL DEPENDENCY PLOT GENERATION\n")
cat("=======================================================================\n\n")

# Configuration
output_dir <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Figures/PDPlots"
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

# Variable mapping (requested names -> actual covariate names)
variable_mapping <- c(
  "Built Area" = "LC_built",
  "Cropland" = "LC_cropland",
  "Elevation" = "Elevation",
  "Precipitation" = "Precip",
  "Shrub Cover" = "LC_shrubs",
  "Temperature" = "TMean",
  "Wind Speed" = "WindMean"
)

# Species mapping (FIXED)
species_mapping <- c(
  "Aeae" = "Aedes aegypti",
  "Aealb" = "Aedes albopictus",
  "Quinx" = "Culex quinquefasciatus",
  "Aem" = "Aedes mediovittatus",
  "Cxn" = "Culex nigripalpus",
  "Psc" = "Psorophora columbiae"
)

# Assign colors from plasma palette
plasma_colors <- viridis::plasma(length(variable_mapping))
names(plasma_colors) <- names(variable_mapping)

cat("Output directory:", output_dir, "\n")
cat("Variables to plot:", length(variable_mapping), "\n\n")

# =============================================================================
# FUNCTION: Extract partial dependency data from single model
# =============================================================================

extract_pdp_single_model <- function(model, variable_name, n_points = 100) {
  
  var_idx <- which(model$gbm.call$predictor.names == variable_name)
  
  if (length(var_idx) == 0) {
    return(NULL)
  }
  
  data_used <- model$gbm.call$dataframe
  var_range <- range(data_used[[variable_name]], na.rm = TRUE)
  
  var_seq <- seq(var_range[1], var_range[2], length.out = n_points)
  
  pd_pred <- plot.gbm(
    model,
    i.var = var_idx,
    n.trees = model$gbm.call$best.trees,
    continuous.resolution = n_points,
    return.grid = TRUE,
    type = "response"
  )
  
  result <- data.frame(
    x = pd_pred[[1]],
    y = pd_pred$y
  )
  
  return(result)
}

# =============================================================================
# FUNCTION: Average partial dependency across bootstrap ensemble
# =============================================================================

extract_pdp_ensemble <- function(bootstrap_ensemble, variable_name, 
                                 n_points = 100, verbose = TRUE) {
  
  if (is.null(bootstrap_ensemble)) {
    if (verbose) cat("    No ensemble available\n")
    return(NULL)
  }
  
  models <- bootstrap_ensemble$models
  covariates <- bootstrap_ensemble$covariates
  
  actual_var_name <- variable_mapping[variable_name]
  
  if (!actual_var_name %in% covariates) {
    if (verbose) cat("    Variable not in model:", variable_name, "\n")
    return(NULL)
  }
  
  if (verbose) cat("    Extracting PDP for", variable_name, "...")
  
  pdp_list <- lapply(models, function(m) {
    tryCatch(
      extract_pdp_single_model(m, actual_var_name, n_points),
      error = function(e) NULL
    )
  })
  
  pdp_list <- pdp_list[!sapply(pdp_list, is.null)]
  
  if (length(pdp_list) == 0) {
    if (verbose) cat(" FAILED\n")
    return(NULL)
  }
  
  all_x <- unlist(lapply(pdp_list, function(df) df$x))
  x_range <- range(all_x, na.rm = TRUE)
  x_common <- seq(x_range[1], x_range[2], length.out = n_points)
  
  y_matrix <- sapply(pdp_list, function(df) {
    approx(df$x, df$y, xout = x_common, rule = 2)$y
  })
  
  y_mean <- rowMeans(y_matrix, na.rm = TRUE)
  y_sd <- apply(y_matrix, 1, sd, na.rm = TRUE)
  y_lower <- apply(y_matrix, 1, quantile, probs = 0.025, na.rm = TRUE)
  y_upper <- apply(y_matrix, 1, quantile, probs = 0.975, na.rm = TRUE)
  
  result <- data.frame(
    x = x_common,
    y_mean = y_mean,
    y_sd = y_sd,
    y_lower = y_lower,
    y_upper = y_upper,
    n_models = ncol(y_matrix)
  )
  
  if (verbose) cat(" ", ncol(y_matrix), "models\n")
  
  return(result)
}

# =============================================================================
# FUNCTION: Create partial dependency plot
# =============================================================================

create_pdp_plot <- function(pdp_data, variable_name, species_name, 
                           model_type, color) {
  
  if (is.null(pdp_data)) {
    return(NULL)
  }
  
  y_label <- if (model_type == "Presence") {
    "Probability of Presence"
  } else {
    "Expected Abundance"
  }
  
  species_formatted <- gsub("_", " ", species_name)
  
  p <- ggplot(pdp_data, aes(x = x, y = y_mean)) +
    geom_ribbon(aes(ymin = y_lower, ymax = y_upper),
                fill = color, alpha = 0.2) +
    geom_line(color = color, size = 1.2) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(face = "italic", size = 14, hjust = 0.5),
      panel.grid.minor = element_blank(),
      axis.title = element_text(size = 11),
      axis.text = element_text(size = 10)
    ) +
    labs(
      title = species_formatted,
      x = variable_name,
      y = y_label
    )
  
  return(p)
}

# =============================================================================
# FUNCTION: Process all variables for one species/model combination
# =============================================================================

process_species_model <- function(species_code, model_type,
                                  bootstrap_ensemble,
                                  output_dir) {
  
  species_name <- species_mapping[species_code]
  
  cat("\n", species_name, " - ", model_type, "\n", sep = "")
  cat("  ", strrep("-", nchar(species_name) + nchar(model_type) + 3), "\n", sep = "")
  
  if (is.null(bootstrap_ensemble)) {
    cat("  No ensemble available - skipping\n")
    return(NULL)
  }
  
  species_dir <- file.path(output_dir, species_code, model_type)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  for (var_name in names(variable_mapping)) {
    
    pdp_data <- extract_pdp_ensemble(
      bootstrap_ensemble, 
      var_name,
      n_points = 100,
      verbose = TRUE
    )
    
    if (!is.null(pdp_data)) {
      plot_obj <- create_pdp_plot(
        pdp_data,
        variable_name = var_name,
        species_name = species_name,
        model_type = model_type,
        color = plasma_colors[var_name]
      )
      
      filename <- file.path(
        species_dir,
        paste0(species_code, "_", model_type, "_", 
               gsub(" ", "_", var_name), ".png")
      )
      
      ggsave(
        filename,
        plot = plot_obj,
        width = 6,
        height = 5,
        dpi = 300,
        bg = "white"
      )
      
      data_filename <- file.path(
        species_dir,
        paste0(species_code, "_", model_type, "_", 
               gsub(" ", "_", var_name), "_data.csv")
      )
      
      write.csv(pdp_data, data_filename, row.names = FALSE)
    }
  }
  
  cat("\n")
}

# =============================================================================
# FUNCTION: Create combined multi-panel plot for one species
# =============================================================================

create_combined_pdp_plot <- function(species_code, model_type,
                                     bootstrap_ensemble,
                                     output_dir) {
  
  species_name <- species_mapping[species_code]
  
  if (is.null(bootstrap_ensemble)) {
    return(NULL)
  }
  
  pdp_list <- list()
  
  for (var_name in names(variable_mapping)) {
    pdp_data <- extract_pdp_ensemble(
      bootstrap_ensemble,
      var_name,
      n_points = 100,
      verbose = FALSE
    )
    
    if (!is.null(pdp_data)) {
      pdp_data$variable <- var_name
      pdp_data$color <- plasma_colors[var_name]
      pdp_list[[var_name]] <- pdp_data
    }
  }
  
  if (length(pdp_list) == 0) {
    return(NULL)
  }
  
  pdp_combined <- bind_rows(pdp_list)
  
  y_label <- if (model_type == "Presence") {
    "Probability of Presence"
  } else {
    "Expected Abundance"
  }
  
  species_formatted <- gsub("_", " ", species_name)
  
  p <- ggplot(pdp_combined, aes(x = x, y = y_mean)) +
    geom_ribbon(aes(ymin = y_lower, ymax = y_upper, fill = variable),
                alpha = 0.2) +
    geom_line(aes(color = variable), size = 1) +
    facet_wrap(~variable, scales = "free_x", ncol = 3) +
    scale_color_manual(values = plasma_colors) +
    scale_fill_manual(values = plasma_colors) +
    theme_minimal(base_size = 11) +
    theme(
      plot.title = element_text(face = "italic", size = 14, hjust = 0.5),
      strip.text = element_text(size = 10, face = "bold"),
      legend.position = "none",
      panel.grid.minor = element_blank()
    ) +
    labs(
      title = paste(species_formatted, "-", model_type),
      x = "Covariate Value",
      y = y_label
    )
  
  return(p)
}

# =============================================================================
# BATCH PROCESSING: All species and model types
# =============================================================================

cat("=======================================================================\n")
cat("PROCESSING ALL SPECIES AND MODEL TYPES\n")
cat("=======================================================================\n")

species_list <- c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc")

total_start <- Sys.time()

for (species_code in species_list) {
  
  cat("\n***********************************************************************\n")
  cat("SPECIES:", species_mapping[species_code], "\n")
  cat("***********************************************************************\n")
  
  if (!is.null(BRT_Bootstrap_Binary[[species_code]])) {
    process_species_model(
      species_code = species_code,
      model_type = "Presence",
      bootstrap_ensemble = BRT_Bootstrap_Binary[[species_code]],
      output_dir = output_dir
    )
    
    combined_plot <- create_combined_pdp_plot(
      species_code = species_code,
      model_type = "Presence",
      bootstrap_ensemble = BRT_Bootstrap_Binary[[species_code]],
      output_dir = output_dir
    )
    
    if (!is.null(combined_plot)) {
      combined_filename <- file.path(
        output_dir,
        species_code,
        paste0(species_code, "_Presence_Combined.png")
      )
      
      ggsave(
        combined_filename,
        plot = combined_plot,
        width = 12,
        height = 8,
        dpi = 300,
        bg = "white"
      )
      
      cat("  Combined presence plot saved\n")
    }
  }
  
  if (!is.null(BRT_Bootstrap_Count[[species_code]])) {
    process_species_model(
      species_code = species_code,
      model_type = "Abundance",
      bootstrap_ensemble = BRT_Bootstrap_Count[[species_code]],
      output_dir = output_dir
    )
    
    combined_plot <- create_combined_pdp_plot(
      species_code = species_code,
      model_type = "Abundance",
      bootstrap_ensemble = BRT_Bootstrap_Count[[species_code]],
      output_dir = output_dir
    )
    
    if (!is.null(combined_plot)) {
      combined_filename <- file.path(
        output_dir,
        species_code,
        paste0(species_code, "_Abundance_Combined.png")
      )
      
      ggsave(
        combined_filename,
        plot = combined_plot,
        width = 12,
        height = 8,
        dpi = 300,
        bg = "white"
      )
      
      cat("  Combined abundance plot saved\n")
    }
  }
}

total_elapsed <- difftime(Sys.time(), total_start, units = "mins")

cat("\n=======================================================================\n")
cat("PARTIAL DEPENDENCY PLOT GENERATION COMPLETE\n")
cat("=======================================================================\n\n")



```



```{r Monthly BRT stats}

# =============================================================================
# SPATIAL STATISTICS EXTRACTION - BASELINE AND MONTHLY PREDICTIONS
# =============================================================================

library(terra)
library(dplyr)
library(tidyr)

# Configuration
prediction_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"

species_info <- data.frame(
  species_code = c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc"),
  species_name = c("Aedes_aegypti", "Aedes_albopictus", "Culex_quinquefasciatus",
                   "Aedes_mediovittatus", "Culex_nigripalpus", "Psorophora_columbiae"),
  stringsAsFactors = FALSE
)

month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

# =============================================================================
# HELPER FUNCTION - EXTRACT SPATIAL STATISTICS
# =============================================================================

extract_spatial_stats <- function(raster_path) {
  if (!file.exists(raster_path)) {
    return(data.frame(mean = NA, median = NA, sd = NA))
  }
  
  r <- rast(raster_path)
  vals <- values(r, na.rm = TRUE)
  
  data.frame(
    mean = mean(vals, na.rm = TRUE),
    median = median(vals, na.rm = TRUE),
    sd = sd(vals, na.rm = TRUE)
  )
}

# =============================================================================
# EXTRACT BASELINE STATISTICS
# =============================================================================

extract_baseline_stats <- function(species_code, metric_type) {
  
  file_suffix <- switch(metric_type,
                       "presence" = "_Presence_Mean.tif",
                       "abundance" = "_Abundance_Mean.tif")
  
  raster_path <- file.path(prediction_base, "Baseline", species_code,
                           paste0(species_code, file_suffix))
  
  stats <- extract_spatial_stats(raster_path)
  stats$species_code <- species_code
  stats$period <- "Baseline"
  stats$metric <- metric_type
  
  return(stats)
}

# =============================================================================
# EXTRACT MONTHLY STATISTICS
# =============================================================================

extract_monthly_stats <- function(species_code, month, metric_type) {
  
  file_suffix <- switch(metric_type,
                       "presence" = paste0("_", month, "_Presence.tif"),
                       "abundance" = paste0("_", month, "_Abundance.tif"))
  
  raster_path <- file.path(prediction_base, "Monthly", species_code,
                           paste0(species_code, file_suffix))
  
  stats <- extract_spatial_stats(raster_path)
  stats$species_code <- species_code
  stats$period <- month
  stats$metric <- metric_type
  
  return(stats)
}

# =============================================================================
# COMPILE ALL STATISTICS
# =============================================================================

cat("Extracting spatial statistics...\n")

all_stats <- lapply(species_info$species_code, function(sp) {
  
  # Baseline presence
  baseline_pres <- extract_baseline_stats(sp, "presence")
  
  # Baseline abundance
  baseline_abund <- extract_baseline_stats(sp, "abundance")
  
  # Monthly presence
  monthly_pres <- lapply(month_names, function(m) {
    extract_monthly_stats(sp, m, "presence")
  })
  monthly_pres <- do.call(rbind, monthly_pres)
  
  # Monthly abundance
  monthly_abund <- lapply(month_names, function(m) {
    extract_monthly_stats(sp, m, "abundance")
  })
  monthly_abund <- do.call(rbind, monthly_abund)
  
  rbind(baseline_pres, baseline_abund, monthly_pres, monthly_abund)
})

stats_table <- do.call(rbind, all_stats)

# Add species names
stats_table <- stats_table %>%
  left_join(species_info, by = "species_code") %>%
  dplyr::select(species_name, species_code, period, metric, mean, median, sd)

# =============================================================================
# CREATE WIDE FORMAT TABLES (EASIER TO READ)
# =============================================================================

# Presence table
presence_wide <- stats_table %>%
  filter(metric == "presence") %>%
  dplyr::select(-metric) %>%
  pivot_wider(
    names_from = period,
    values_from = c(mean, median, sd),
    names_glue = "{period}_{.value}"
  ) %>%
  dplyr::select(species_name, species_code,
                Baseline_mean, Baseline_median, Baseline_sd,
                everything())

# Abundance table
abundance_wide <- stats_table %>%
  filter(metric == "abundance") %>%
  dplyr::select(-metric) %>%
  pivot_wider(
    names_from = period,
    values_from = c(mean, median, sd),
    names_glue = "{period}_{.value}"
  ) %>%
  dplyr::select(species_name, species_code,
                Baseline_mean, Baseline_median, Baseline_sd,
                everything())

# =============================================================================
# SAVE OUTPUTS
# =============================================================================

output_dir <- file.path(prediction_base, "Summary_Statistics")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

# Long format (all data in one table)
write.csv(stats_table, 
          file.path(output_dir, "Spatial_Statistics_Long.csv"),
          row.names = FALSE)

# Wide format - Presence
write.csv(presence_wide,
          file.path(output_dir, "Spatial_Statistics_Presence.csv"),
          row.names = FALSE)

# Wide format - Abundance
write.csv(abundance_wide,
          file.path(output_dir, "Spatial_Statistics_Abundance.csv"),
          row.names = FALSE)

cat("\nSummary statistics saved to:", output_dir, "\n")
cat("  - Spatial_Statistics_Long.csv (all data)\n")
cat("  - Spatial_Statistics_Presence.csv (wide format)\n")
cat("  - Spatial_Statistics_Abundance.csv (wide format)\n")

# =============================================================================
# PREVIEW RESULTS
# =============================================================================

cat("\nPresence Statistics Preview (Baseline):\n")
print(stats_table %>% 
        filter(metric == "presence", period == "Baseline") %>%
        dplyr::select(species_name, mean, median, sd),
      row.names = FALSE)

cat("\nAbundance Statistics Preview (Baseline):\n")
print(stats_table %>% 
        filter(metric == "abundance", period == "Baseline") %>%
        dplyr::select(species_name, mean, median, sd),
      row.names = FALSE)

```



```{r Comprehensive Summary Table for All Species}

# =============================================================================
# COMPREHENSIVE SUMMARY STATISTICS TABLE
# All Six Species by Trap Type and Overall Study Period
# =============================================================================

library(dplyr)
library(tidyr)
library(kableExtra)

# Species configuration
species_list <- c("Quinx", "Aeae", "Aealb", "Aem", "Cxn", "Psc")
species_names <- c(
  "Culex quinquefasciatus",
  "Aedes aegypti", 
  "Aedes albopictus",
  "Aedes mediovittatus",
  "Culex nigripalpus",
  "Psorophora columbiae"
)

# =============================================================================
# Calculate summary statistics for each species
# =============================================================================

calculate_species_summary <- function(species_col, trap_type_col = "Trap_Type") {
  
  # By trap type
  by_trap <- HCM_Full_Aeae %>%
    group_by(Trap_Type = !!sym(trap_type_col)) %>%
    summarise(
      Total = sum(!!sym(species_col), na.rm = TRUE),
      Mean = mean(!!sym(species_col), na.rm = TRUE),
      Median = median(!!sym(species_col), na.rm = TRUE),
      SD = sd(!!sym(species_col), na.rm = TRUE),
      .groups = "drop"
    )
  
  # Overall (all trap types combined)
  overall <- HCM_Full_Aeae %>%
    summarise(
      Trap_Type = "All Traps",
      Total = sum(!!sym(species_col), na.rm = TRUE),
      Mean = mean(!!sym(species_col), na.rm = TRUE),
      Median = median(!!sym(species_col), na.rm = TRUE),
      SD = sd(!!sym(species_col), na.rm = TRUE)
    )
  
  # Combine
  bind_rows(by_trap, overall)
}

# Generate summary for each species
summary_list <- list()

for (i in seq_along(species_list)) {
  species <- species_list[i]
  species_name <- species_names[i]
  
  summary_stats <- calculate_species_summary(species)
  summary_stats$Species <- species_name
  
  summary_list[[species]] <- summary_stats
}

# Combine all species
all_species_summary <- bind_rows(summary_list) %>%
  dplyr::select(Species, Trap_Type, Total, Mean, Median, SD)

# =============================================================================
# Calculate combined totals across all species
# =============================================================================

# Create total counts column
HCM_Full_Aeae_with_total <- HCM_Full_Aeae %>%
  mutate(Total_All_Species = Quinx + Aeae + Aealb + Aem + Cxn + Psc)

# By trap type
combined_by_trap <- HCM_Full_Aeae_with_total %>%
  group_by(Trap_Type) %>%
  summarise(
    Total = sum(Total_All_Species, na.rm = TRUE),
    Mean = mean(Total_All_Species, na.rm = TRUE),
    Median = median(Total_All_Species, na.rm = TRUE),
    SD = sd(Total_All_Species, na.rm = TRUE),
    .groups = "drop"
  )

# Overall
combined_overall <- HCM_Full_Aeae_with_total %>%
  summarise(
    Trap_Type = "All Traps",
    Total = sum(Total_All_Species, na.rm = TRUE),
    Mean = mean(Total_All_Species, na.rm = TRUE),
    Median = median(Total_All_Species, na.rm = TRUE),
    SD = sd(Total_All_Species, na.rm = TRUE)
  )

combined_summary <- bind_rows(combined_by_trap, combined_overall) %>%
  mutate(Species = "All Species Combined") %>%
  dplyr::select(Species, Trap_Type, Total, Mean, Median, SD)

# Add to main summary
all_species_summary <- bind_rows(all_species_summary, combined_summary)

# =============================================================================
# Format table
# =============================================================================

# Round numeric columns
summary_table_formatted <- all_species_summary %>%
  mutate(
    Mean = round(Mean, 2),
    Median = round(Median, 2),
    SD = round(SD, 2)
  )

# Reorder to put "All Traps" at bottom of each species group
summary_table_formatted <- summary_table_formatted %>%
  arrange(
    factor(Species, levels = c(species_names, "All Species Combined")),
    factor(Trap_Type, levels = c("BG- Sentinel", "CDC Gravid", "CDC LT", "All Traps"))
  )

# =============================================================================
# Create beautiful HTML table
# =============================================================================

html_table <- summary_table_formatted %>%
  kable(
    format = "html",
    escape = FALSE,
    col.names = c("Species", "Trap Type", "Total", "Mean", "Median", "SD"),
    align = c("l", "l", "r", "r", "r", "r"),
    caption = "Table X. Summary Statistics for Mosquito Abundance by Species and Trap Type"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    font_size = 12
  ) %>%
  # Highlight "All Traps" rows
  row_spec(
    which(summary_table_formatted$Trap_Type == "All Traps"),
    bold = TRUE,
    background = "#f0f0f0"
  ) %>%
  # Highlight "All Species Combined" rows
  row_spec(
    which(summary_table_formatted$Species == "All Species Combined"),
    bold = TRUE,
    background = "#e6f3ff"
  ) %>%
  # Format species names in italics
  column_spec(1, italic = TRUE, width = "12em") %>%
  column_spec(2, width = "10em")

# Display the table
html_table

# =============================================================================
# Study-wide summary (console output)
# =============================================================================

cat("\n\nSTUDY-WIDE SUMMARY\n")
cat("==================\n\n")

study_wide <- summary_table_formatted %>%
  filter(Trap_Type == "All Traps")

print(study_wide, n = Inf)

# Calculate percentages
study_wide_pct <- study_wide %>%
  filter(Species != "All Species Combined") %>%
  mutate(
    Percentage = round(100 * Total / sum(Total), 1)
  )

cat("\n\nSpecies Composition:\n")
print(study_wide_pct %>% dplyr::select(Species, Total, Percentage), n = Inf)

cat("\n\nOverall Summary:\n")
cat("  Total observations:", nrow(HCM_Full_Aeae), "\n")
cat("  Total mosquitoes:", sum(HCM_Full_Aeae_with_total$Total_All_Species), "\n")
cat("  Mean per trap event:", round(mean(HCM_Full_Aeae_with_total$Total_All_Species), 2), "\n")

```



```{r Calculate Standard Deviations by Trap Type}

# =============================================================================
# CALCULATE STANDARD DEVIATIONS BY TRAP TYPE
# =============================================================================

library(dplyr)

# Species configuration
species_list <- c("Quinx", "Aeae", "Aealb", "Aem", "Cxn", "Psc")
species_names <- c(
  "Culex quinquefasciatus",
  "Aedes aegypti", 
  "Aedes albopictus",
  "Aedes mediovittatus",
  "Culex nigripalpus",
  "Psorophora columbiae"
)

# Create total column
HCM_Full_Aeae_with_total <- HCM_Full_Aeae %>%
  mutate(Total_All_Species = Quinx + Aeae + Aealb + Aem + Cxn + Psc)

cat("\n=======================================================================\n")
cat("  STANDARD DEVIATIONS BY TRAP TYPE\n")
cat("=======================================================================\n\n")

# =============================================================================
# Calculate SD for each species by trap type
# =============================================================================

sd_results <- list()

for (i in seq_along(species_list)) {
  species <- species_list[i]
  species_name <- species_names[i]
  
  cat(species_name, ":\n")
  
  # By trap type
  trap_sds <- HCM_Full_Aeae %>%
    group_by(Trap_Type) %>%
    summarise(
      SD = sd(!!sym(species), na.rm = TRUE),
      .groups = "drop"
    )
  
  # Print for this species
  for (j in 1:nrow(trap_sds)) {
    cat("  ", trap_sds$Trap_Type[j], ": ", 
        round(trap_sds$SD[j], 2), "\n", sep = "")
  }
  
  # Overall SD
  overall_sd <- sd(HCM_Full_Aeae[[species]], na.rm = TRUE)
  cat("  All Traps: ", round(overall_sd, 2), "\n\n", sep = "")
  
  # Store results
  trap_sds$Species <- species_name
  trap_sds_all <- trap_sds %>%
    add_row(Trap_Type = "All Traps", SD = overall_sd, Species = species_name)
  
  sd_results[[species]] <- trap_sds_all
}

# =============================================================================
# Calculate SD for Total Mosquitoes by trap type
# =============================================================================

cat("All Species Combined (Total Mosquitoes):\n")

total_sds <- HCM_Full_Aeae_with_total %>%
  group_by(Trap_Type) %>%
  summarise(
    SD = sd(Total_All_Species, na.rm = TRUE),
    .groups = "drop"
  )

for (j in 1:nrow(total_sds)) {
  cat("  ", total_sds$Trap_Type[j], ": ", 
      round(total_sds$SD[j], 2), "\n", sep = "")
}

overall_total_sd <- sd(HCM_Full_Aeae_with_total$Total_All_Species, na.rm = TRUE)
cat("  All Traps: ", round(overall_total_sd, 2), "\n\n", sep = "")

total_sds$Species <- "All Species Combined"
total_sds_all <- total_sds %>%
  add_row(Trap_Type = "All Traps", SD = overall_total_sd, 
          Species = "All Species Combined")

sd_results[["Total"]] <- total_sds_all

# =============================================================================
# Combine into single table
# =============================================================================

all_sds <- bind_rows(sd_results) %>%
  dplyr::select(Species, Trap_Type, SD) %>%
  mutate(SD = round(SD, 2))

# Reorder
all_sds <- all_sds %>%
  arrange(
    factor(Species, levels = c(species_names, "All Species Combined")),
    factor(Trap_Type, levels = c("BG- Sentinel", "CDC Gravid", "CDC LT", "All Traps"))
  )

cat("=======================================================================\n")
cat("  COMPLETE STANDARD DEVIATION TABLE\n")
cat("=======================================================================\n\n")

print(all_sds, n = Inf)

# =============================================================================
# Create formatted table matching your layout
# =============================================================================

cat("\n\n=======================================================================\n")
cat("  FORMATTED TABLE (MATCHING YOUR LAYOUT)\n")
cat("=======================================================================\n\n")

# Pivot to wide format for easier viewing
sd_wide <- all_sds %>%
  pivot_wider(names_from = Trap_Type, values_from = SD)

print(sd_wide, n = Inf)

# =============================================================================
# Create CSV output
# =============================================================================

csv_file <- "/mnt/user-data/outputs/standard_deviations_by_trap.csv"
write.csv(all_sds, csv_file, row.names = FALSE)
cat("\n\nCSV saved to:", csv_file, "\n")

# Also save wide format
csv_file_wide <- "/mnt/user-data/outputs/standard_deviations_wide.csv"
write.csv(sd_wide, csv_file_wide, row.names = FALSE)
cat("Wide format CSV saved to:", csv_file_wide, "\n")

# =============================================================================
# Summary statistics about the standard deviations
# =============================================================================

cat("\n\n=======================================================================\n")
cat("  STANDARD DEVIATION SUMMARY\n")
cat("=======================================================================\n\n")

cat("Range of SDs across all species and trap types:\n")
cat("  Minimum:", round(min(all_sds$SD, na.rm = TRUE), 2), "\n")
cat("  Maximum:", round(max(all_sds$SD, na.rm = TRUE), 2), "\n")
cat("  Mean:", round(mean(all_sds$SD, na.rm = TRUE), 2), "\n")
cat("  Median:", round(median(all_sds$SD, na.rm = TRUE), 2), "\n\n")

# Which species/trap combinations have highest variability?
cat("Top 5 highest standard deviations:\n")
top_sds <- all_sds %>%
  arrange(desc(SD)) %>%
  head(5)
print(top_sds, row.names = FALSE)

```





# Old and alternative code; likely requires significant reconfiguring for
# directories and object names

```{r Code for hurdle models}

  # Fit the global hurdle models
    Glob.Hurd.Aeae <- pscl::hurdle(
      Aeae ~ Precip + TMean + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )
  
    Glob.Hurd.Aealb <- hurdle(
      Aealb ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )  
  
    Glob.Hurd.Quinx <- hurdle(
      Quinx ~ Precip + TMean + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Cxq, 
      dist = "negbin"
    )
  
    Glob.Hurd.Cxn <- hurdle(
      Cxn ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Cxn, 
      dist = "negbin"
    )

    Glob.Hurd.Aem <- hurdle(
      Aem ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aem, 
      dist = "negbin"
    )
  
    Glob.Hurd.Psc <- hurdle(
      Psc ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Psc, 
      dist = "negbin"
    )    
      
  # Prepare for dredging
    options(na.action = "na.fail")
  
  # Create a cluster for parallel processing
    cl <- makeCluster(detectCores() - 1)
    clusterEvalQ(cl, {
      library(MuMIn)
      library(countreg)
      library(sp)
      library(parallel)
    })
    
    clusterExport(cl, list("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq", "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc", 
                           "Glob.Hurd.Aeae", "Glob.Hurd.Aealb", "Glob.Hurd.Quinx", "Glob.Hurd.Cxn", "Glob.Hurd.Aem", "Glob.Hurd.Psc"))
  

  # Perform the dredge operation, excluding models with both count_Precip and count_TMean
    Dredge.Aeae <- dredge(Glob.Hurd.Aeae, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Aealb <- dredge(Glob.Hurd.Aealb, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Quinx <- dredge(Glob.Hurd.Quinx, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Cxn <- dredge(Glob.Hurd.Cxn, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Aem <- dredge(Glob.Hurd.Aem, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Psc <- dredge(Glob.Hurd.Psc, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)  
    
  # Stop the cluster after dredging
    stopCluster(cl)
  
  # Reset the NA action to omit missing values
    options(na.action = "na.omit")
  
  # "Best" Aeae Model
    Aeae_Top10 <- get.models(Dredge.Aeae, subset = 1:10)
    View(Aeae_Top10)
  
  # "Best" Aealb Model
    Aealb_Top10 <- get.models(Dredge.Aealb, subset = 1:10)
    View(Aealb_Top10)
  
  # "Best" Quinx Model
    Quinx_Top10 <- get.models(Dredge.Quinx, subset = 1:10)
    View(Quinx_Top10)
  
  # "Best" Cxn Model
    Cxn_Top10 <- get.models(Dredge.Cxn, subset = 1:10)
    View(Cxn_Top10)
  
  # "Best" Aem Model
    Aem_Top10 <- get.models(Dredge.Aem, subset = 1:10)
    View(Aem_Top10)
  
  # "Best" Psc Model
    Psc_Top10 <- get.models(Dredge.Psc, subset = 1:10)
    View(Psc_Top10)
  
  # Extract the "best" model for each species
    Best.Aeae <- get.models(Dredge.Aeae, subset = 1)[[1]]
    Best.Aealb <- get.models(Dredge.Aealb, subset = 1)[[1]]
    Best.Quinx <- get.models(Dredge.Quinx, subset = 1)[[1]]
    Best.Cxn <- get.models(Dredge.Cxn, subset = 1)[[1]]
    Best.Aem <- get.models(Dredge.Aem, subset = 1)[[1]]
    Best.Psc <- get.models(Dredge.Psc, subset = 1)[[1]]
    
  # Summarize the "best" models for each species
    summary(Best.Aeae)
    summary(Best.Aealb)
    summary(Best.Quinx)
    summary(Best.Aem)
    summary(Best.Cxn)
    summary(Best.Psc)


  # Aedes aegypti Model
    Best.Aeae <- pscl::hurdle(
      Aeae ~ Elevation + nightlight + Precip | Elevation + nightlight + Precip, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )

  # Aedes albopictus Model
    Best.Aealb <- pscl::hurdle(
      Aealb ~ Elevation + nightlight + Precip | Elevation + nightlight + TMean, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )

  # Culex quinquefasciatus Model
    Best.Quinx <- pscl::hurdle(
      Quinx ~ TMean | Elevation + nightlight + Precip, 
      data = HCM_Full_Cxq, 
      dist = "negbin"
    )

  # Culex nigripalpus Model
    Best.Cxn <- pscl::hurdle(
      Cxn ~ Precip | Elevation + nightlight + Precip, 
      data = HCM_Full_Cxn, 
      dist = "negbin"
    )    
      
  # Aedes mediovittatus Model
    Best.Aem <- pscl::hurdle(
      Aem ~ Precip | Elevation + nightlight, 
      data = HCM_Full_Aem, 
      dist = "negbin"
    )  
    
  # Psorophora columbiae Model      
    Best.Psc <- pscl::hurdle(
      Psc ~ Elevation + nightlight + TMean | TMean + nightlight + Elevation, 
      data = HCM_Full_Psc, 
      dist = "negbin"
    )  


```



```{r BRT Code w/o landcover}

library(pROC)
library(caret)
library(purrr)
library(dplyr)
library(dismo)
library(gbm)

# ---------------------------
# Variable Configuration
# ---------------------------

# Climate and environmental covariates (NO land cover variables)
covariates <- c("Precip", "TMean", "WindMean", "nightlight", "Elevation")

# Define species and their datasets
species_list <- c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc")
dataset_names <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq",
                   "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")

# ---------------------------
# Function to determine appropriate tree complexity based on sample size
# ---------------------------
get_tree_complexity <- function(n_present) {
  if (n_present < 100) return(2)       # Very limited data
  else if (n_present < 300) return(3)  # Limited data
  else return(5)                        # Sufficient data
}

# ---------------------------
# Verify covariate availability
# ---------------------------
cat("\n========================================")
cat("\n   CHECKING VARIABLE AVAILABILITY")
cat("\n========================================\n")

# Check if all datasets have required covariates
for (dataset_name in dataset_names) {
  df <- get(dataset_name, envir = .GlobalEnv)
  dataset_vars <- names(df)
  
  missing_vars <- setdiff(covariates, dataset_vars)
  
  cat("\n", dataset_name, ":\n", sep = "")
  if (length(missing_vars) == 0) {
    cat("  All required covariates present\n")
  } else {
    cat("  WARNING: Missing variables:", paste(missing_vars, collapse = ", "), "\n")
  }
}

cat("\n")
cat("Using", length(covariates), "covariates for all models:\n")
cat("  ", paste(covariates, collapse = ", "), "\n\n")

# ---------------------------
# Robust fitting function with retry logic
# ---------------------------
fit_binary_brt_adaptive <- function(species, dataset_name, max_attempts = 3) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Binary <- dataset %>%
    mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
    dplyr::select(SpeciesBin, all_of(covariates)) %>%
    na.omit()
  
  n_present <- sum(HCM_Binary$SpeciesBin == 1)
  n_absent <- sum(HCM_Binary$SpeciesBin == 0)
  tree_comp <- get_tree_complexity(n_present)
  
  cat("\n=== Fitting binary model for", species, "===")
  cat("\n    Dataset:", dataset_name)
  cat("\n    N present:", n_present, "| N absent:", n_absent)
  cat("\n    Prevalence:", round(n_present / nrow(HCM_Binary), 3))
  cat("\n    Tree complexity:", tree_comp)
  cat("\n    Covariates:", length(covariates), "\n")
  
  # Check for sufficient data
  if (n_present < 20) {
    cat("    SKIPPED: Insufficient presences (<20)\n")
    return(NULL)
  }
  
  # Try fitting with multiple attempts
  for (attempt in 1:max_attempts) {
    model <- tryCatch({
      gbm.step(
        data = HCM_Binary,
        gbm.x = covariates,
        gbm.y = "SpeciesBin",
        family = "bernoulli",
        tree.complexity = tree_comp,
        learning.rate = 0.01,
        bag.fraction = 0.75,
        silent = FALSE,
        plot.main = FALSE
      )
    }, error = function(e) {
      cat("    Attempt", attempt, "failed:", e$message, "\n")
      return(NULL)
    })
    
    if (!is.null(model)) {
      cat("    SUCCESS on attempt", attempt, "\n")
      # Store covariates used in model for later prediction
      model$covariates_used <- covariates
      return(model)
    }
  }
  
  cat("    FAILED after", max_attempts, "attempts\n")
  return(NULL)
}

# ---------------------------
# Count model fitting function
# ---------------------------
fit_count_brt_adaptive <- function(species, dataset_name, max_attempts = 3) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Count <- dataset %>%
    filter(.data[[species]] >= 1) %>%
    dplyr::select(all_of(species), all_of(covariates)) %>%
    na.omit()
  
  if (nrow(HCM_Count) == 0) {
    cat("\n=== Count model for", species, "===")
    cat("\n    SKIPPED: No presence records\n")
    return(NULL)
  }
  
  if (nrow(HCM_Count) < 20) {
    cat("\n=== Count model for", species, "===")
    cat("\n    SKIPPED: Insufficient observations (<20)\n")
    return(NULL)
  }
  
  n_present <- nrow(HCM_Count)
  tree_comp <- get_tree_complexity(n_present)
  
  cat("\n=== Fitting count model for", species, "===")
  cat("\n    Dataset:", dataset_name)
  cat("\n    N observations:", n_present)
  cat("\n    Count range:", min(HCM_Count[[species]]), "to", max(HCM_Count[[species]]))
  cat("\n    Mean count:", round(mean(HCM_Count[[species]]), 2))
  cat("\n    Tree complexity:", tree_comp)
  cat("\n    Covariates:", length(covariates), "\n")
  
  # Try fitting with multiple learning rates if needed
  learning_rates <- c(0.01, 0.005, 0.001)
  
  for (attempt in 1:max_attempts) {
    lr <- learning_rates[min(attempt, length(learning_rates))]
    cat("    Attempt", attempt, "with learning rate", lr, "\n")
    
    model <- tryCatch({
      gbm.step(
        data = HCM_Count,
        gbm.x = covariates,
        gbm.y = species,
        family = "poisson",
        tree.complexity = tree_comp,
        learning.rate = lr,
        bag.fraction = 0.75,
        silent = FALSE,
        plot.main = FALSE,
        max.trees = 10000,
        n.minobsinnode = 10
      )
    }, error = function(e) {
      cat("    Attempt", attempt, "failed:", e$message, "\n")
      return(NULL)
    })
    
    if (!is.null(model)) {
      cat("    SUCCESS on attempt", attempt, "\n")
      cat("    Final trees:", model$n.trees, "\n")
      # Store covariates used
      model$covariates_used <- covariates
      return(model)
    }
  }
  
  cat("    FAILED after", max_attempts, "attempts\n")
  return(NULL)
}

# ---------------------------
# Safe assessment functions
# ---------------------------
assess_binary_performance_safe <- function(model, species, dataset_name) {
  if (is.null(model)) {
    return(data.frame(
      Species = species,
      N_Covariates = NA,
      AUC = NA,
      Optimal_Threshold = NA,
      Sensitivity = NA,
      Specificity = NA,
      Accuracy = NA,
      Kappa = NA,
      CV_Correlation = NA,
      CV_Deviance = NA,
      Status = "FAILED"
    ))
  }
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Binary <- dataset %>%
    mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
    dplyr::select(SpeciesBin, all_of(covariates)) %>%
    na.omit()
  
  pred_prob <- predict(model, HCM_Binary, n.trees = model$gbm.call$best.trees, type = "response")
  
  roc_obj <- roc(HCM_Binary$SpeciesBin, pred_prob)
  coords_best <- coords(roc_obj, "best", best.method = "youden")
  
  pred_class <- ifelse(pred_prob >= coords_best$threshold, 1, 0)
  cm <- confusionMatrix(factor(pred_class, levels = c(0, 1)), 
                        factor(HCM_Binary$SpeciesBin, levels = c(0, 1)))
  
  data.frame(
    Species = species,
    N_Covariates = length(covariates),
    AUC = as.numeric(auc(roc_obj)),
    Optimal_Threshold = coords_best$threshold,
    Sensitivity = coords_best$sensitivity,
    Specificity = coords_best$specificity,
    Accuracy = cm$overall["Accuracy"],
    Kappa = cm$overall["Kappa"],
    CV_Correlation = model$cv.statistics$correlation.mean,
    CV_Deviance = model$cv.statistics$deviance.mean,
    Status = "SUCCESS"
  )
}

assess_count_performance_safe <- function(model, species, dataset_name) {
  if (is.null(model)) {
    return(data.frame(
      Species = species,
      N_Obs = NA,
      N_Covariates = NA,
      Correlation = NA,
      RMSE = NA,
      MAE = NA,
      CV_Correlation = NA,
      CV_Deviance = NA,
      Status = "FAILED"
    ))
  }
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Count <- dataset %>%
    filter(.data[[species]] >= 1) %>%
    dplyr::select(all_of(species), all_of(covariates)) %>%
    na.omit()
  
  pred_count <- predict(model, HCM_Count, n.trees = model$gbm.call$best.trees, type = "response")
  actual_count <- HCM_Count[[species]]
  
  data.frame(
    Species = species,
    N_Obs = nrow(HCM_Count),
    N_Covariates = length(covariates),
    Correlation = cor(actual_count, pred_count),
    RMSE = sqrt(mean((actual_count - pred_count)^2)),
    MAE = mean(abs(actual_count - pred_count)),
    CV_Correlation = model$cv.statistics$correlation.mean,
    CV_Deviance = model$cv.statistics$deviance.mean,
    Status = "SUCCESS"
  )
}

# ---------------------------
# Fit all models
# ---------------------------
set.seed(1999)

cat("\n========================================")
cat("\n   FITTING BINARY MODELS")
cat("\n========================================\n")

BRT_Binary_models <- map2(species_list, dataset_names, fit_binary_brt_adaptive) %>%
  set_names(species_list)

cat("\n========================================")
cat("\n   FITTING COUNT MODELS")
cat("\n========================================\n")

BRT_Count_models <- map2(species_list, dataset_names, fit_count_brt_adaptive) %>%
  set_names(species_list)

# ---------------------------
# Generate performance tables
# ---------------------------
binary_performance <- pmap_dfr(
  list(BRT_Binary_models, species_list, dataset_names),
  assess_binary_performance_safe
)

count_performance <- pmap_dfr(
  list(BRT_Count_models, species_list, dataset_names),
  assess_count_performance_safe
)

# Sample diagnostics table
sample_diagnostics <- map2_dfr(species_list, dataset_names, function(species, dataset_name) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  data.frame(
    Species = species,
    Total_Obs = nrow(dataset),
    N_Present = sum(dataset[[species]] >= 1),
    N_Absent = sum(dataset[[species]] == 0),
    Prevalence = round(mean(dataset[[species]] >= 1), 3),
    Mean_Count_When_Present = round(mean(dataset[[species]][dataset[[species]] >= 1]), 2)
  )
})

# ---------------------------
# Display results
# ---------------------------
cat("\n========================================")
cat("\n   RESULTS SUMMARY")
cat("\n========================================\n")

cat("\n=== SAMPLE DIAGNOSTICS ===\n")
print(sample_diagnostics, row.names = FALSE)

cat("\n=== BINARY MODEL PERFORMANCE ===\n")
print(binary_performance, row.names = FALSE)

cat("\n=== COUNT MODEL PERFORMANCE ===\n")
print(count_performance, row.names = FALSE)

# Model success summary
cat("\n=== MODEL FITTING SUMMARY ===\n")
binary_success <- sum(!sapply(BRT_Binary_models, is.null))
count_success <- sum(!sapply(BRT_Count_models, is.null))

cat("Binary models successful:", binary_success, "/", length(species_list), "\n")
cat("Count models successful:", count_success, "/", length(species_list), "\n")

if (binary_success < length(species_list)) {
  cat("\nFailed binary models:", 
      paste(species_list[sapply(BRT_Binary_models, is.null)], collapse = ", "), "\n")
}

if (count_success < length(species_list)) {
  cat("Failed count models:", 
      paste(species_list[sapply(BRT_Count_models, is.null)], collapse = ", "), "\n")
}

# ---------------------------
# Variable importance summary
# ---------------------------
cat("\n=== VARIABLE IMPORTANCE ===\n")

for (species in species_list) {
  model <- BRT_Binary_models[[species]]
  if (!is.null(model)) {
    var_imp <- summary(model, plotit = FALSE)
    
    cat("\n", species, ":\n", sep = "")
    var_imp <- var_imp[order(-var_imp$rel.inf), ]
    for (i in 1:nrow(var_imp)) {
      cat(sprintf("  %s: %.2f%%\n", var_imp$var[i], var_imp$rel.inf[i]))
    }
  } else {
    cat("\n", species, ": Model fitting failed\n", sep = "")
  }
}

cat("\n========================================")
cat("\n   MODELING COMPLETE")
cat("\n========================================\n\n")

# Save model objects for predictions
cat("Model objects saved in environment:\n")
cat("  - BRT_Binary_models (list of", length(BRT_Binary_models), "models)\n")
cat("  - BRT_Count_models (list of", length(BRT_Count_models), "models)\n")
cat("  - binary_performance (performance metrics)\n")
cat("  - count_performance (performance metrics)\n\n")

cat("Ready for predictions!\n")

```



```{r Code for new hurdle models}
# ==============================================================================
# HURDLE MODEL FOR SPATIAL PREDICTION - FIXED
# Location-blocked CV for honest performance estimation
# ==============================================================================
library(xgboost)
library(purrr)
library(dplyr)
library(pROC)

# ------------------------------------------------------------------------------
# Configuration
# ------------------------------------------------------------------------------
species_config <- list(
    Aeae  = list(data = "HCM_Full_Aeae",  outcome = "Aeae"),
    Aealb = list(data = "HCM_Full_Aealb", outcome = "Aealb"),
    Cxq   = list(data = "HCM_Full_Cxq",   outcome = "Quinx"),
    Aem   = list(data = "HCM_Full_Aem",   outcome = "Aem"),
    Cxn   = list(data = "HCM_Full_Cxn",   outcome = "Cxn"),
    Psc   = list(data = "HCM_Full_Psc",   outcome = "Psc")
)

model_covariates <- c(
    "Precip", "TMean", "WindMean",
    "nightlight", "Elevation",
    "trees", "shrubs", "cropland", "wetland"
)

# ------------------------------------------------------------------------------
# Hyperparameters
# ------------------------------------------------------------------------------
params_presence <- list(
    objective        = "binary:logistic",
    eval_metric      = "auc",
    max_depth        = 4,
    eta              = 0.02,
    subsample        = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 5,
    lambda           = 1,
    alpha            = 0.1
)

params_abundance <- list(
    objective        = "count:poisson",
    max_depth        = 4,
    eta              = 0.02,
    subsample        = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 5,
    lambda           = 1,
    alpha            = 0.1
)

# ------------------------------------------------------------------------------
# Location-blocked fold creation
# ------------------------------------------------------------------------------
create_location_folds <- function(df, location_col = "Location", n_folds = 5, seed = 42) {
    locations <- unique(df[[location_col]])
    n_locs <- length(locations)
    
    set.seed(seed)
    loc_assignments <- sample(rep(1:n_folds, length.out = n_locs))
    names(loc_assignments) <- locations
    
    folds <- lapply(1:n_folds, function(f) {
        test_locs <- names(loc_assignments)[loc_assignments == f]
        list(
            train = which(!df[[location_col]] %in% test_locs),
            test  = which(df[[location_col]] %in% test_locs)
        )
    })
    
    return(folds)
}

# ------------------------------------------------------------------------------
# Metrics calculation - FIXED
# ------------------------------------------------------------------------------
calc_presence_metrics <- function(actual, predicted_prob) {
    # Check if we have both classes
    if (length(unique(actual)) < 2) {
        return(list(
            auc = NA,
            threshold = NA,
            sensitivity = NA,
            specificity = NA,
            precision = NA,
            f1 = NA,
            valid = FALSE
        ))
    }
    
    tryCatch({
        roc_obj <- roc(actual, predicted_prob, quiet = TRUE)
        auc_val <- as.numeric(auc(roc_obj))
        
        # Optimal threshold via Youden - extract as numeric
        coords_best <- coords(roc_obj, "best", best.method = "youden",
                              ret = c("threshold", "sensitivity", "specificity"))
        
        # Extract values properly (coords returns a data frame)
        threshold_val <- as.numeric(coords_best[1, "threshold"])
        sensitivity_val <- as.numeric(coords_best[1, "sensitivity"])
        specificity_val <- as.numeric(coords_best[1, "specificity"])
        
        # Metrics at optimal threshold
        pred_class <- as.integer(predicted_prob >= threshold_val)
        tp <- sum(actual == 1 & pred_class == 1)
        tn <- sum(actual == 0 & pred_class == 0)
        fp <- sum(actual == 0 & pred_class == 1)
        fn <- sum(actual == 1 & pred_class == 0)
        
        precision <- ifelse(tp + fp > 0, tp / (tp + fp), 0)
        f1 <- ifelse(precision + sensitivity_val > 0,
                     2 * precision * sensitivity_val / (precision + sensitivity_val), 0)
        
        list(
            auc         = auc_val,
            threshold   = threshold_val,
            sensitivity = sensitivity_val,
            specificity = specificity_val,
            precision   = precision,
            f1          = f1,
            valid       = TRUE
        )
    }, error = function(e) {
        list(
            auc = NA,
            threshold = NA,
            sensitivity = NA,
            specificity = NA,
            precision = NA,
            f1 = NA,
            valid = FALSE
        )
    })
}

calc_abundance_metrics <- function(actual, predicted) {
    if (length(actual) < 3) {
        return(list(
            mae = NA,
            rmse = NA,
            correlation = NA,
            rank_cor = NA,
            valid = FALSE
        ))
    }
    
    mae  <- mean(abs(actual - predicted))
    rmse <- sqrt(mean((actual - predicted)^2))
    cor_val <- cor(actual, predicted, use = "complete.obs")
    cor_spearman <- cor(actual, predicted, method = "spearman", use = "complete.obs")
    
    list(
        mae          = mae,
        rmse         = rmse,
        correlation  = cor_val,
        rank_cor     = cor_spearman,
        valid        = TRUE
    )
}

# ------------------------------------------------------------------------------
# Main training function
# ------------------------------------------------------------------------------
train_hurdle_model <- function(species_name, config, covariates) {
    message("\n", strrep("=", 60))
    message("SPECIES: ", species_name)
    message(strrep("=", 60))
    
    tryCatch({
        # Load data
        df <- get(config$data, envir = .GlobalEnv)
        outcome_col <- config$outcome
        
        # Validate columns
        missing <- setdiff(c(covariates, outcome_col, "Location"), names(df))
        if (length(missing) > 0) {
            stop("Missing columns: ", paste(missing, collapse = ", "))
        }
        
        # Prepare matrices
        X <- as.matrix(df[, covariates])
        y <- df[[outcome_col]]
        
        # Remove incomplete cases
        complete_idx <- complete.cases(X, y)
        X <- X[complete_idx, ]
        y <- y[complete_idx]
        df_complete <- df[complete_idx, ]
        
        message("\nData: ", length(y), " obs, ", sum(y == 0), " zeros (",
                round(100 * mean(y == 0), 1), "%)")
        message("Unique locations: ", n_distinct(df_complete$Location))
        
        # Create location-blocked folds
        folds <- create_location_folds(df_complete, "Location", n_folds = 5)
        
        # ======================================================================
        # PRESENCE MODEL - Location-blocked CV
        # ======================================================================
        message("\n--- PRESENCE MODEL ---")
        presence <- as.integer(y > 0)
        
        # Add class weight for imbalance
        params_p <- params_presence
        params_p$scale_pos_weight <- sum(presence == 0) / sum(presence == 1)
        
        # Cross-validation
        cv_metrics_p <- list()
        cv_rounds_p <- numeric(length(folds))
        
        for (i in seq_along(folds)) {
            idx_train <- folds[[i]]$train
            idx_test  <- folds[[i]]$test
            
            # Check if test fold has both classes
            if (length(unique(presence[idx_test])) < 2) {
                message("  Fold ", i, ": Skipping (only one class in test set)")
                cv_rounds_p[i] <- NA
                cv_metrics_p[[i]] <- list(valid = FALSE)
                next
            }
            
            dtrain <- xgb.DMatrix(X[idx_train, ], label = presence[idx_train])
            dtest  <- xgb.DMatrix(X[idx_test, ], label = presence[idx_test])
            
            # Train with early stopping
            fold_model <- xgb.train(
                params    = params_p,
                data      = dtrain,
                nrounds   = 1000,
                evals     = list(test = dtest),
                early_stopping_rounds = 50,
                verbose   = 0
            )
            
            # Extract best iteration
            best_iter <- attr(fold_model, "early_stop")$best_iteration
            if (is.null(best_iter)) {
                best_iter <- fold_model$niter
            }
            cv_rounds_p[i] <- best_iter
            
            # Evaluate
            pred_prob <- predict(fold_model, dtest)
            cv_metrics_p[[i]] <- calc_presence_metrics(presence[idx_test], pred_prob)
        }
        
        # Filter valid folds
        valid_folds_p <- sapply(cv_metrics_p, function(x) isTRUE(x$valid))
        
        if (sum(valid_folds_p) == 0) {
            warning("No valid CV folds for presence model - results unreliable")
            cv_auc <- NA
            cv_auc_sd <- NA
            cv_threshold <- 0.5
            cv_sens <- NA
            cv_spec <- NA
        } else {
            cv_auc <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "auc"), na.rm = TRUE)
            cv_auc_sd <- sd(sapply(cv_metrics_p[valid_folds_p], `[[`, "auc"), na.rm = TRUE)
            cv_threshold <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "threshold"), na.rm = TRUE)
            cv_sens <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "sensitivity"), na.rm = TRUE)
            cv_spec <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "specificity"), na.rm = TRUE)
        }
        
        message("  Valid folds: ", sum(valid_folds_p), "/", length(folds))
        message("  CV AUC: ", round(cv_auc, 4), " ± ", round(cv_auc_sd, 4))
        message("  Optimal threshold: ", round(cv_threshold, 3))
        message("  Sensitivity: ", round(cv_sens, 3), ", Specificity: ", round(cv_spec, 3))
        
        # Train final model on all data
        dtrain_full <- xgb.DMatrix(X, label = presence)
        final_rounds_p <- round(median(cv_rounds_p[!is.na(cv_rounds_p)]))
        
        model_presence <- xgb.train(
            params  = params_p,
            data    = dtrain_full,
            nrounds = final_rounds_p,
            verbose = 0
        )
        
        message("  Final model: ", final_rounds_p, " rounds")
        
        # ======================================================================
        # ABUNDANCE MODEL - Location-blocked CV (positive counts only)
        # ======================================================================
        message("\n--- ABUNDANCE MODEL ---")
        pos_idx <- which(y > 0)
        X_pos <- X[pos_idx, ]
        y_pos <- y[pos_idx]
        df_pos <- df_complete[pos_idx, ]
        
        message("  Positive obs: ", length(y_pos))
        message("  Range: ", min(y_pos), "-", max(y_pos),
                ", Mean: ", round(mean(y_pos), 1),
                ", Var/Mean: ", round(var(y_pos)/mean(y_pos), 1))
        
        # Check for overdispersion
        params_a <- params_abundance
        if (var(y_pos) / mean(y_pos) > 10) {
            message("  High overdispersion - using Tweedie")
            params_a$objective <- "reg:tweedie"
            params_a$tweedie_variance_power <- 1.5
        }
        
        # Create folds for positive data
        folds_pos <- create_location_folds(df_pos, "Location", n_folds = 5)
        
        # Cross-validation
        cv_metrics_a <- list()
        cv_rounds_a <- numeric(length(folds_pos))
        
        for (i in seq_along(folds_pos)) {
            idx_train <- folds_pos[[i]]$train
            idx_test  <- folds_pos[[i]]$test
            
            if (length(idx_test) < 3) {
                message("  Fold ", i, ": Skipping (too few test samples)")
                cv_rounds_a[i] <- NA
                cv_metrics_a[[i]] <- list(valid = FALSE)
                next
            }
            
            dtrain <- xgb.DMatrix(X_pos[idx_train, ], label = y_pos[idx_train])
            dtest  <- xgb.DMatrix(X_pos[idx_test, ], label = y_pos[idx_test])
            
            fold_model <- xgb.train(
                params    = params_a,
                data      = dtrain,
                nrounds   = 1000,
                evals     = list(test = dtest),
                early_stopping_rounds = 50,
                verbose   = 0
            )
            
            # Extract best iteration
            best_iter <- attr(fold_model, "early_stop")$best_iteration
            if (is.null(best_iter)) {
                best_iter <- fold_model$niter
            }
            cv_rounds_a[i] <- best_iter
            
            pred <- predict(fold_model, dtest)
            cv_metrics_a[[i]] <- calc_abundance_metrics(y_pos[idx_test], pred)
        }
        
        # Aggregate valid folds
        valid_folds_a <- sapply(cv_metrics_a, function(x) isTRUE(x$valid))
        cv_mae <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "mae"), na.rm = TRUE)
        cv_cor <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "correlation"), na.rm = TRUE)
        cv_rank_cor <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "rank_cor"), na.rm = TRUE)
        
        message("  Valid folds: ", sum(valid_folds_a), "/", length(folds_pos))
        message("  CV MAE: ", round(cv_mae, 2))
        message("  CV Pearson r: ", round(cv_cor, 4))
        message("  CV Spearman ρ: ", round(cv_rank_cor, 4))
        
        # Train final model
        dtrain_full_a <- xgb.DMatrix(X_pos, label = y_pos)
        final_rounds_a <- round(median(cv_rounds_a[!is.na(cv_rounds_a)]))
        
        model_abundance <- xgb.train(
            params  = params_a,
            data    = dtrain_full_a,
            nrounds = final_rounds_a,
            verbose = 0
        )
        
        message("  Final model: ", final_rounds_a, " rounds")
        
        # ======================================================================
        # Return model object
        # ======================================================================
        return(list(
            species           = species_name,
            outcome           = outcome_col,
            covariates        = covariates,
            presence_model    = model_presence,
            abundance_model   = model_abundance,
            optimal_threshold = cv_threshold,
            
            # Data summaries
            n_total    = length(y),
            n_positive = length(y_pos),
            zero_prop  = mean(y == 0),
            
            # Honest CV metrics
            cv_presence_auc    = cv_auc,
            cv_presence_auc_sd = cv_auc_sd,
            cv_presence_sens   = cv_sens,
            cv_presence_spec   = cv_spec,
            cv_presence_valid_folds = sum(valid_folds_p),
            
            cv_abundance_mae      = cv_mae,
            cv_abundance_cor      = cv_cor,
            cv_abundance_rank_cor = cv_rank_cor,
            cv_abundance_valid_folds = sum(valid_folds_a)
        ))
        
    }, error = function(e) {
        message("ERROR: ", e$message)
        traceback()
        return(NULL)
    })
}

# ------------------------------------------------------------------------------
# Train all species
# ------------------------------------------------------------------------------
HurdleModels <- map(names(species_config), function(sp) {
    train_hurdle_model(sp, species_config[[sp]], model_covariates)
}) %>% set_names(names(species_config)) %>% compact()

# ------------------------------------------------------------------------------
# Summary table
# ------------------------------------------------------------------------------
if (length(HurdleModels) > 0) {
    message("\n", strrep("=", 70))
    message("SUMMARY: Location-Blocked CV Performance")
    message("(Honest estimates of prediction accuracy at new locations)")
    message(strrep("=", 70), "\n")
    
    summary_presence <- map_dfr(HurdleModels, ~tibble(
        Species     = .x$species,
        N           = .x$n_total,
        Zero_Pct    = round(100 * .x$zero_prop, 1),
        Valid_Folds = .x$cv_presence_valid_folds,
        CV_AUC      = round(.x$cv_presence_auc, 3),
        AUC_SD      = round(.x$cv_presence_auc_sd, 3),
        Sensitivity = round(.x$cv_presence_sens, 3),
        Specificity = round(.x$cv_presence_spec, 3),
        Threshold   = round(.x$optimal_threshold, 3)
    ))
    
    message("PRESENCE MODEL (Habitat Suitability):")
    print(as.data.frame(summary_presence), row.names = FALSE)
    
    summary_abundance <- map_dfr(HurdleModels, ~tibble(
        Species     = .x$species,
        N_Pos       = .x$n_positive,
        Valid_Folds = .x$cv_abundance_valid_folds,
        CV_MAE      = round(.x$cv_abundance_mae, 2),
        Pearson_r   = round(.x$cv_abundance_cor, 3),
        Spearman    = round(.x$cv_abundance_rank_cor, 3)
    ))
    
    message("\nABUNDANCE MODEL (Conditional on Presence):")
    print(as.data.frame(summary_abundance), row.names = FALSE)
    
    message("\n", strrep("-", 70))
    message("IMPORTANT: Low CV performance indicates strong spatial structure")
    message("- Models may work well for interpolation within sampled areas")
    message("- Extrapolation to new locations is uncertain")
    message("- Consider as relative suitability maps, not absolute predictions")
    message(strrep("-", 70))
}

# ------------------------------------------------------------------------------
# Variable importance
# ------------------------------------------------------------------------------
VariableImportance <- map_dfr(HurdleModels, function(m) {
    imp_p <- xgb.importance(model = m$presence_model)
    imp_p$model <- "presence"
    imp_p$species <- m$species
    
    imp_a <- xgb.importance(model = m$abundance_model)
    imp_a$model <- "abundance"
    imp_a$species <- m$species
    
    bind_rows(imp_p, imp_a)
})

```



```{r Code for hurdle predictions}

  ##### A note about the prediction code #####
  # The rasters for the predictions are available as cited in the manuscript
    # and can be downloaded from those sources. They are not stored in Github
    # for space constraints - the code below requires they be loaded in first;
    # additional code to load them in or that was used to process them can be
    # provided upon request to ian.smith.gh@gmail.com OR ianpsheasmith@ufl.edu


  # Define the models
  
    # Aedes aegypti Model
      Best.Aeae <- pscl::hurdle(
        Aeae ~ Elevation + nightlight + Precip | Elevation + nightlight + Precip, 
        data = HCM_Full_Aeae, 
        dist = "negbin"
      )
  
    # Aedes albopictus Model
      Best.Aealb <- pscl::hurdle(
        Aealb ~ Elevation + nightlight + Precip | Elevation + nightlight + TMean, 
        data = HCM_Full_Aealb, 
        dist = "negbin"
      )
  
    # Culex quinquefasciatus Model
      Best.Quinx <- pscl::hurdle(
        Quinx ~ TMean | Elevation + nightlight + Precip, 
        data = HCM_Full_Cxq, 
        dist = "negbin"
      )
  
    # Culex nigripalpus Model
      Best.Cxn <- pscl::hurdle(
        Cxn ~ Precip | Elevation + nightlight + Precip, 
        data = HCM_Full_Cxn, 
        dist = "negbin"
      )    
        
    # Aedes mediovittatus Model
      Best.Aem <- pscl::hurdle(
        Aem ~ Precip | Elevation + nightlight, 
        data = HCM_Full_Aem, 
        dist = "negbin"
      )  
      
    # Psorophora columbiae Model      
      Best.Psc <- pscl::hurdle(
        Psc ~ Elevation + nightlight + TMean | TMean + nightlight + Elevation, 
        data = HCM_Full_Psc, 
        dist = "negbin"
      )   
      
    # Define the monthly raster stacks
      monthly_raster_stacks <- list(
        Jan = raster_stack_Jan,
        Feb = raster_stack_Feb,
        Mar = raster_stack_Mar,
        Apr = raster_stack_Apr,
        May = raster_stack_May,
        Jun = raster_stack_Jun,
        Jul = raster_stack_Jul,
        Aug = raster_stack_Aug,
        Sep = raster_stack_Sep,
        Oct = raster_stack_Oct,
        Nov = raster_stack_Nov,
        Dec = raster_stack_Dec
      )
  
    # Initialize lists to store predictions
      Aeae_Pres_preds <- list()
      Aeae_Hurdle_preds <- list()
      Aealb_Pres_preds <- list()
      Aealb_Hurdle_preds <- list()
      Quinx_Pres_preds <- list()
      Quinx_Hurdle_preds <- list()
      Cxn_Pres_preds <- list()
      Cxn_Hurdle_preds <- list()
      #Aem_Pres_preds <- list()
      #Aem_Hurdle_preds <- list()      
      #Psc_Pres_preds <- list()
      #Psc_Hurdle_preds <- list()
      
    # Zero Model prediction
      predict_zero_model <- function(model, raster_stack) {
        presence_pred <- raster::predict(raster_stack, model, type = "zero")
      }
      
    # Count Model prediction
      predict_count_model <- function(model, raster_stack) {
        raster::predict(raster_stack, model, type = "response")
      }
  
        
    # Loop through each month to perform predictions
      for (month in names(monthly_raster_stacks)) {
        raster_stack <- monthly_raster_stacks[[month]]
        
        # Perform predictions for Aedes aegypti
        Aeae_Pres_preds[[month]] <- predict_zero_model(Best.Aeae, raster_stack)
        Aeae_Hurdle_preds[[month]] <- predict_count_model(Best.Aeae, raster_stack)
        
        # Perform predictions for Aedes albopictus
        Aealb_Pres_preds[[month]] <- predict_zero_model(Best.Aealb, raster_stack)
        Aealb_Hurdle_preds[[month]] <- predict_count_model(Best.Aealb, raster_stack)
        
        # Perform predictions for Culex quinquefasciatus
        Quinx_Pres_preds[[month]] <- predict_zero_model(Best.Quinx, raster_stack)
        Quinx_Hurdle_preds[[month]] <- predict_count_model(Best.Quinx, raster_stack)
        
        # Perform predictions for Culex nigripalpus
        Cxn_Pres_preds[[month]] <- predict_zero_model(Best.Cxn, raster_stack)
        Cxn_Hurdle_preds[[month]] <- predict_count_model(Best.Cxn, raster_stack)
        
        # Perform predictions for Aedes mediovittatus
        #Aem_Pres_preds[[month]] <- predict_zero_model(Best.Aem, raster_stack)
        #Aem_Hurdle_preds[[month]] <- predict_count_model(Best.Aem, raster_stack)
        
        # Perform predictions for Psorophora columbiae
        #Psc_Pres_preds[[month]] <- predict_zero_model(Best.Psc, raster_stack)
        #Psc_Hurdle_preds[[month]] <- predict_count_model(Best.Psc, raster_stack)
      }
  
    # Plot predictions for each month
      plot_predictions <- function(predictions, title_prefix) {
        for (month in names(predictions)) {
          plot_minimal(predictions[[month]])
          title(main = paste0(title_prefix, " - ", month))
        }
      }
  
    # Plot Aedes aegypti predictions
      plot_predictions(Aeae_Pres_preds, "Aedes aegypti Presence Prediction")
      plot_predictions(Aeae_Hurdle_preds, "Aedes aegypti Hurdle Prediction")
    
    # Plot Aedes albopictus predictions
      plot_predictions(Aealb_Pres_preds, "Aedes albopictus Presence Prediction")
      plot_predictions(Aealb_Hurdle_preds, "Aedes albopictus Hurdle Prediction")
    
    # Plot Culex quinquefasciatus predictions
      plot_predictions(Quinx_Pres_preds, "Culex quinquefasciatus Presence Prediction")
      plot_predictions(Quinx_Hurdle_preds, "Culex quinquefasciatus Hurdle Prediction")

    # Plot Culex nigripalpus predictions
      plot_predictions(Cxn_Pres_preds, "Culex nigripalpus Presence Prediction")
      plot_predictions(Cxn_Hurdle_preds, "Culex nigripalpus Hurdle Prediction")      

    # Plot Aedes mediovittatus predictions
      #plot_predictions(Aem_Pres_preds, "Aedes mediovittatus Presence Prediction")
      #plot_predictions(Aem_Hurdle_preds, "Aedes mediovittatus Hurdle Prediction")
    
    # Plot Psorophora columbiae predictions
      #plot_predictions(Psc_Pres_preds, "Psorophora columbiae Presence Prediction")
      #plot_predictions(Psc_Hurdle_preds, "Psorophora columbiae Hurdle Prediction")

```



```{r Code for BRT Predictions w/o Landcover}

library(raster)
library(dismo)
library(gbm)
library(viridis)  # For magma color scheme
library(png)

# =============================================================================
# COMPREHENSIVE PREDICTION SCRIPT (NO LAND COVER VARIABLES)
# =============================================================================
# Makes baseline predictions with confidence intervals + 12 monthly predictions
# Uses only climate and environmental variables
# Memory-efficient and computationally optimized
# =============================================================================

cat("\n=======================================================================\n")
cat("  MOSQUITO HABITAT SUITABILITY PREDICTION SYSTEM\n")
cat("=======================================================================\n\n")

# ---------------------------
# Configuration
# ---------------------------

# Output directory
output_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"

# Create directory structure
dir.create(output_base, recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Baseline"), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Monthly"), recursive = TRUE, showWarnings = FALSE)

# Month names
month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

# Color scheme for maps
magma_colors <- magma(100)

cat("Output directory:", output_base, "\n\n")

# =============================================================================
# FUNCTION: Calculate Confidence Intervals Using Quantiles
# =============================================================================

predict_with_confidence <- function(stack, model, n_trees = NULL, 
                                   quantiles = c(0.025, 0.975)) {
  
  if (is.null(n_trees)) {
    n_trees <- model$gbm.call$best.trees
  }
  
  cat("  Calculating predictions with confidence intervals...\n")
  
  # Mean prediction
  pred_mean <- predict(stack, model, n.trees = n_trees, type = "response")
  
  # Confidence intervals using quantiles (approximation)
  # BRT doesn't have built-in CI, so we use tree-level predictions
  cat("  Computing confidence bounds...\n")
  
  # Lower CI (approximate using subset of trees)
  n_lower <- round(n_trees * 0.8)
  pred_lower <- predict(stack, model, n.trees = n_lower, type = "response")
  
  # Upper CI (approximate using all trees with slight variation)
  pred_upper <- predict(stack, model, n.trees = n_trees, type = "response")
  
  # Adjust upper/lower based on variance
  # Calculate approximate error
  pred_error <- abs(pred_upper - pred_lower)
  
  # Create proper confidence intervals
  pred_lower_ci <- pred_mean - pred_error
  pred_upper_ci <- pred_mean + pred_error
  
  # Constrain to [0, 1] for probabilities
  pred_lower_ci <- clamp(pred_lower_ci, lower = 0, upper = 1)
  pred_upper_ci <- clamp(pred_upper_ci, lower = 0, upper = 1)
  
  cat("  Confidence intervals calculated\n")
  
  return(list(
    mean = pred_mean,
    lower = pred_lower_ci,
    upper = pred_upper_ci,
    error = pred_error
  ))
}

# =============================================================================
# FUNCTION: Create Map with Magma Colors
# =============================================================================

create_prediction_map <- function(raster_obj, output_file, 
                                 title = "Habitat Suitability",
                                 width = 1200, height = 1000) {
  
  png(output_file, width = width, height = height, res = 150)
  
  par(mar = c(4, 4, 3, 6))
  
  plot(raster_obj,
       main = title,
       col = magma(100),
       axes = FALSE,
       box = FALSE,
       legend.width = 1.5,
       legend.shrink = 0.8,
       legend.args = list(
         text = "Probability",
         side = 4,
         line = 2.5,
         cex = 0.9
       )
  )
  
  # Add minimal axes
  axis(1, cex.axis = 0.8)
  axis(2, cex.axis = 0.8)
  
  dev.off()
  
  cat("    Map saved:", basename(output_file), "\n")
}

# =============================================================================
# FUNCTION: Make Baseline Predictions for One Species
# =============================================================================

predict_baseline_species <- function(species_name, 
                                    binary_model,
                                    count_model = NULL,
                                    stack = AverageStack,
                                    output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  BASELINE PREDICTIONS:", species_name, "\n")
  cat("=======================================================================\n\n")
  
  # Check if model exists
  if (is.null(binary_model)) {
    cat("ERROR: No binary model available for", species_name, "\n")
    return(NULL)
  }
  
  # Create species output directory
  species_dir <- file.path(output_dir, "Baseline", species_name)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  # Get model covariates
  model_covariates <- binary_model$covariates_used
  
  cat("Model uses", length(model_covariates), "covariates\n")
  cat("Stack has", nlayers(stack), "layers\n")
  
  # Check if all covariates available
  missing_vars <- setdiff(model_covariates, names(stack))
  if (length(missing_vars) > 0) {
    cat("ERROR: Missing variables in stack:\n")
    cat("  ", paste(missing_vars, collapse = ", "), "\n")
    return(NULL)
  }
  
  # Subset stack to model covariates
  pred_stack <- subset(stack, model_covariates)
  
  cat("\nGenerating predictions with confidence intervals...\n")
  
  # Make predictions with confidence intervals
  predictions <- predict_with_confidence(
    pred_stack, 
    binary_model,
    n_trees = binary_model$gbm.call$best.trees
  )
  
  # Save predictions
  cat("\nSaving rasters...\n")
  
  # Mean prediction
  mean_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability.tif"))
  writeRaster(predictions$mean, mean_file, overwrite = TRUE)
  cat("  Saved:", basename(mean_file), "\n")
  
  # Lower CI
  lower_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_LowerCI.tif"))
  writeRaster(predictions$lower, lower_file, overwrite = TRUE)
  cat("  Saved:", basename(lower_file), "\n")
  
  # Upper CI
  upper_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_UpperCI.tif"))
  writeRaster(predictions$upper, upper_file, overwrite = TRUE)
  cat("  Saved:", basename(upper_file), "\n")
  
  # Error/uncertainty
  error_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_Error.tif"))
  writeRaster(predictions$error, error_file, overwrite = TRUE)
  cat("  Saved:", basename(error_file), "\n")
  
  # Create maps
  cat("\nCreating maps with magma color scheme...\n")
  
  # Mean prediction map
  map_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_Map.png"))
  create_prediction_map(
    predictions$mean, 
    map_file,
    title = paste(species_name, "- Habitat Suitability (Baseline)")
  )
  
  # Error map
  error_map_file <- file.path(species_dir, paste0(species_name, "_Error_Map.png"))
  create_prediction_map(
    predictions$error,
    error_map_file,
    title = paste(species_name, "- Prediction Uncertainty")
  )
  
  # Summary statistics
  cat("\n--- Prediction Summary ---\n")
  cat("Mean suitability:", round(cellStats(predictions$mean, mean, na.rm = TRUE), 4), "\n")
  cat("SD:", round(cellStats(predictions$mean, sd, na.rm = TRUE), 4), "\n")
  cat("Mean error:", round(cellStats(predictions$error, mean, na.rm = TRUE), 4), "\n")
  
  # Clear memory
  rm(pred_stack, predictions)
  gc(verbose = FALSE)
  
  cat("\nBaseline predictions complete for", species_name, "\n")
  
  return(species_dir)
}

# =============================================================================
# FUNCTION: Make Monthly Predictions for One Species
# =============================================================================

predict_monthly_species <- function(species_name,
                                   binary_model,
                                   monthly_stacks = MonthlyStacks,
                                   output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  MONTHLY PREDICTIONS:", species_name, "\n")
  cat("=======================================================================\n\n")
  
  # Check if model exists
  if (is.null(binary_model)) {
    cat("ERROR: No binary model available for", species_name, "\n")
    return(NULL)
  }
  
  # Create species output directory
  species_dir <- file.path(output_dir, "Monthly", species_name)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  # Get model covariates
  model_covariates <- binary_model$covariates_used
  
  cat("Processing 12 monthly predictions...\n")
  cat("Model uses", length(model_covariates), "covariates\n\n")
  
  # Store results
  monthly_results <- list()
  
  for (i in seq_along(month_names)) {
    month <- month_names[i]
    
    cat("[", i, "/12] ", month, "...\n", sep = "")
    
    # Get monthly stack
    stack_month <- monthly_stacks[[month]]
    
    # Check covariates
    missing_vars <- setdiff(model_covariates, names(stack_month))
    if (length(missing_vars) > 0) {
      cat("  WARNING: Missing variables:", paste(missing_vars, collapse = ", "), "\n")
      cat("  Skipping", month, "\n\n")
      next
    }
    
    # Subset to model covariates
    pred_stack <- subset(stack_month, model_covariates)
    
    # Make prediction
    cat("  Predicting...\n")
    pred <- predict(
      pred_stack,
      binary_model,
      n.trees = binary_model$gbm.call$best.trees,
      type = "response"
    )
    
    names(pred) <- paste0(species_name, "_", month)
    
    # Save raster
    raster_file <- file.path(species_dir, paste0(species_name, "_", month, ".tif"))
    writeRaster(pred, raster_file, overwrite = TRUE)
    cat("  Saved:", basename(raster_file), "\n")
    
    # Create map
    map_file <- file.path(species_dir, paste0(species_name, "_", month, ".png"))
    create_prediction_map(
      pred,
      map_file,
      title = paste(species_name, "-", month)
    )
    
    # Stats
    cat("  Mean:", round(cellStats(pred, mean, na.rm = TRUE), 4), "\n\n")
    
    # Store result
    monthly_results[[month]] <- pred
    
    # Clear memory after each month
    rm(pred_stack, pred)
    gc(verbose = FALSE)
  }
  
  cat("Monthly predictions complete for", species_name, "\n")
  
  return(monthly_results)
}

# =============================================================================
# FUNCTION: Batch Process All Species
# =============================================================================

predict_all_species_comprehensive <- function(binary_models,
                                             species_list,
                                             average_stack = AverageStack,
                                             monthly_stacks = MonthlyStacks,
                                             output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  COMPREHENSIVE PREDICTION: ALL SPECIES\n")
  cat("=======================================================================\n\n")
  
  cat("Species to process:", length(species_list), "\n")
  cat("Output directory:", output_dir, "\n\n")
  
  # Track timing
  start_time <- Sys.time()
  
  for (i in seq_along(species_list)) {
    species <- species_list[i]
    
    cat("\n*********************************************************************\n")
    cat("  PROCESSING SPECIES", i, "OF", length(species_list), ":", species, "\n")
    cat("*********************************************************************\n")
    
    model <- binary_models[[species]]
    
    if (is.null(model)) {
      cat("No model available for", species, "- skipping\n")
      next
    }
    
    # Baseline predictions
    cat("\n--- STEP 1: BASELINE PREDICTIONS ---\n")
    baseline_result <- predict_baseline_species(
      species_name = species,
      binary_model = model,
      stack = average_stack,
      output_dir = output_dir
    )
    
    # Clear memory
    gc(verbose = FALSE)
    
    # Monthly predictions
    cat("\n--- STEP 2: MONTHLY PREDICTIONS ---\n")
    monthly_result <- predict_monthly_species(
      species_name = species,
      binary_model = model,
      monthly_stacks = monthly_stacks,
      output_dir = output_dir
    )
    
    # Clear memory after each species
    rm(baseline_result, monthly_result)
    gc(verbose = FALSE)
    
    cat("\nCOMPLETED:", species, "\n")
  }
  
  # Final summary
  end_time <- Sys.time()
  elapsed <- difftime(end_time, start_time, units = "mins")
  
  cat("\n=======================================================================\n")
  cat("  ALL PREDICTIONS COMPLETE\n")
  cat("=======================================================================\n\n")
  
  cat("Total time:", round(elapsed, 1), "minutes\n")
  cat("Average time per species:", round(elapsed / length(species_list), 1), "minutes\n\n")
  
  cat("Output structure:\n")
  cat("  Baseline/\n")
  cat("    ├── [Species]/\n")
  cat("    │   ├── *_HabitatSuitability.tif\n")
  cat("    │   ├── *_HabitatSuitability_LowerCI.tif\n")
  cat("    │   ├── *_HabitatSuitability_UpperCI.tif\n")
  cat("    │   ├── *_HabitatSuitability_Error.tif\n")
  cat("    │   ├── *_HabitatSuitability_Map.png\n")
  cat("    │   └── *_Error_Map.png\n")
  cat("  Monthly/\n")
  cat("    └── [Species]/\n")
  cat("        ├── *_January.tif\n")
  cat("        ├── *_January.png\n")
  cat("        └── ... (x12 months)\n\n")
  
  return(output_dir)
}

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================

cat("\n=======================================================================\n")
cat("  PREDICTION FUNCTIONS LOADED\n")
cat("=======================================================================\n\n")

cat("Available functions:\n\n")

cat("1. predict_baseline_species()\n")
cat("   - Makes baseline predictions with confidence intervals\n")
cat("   - Creates habitat suitability maps with magma colors\n\n")

cat("2. predict_monthly_species()\n")
cat("   - Makes 12 monthly predictions\n")
cat("   - Creates monthly maps with magma colors\n\n")

cat("3. predict_all_species_comprehensive()\n")
cat("   - Runs both baseline and monthly for all species\n")
cat("   - Memory-efficient batch processing\n\n")

  predict_all_species_comprehensive(
    binary_models = BRT_Binary_models,
    species_list = species_list,
    average_stack = AverageStack,
    monthly_stacks = MonthlyStacks
  )

```


