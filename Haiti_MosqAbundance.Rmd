---
title: "Haiti_MosqAbundance"
author: "Ian Pshea-Smith"
date: "`r Sys.Date()`"
output: html_document
---


```{r Loading required libraries}

  # spatial hurdle libraries
  library(dplyr)
  library(ggplot2)
  library(inlabru)
  library(terra)
  library(sf)
  library(RColorBrewer)
  library(magrittr)
  library(patchwork)
  library(parallel)
  library(sp)
  library(gstat)
  library(MuMIn)
  library(parallel)
  library(viridis)
  library(RColorBrewer)
  library(readr)
  library(ggcorrplot)
  library(corrplot)
  library(gridExtra)
  library(ggtext)
  library(kableExtra)
  library(leaflet)

```



```{r Loading in Data}

  ##### A note about the data import and below code #####
  # Data processing and appending covariates is available as a seperate set of
    # code (HaitiCountModels.Rmd, available upon request to 
    # ian.smith.gh@gmail.com). Below is import code for the processed dataset,
    # including both the cleaned abundance data and the covariate data
    # already extracted from Bioclim & WorldPop.

  # Define GitHub base URL for raw files
    base_url <- "https://raw.githubusercontent.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/main/"

  # Define dataset names
    datasets <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq", 
                  "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")
  
  # Initialize an empty list to store data
    dataset_list <- list()
  
  # Download and read each dataset directly into R
    for (dataset in datasets) {
      file_url <- paste0(base_url, dataset, ".csv")
      
      # Read CSV directly into R env
      dataset_list[[dataset]] <- read.csv(file_url, stringsAsFactors = FALSE)
      
      # Assign dataset to global environment
      assign(dataset, dataset_list[[dataset]], envir = .GlobalEnv)
      
      message(paste("Loaded:", dataset))
    }

  # Test for Aeae
    head(HCM_Full_Aeae)

  # Download Shapefiles for the map(s)
    zip_url <- "https://github.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/raw/main/Haiti_Shapefiles.zip"
    zip_dest <- tempfile(fileext = ".zip")
    unzip_dir <- tempfile()
    download.file(zip_url, destfile = zip_dest, mode = "wb")
    unzip(zip_dest, exdir = unzip_dir)

  # read in the shapefiles
    all_files <- list.files(unzip_dir, recursive = TRUE, full.names = TRUE)
    adm2_path <- all_files[grepl("adm2.*\\.shp$", all_files)]
    adm3_path <- all_files[grepl("adm3.*\\.shp$", all_files)]
    Haiti_adm2 <- st_read(adm2_path)
    Haiti_adm3 <- st_read(adm3_path)
    
  # Base URL for raw GitHub files
    base_url <- "https://raw.githubusercontent.com/IanPsheaSmith/Haiti_MosqAbundanceStudy/main/Rasters/"
  
  # Load AverageStack raster data
    AverageStack <- stack(paste0(base_url, "AverageStack.tif"))
  
  # Load MonthlyStacks raster data
    month_names <- c("January", "February", "March", "April", "May", "June",
                     "July", "August", "September", "October", "November", "December")
    
    MonthlyStacks <- list()
    for(month in month_names) {
      MonthlyStacks[[month]] <- stack(paste0(base_url, month, "_Stack.tif"))
    }

```



```{r Figure 1 - Study Area Map}

# Convert HCM_Full_Aeae to sf object
  HCM_Full_Aeae_sf <- st_as_sf(HCM_Full_Aeae,
                                coords = c("Longitude", "Latitude"),
                                crs = 4326)
  
  # Identify the ADM2 polygons (communes) that contain sample points
  adm2_flagged <- Haiti_adm2[
    lengths(st_intersects(Haiti_adm2, HCM_Full_Aeae_sf)) > 0,
  ]
  
  # Plot all communes in light grey
  Haiti_StudySiteCommunes <- ggplot() +
    # all communes (ADM2) in light grey
    geom_sf(
      data  = Haiti_adm2,
      fill  = "white",
      color = "grey",
      size  = 0.05
    ) +
    # communes intersecting sample points
    geom_sf(
      data  = adm2_flagged,
      fill  = "grey",
      color = "black",
      size  = 0.05
    ) +
    theme_minimal() +
    labs(
      title = "",
      x     = "",
      y     = ""
    )
  
  # Count observations per location
  HCM_counts <- HCM_Full_Aeae %>%
    group_by(Latitude, Longitude) %>%
    summarise(n_obs = n(), .groups = "drop") %>%
    st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326)
  
  # Plot the study sites alone with graduated points
  Haiti_StudySite <- ggplot() +
    geom_sf(
      data  = adm2_flagged,
      fill  = "white",
      color = "black",
      size  = 0.05
    ) +
    geom_sf(
      data = HCM_counts,
      aes(size = n_obs),
      alpha = 0.6,
      color = "#7851A9"
    ) +
    scale_size_continuous(name = "# Observations") +
    theme_minimal()
  
  # Print the figures
  print(Haiti_StudySiteCommunes)
  print(Haiti_StudySite)

```



```{r Interactive Map of Data}

  # Aggregate data by location with species counts
    HCM_map_data <- HCM_Full_Aeae %>%
      group_by(Latitude, Longitude) %>%
      summarise(
        n_obs = n(),
        Quinx = sum(Quinx, na.rm = TRUE),
        Aeae = sum(Aeae, na.rm = TRUE),
        Aealb = sum(Aealb, na.rm = TRUE),
        Aem = sum(Aem, na.rm = TRUE),
        Cxn = sum(Cxn, na.rm = TRUE),
        Psc = sum(Psc, na.rm = TRUE),
        .groups = "drop"
      )
  
  # Create leaflet map
    leaflet(HCM_map_data) %>%
      addTiles(group = "OpenStreetMap") %>%
      addProviderTiles("Esri.WorldImagery", group = "Satellite") %>%
      addProviderTiles("Esri.WorldShadedRelief", group = "Elevation") %>%
      addCircleMarkers(
        lng = ~Longitude,
        lat = ~Latitude,
        radius = ~sqrt(n_obs) * 2,
        popup = ~paste0("Collection Events: ", n_obs, "<br>",
                        "<i>Cx. quinquefasciatus</i>: ", Quinx, "<br>",
                        "<i>Ae. aegypti</i>: ", Aeae, "<br>",
                        "<i>Ae. albopictus</i>: ", Aealb, "<br>",
                        "<i>Ae. mediovittatus</i>: ", Aem, "<br>",
                        "<i>Cx. nigripalpus</i>: ", Cxn, "<br>",
                        "<i>Ps. columbiae</i>: ", Psc)
      ) %>%
      addLayersControl(
        baseGroups = c("OpenStreetMap", "Satellite", "Elevation"),
        options = layersControlOptions(collapsed = FALSE)
      )

```



```{r Basic Descriptive Tables & Visualizations}

  # Renaming covariates
  HCM_Full_Aeae_renamed <- HCM_Full_Aeae %>%
    rename(
      Precipitation = Precip,
      Temperature = TMean,
      `Wind Speed` = WindMean,
      `Night Lights` = nightlight
    )
  
  # Selecting only the necessary columns for the correlation matrix
  cor_data <- HCM_Full_Aeae_renamed %>%
    dplyr::select(Precipitation, Temperature, `Wind Speed`, `Night Lights`, Elevation)
  
  # Selecting only the necessary columns for the correlation matrix
  cor_data <- HCM_Full_Aeae_renamed %>%
    dplyr::select(Precipitation, Temperature, `Wind Speed`, `Night Lights`, Elevation)
  
  # Calculating the correlation matrix
  cor_matrix <- cor(cor_data, use = "complete.obs")
  
  # Define the custom color ramp palette from yellow to pink
  yellow_pink_colors <- c("#FFF44A", "#FF9D82", "#FF769F", "#FF51BD")
  
  # Plotting the correlation matrix using ggcorrplot with a gradient color scale
  ggcorrplot(cor_matrix, 
             hc.order = TRUE, 
             type = "lower", 
             lab = TRUE, 
             lab_col = "black", 
             outline.col = "white", 
             ggtheme = ggplot2::theme_minimal()) +
    scale_fill_gradientn(colors = yellow_pink_colors) +
    ggtitle("Correlation Matrix")
  

  
  # Define the path to save the combined plot
  output_path <- "REPLACE WITH YOUR FOLDER PATH"
  
  # Define the variables and their respective titles
  variables <- c("Quinx", "Aeae", "Aealb")
  titles <- c(
    "Counts of *Culex quinquefasciatus*",
    "Counts of *Aedes aegypti*",
    "Counts of *Aedes albopictus*"
  )
  
  # Define the colors for each plot
  colors <- c("lightpink", "orchid", "mediumpurple")
  
  # Define a function to create a histogram with a specific color and title
  create_histogram <- function(data, variable, title, color) {
    ggplot(data, aes_string(variable)) +
      geom_histogram(fill = color, color = "black", bins = 30) +
      labs(title = title, x = variable, y = "Count") +
      theme_minimal() +
      theme(
        plot.title = element_markdown(),
        plot.background = element_rect(fill = "transparent", color = NA)
      )
  }
  
  # Create histograms
  histograms <- lapply(seq_along(variables), function(i) {
    create_histogram(HCM_Full_Aeae_renamed, variables[i], titles[i], colors[i])
  })
  
  # Find the maximum y-axis limit to use the same for all plots
  max_y <- max(sapply(histograms, function(p) {
    ggplot_build(p)$layout$panel_params[[1]]$y.range[2]
  }))
  
  # Update histograms to have the same y-axis limit
  histograms <- lapply(histograms, function(p) {
    p + ylim(0, max_y)
  })
  
  # Combine histograms side-by-side
  combined_plot <- grid.arrange(grobs = histograms, ncol = 3)
  
  # Save the combined plot as a PNG with a transparent background
  ggsave(
    filename = file.path(output_path, "combined_histograms.png"),
    plot = combined_plot,
    device = "png",
    bg = "transparent",
    width = 24,  # Adjust width as needed
    height = 8,  # Adjust height as needed
    units = "in"
  )
  
  # Save individual histograms as PNGs with transparent backgrounds
  for (i in seq_along(histograms)) {
    ggsave(
      filename = file.path(output_path, paste0(variables[i], "_histogram.png")),
      plot = histograms[[i]],
      device = "png",
      bg = "transparent",
      width = 8,  # Adjust width as needed
      height = 8,  # Adjust height as needed
      units = "in"
    )
  }
  
    # Summary statistics calculation
    summary_table <- HCM_Full_Aeae_renamed %>%
      group_by(Trap_Type) %>%
      summarise(
        Total_Aedes_aegypti = sum(Aeae),
        Mean_Aedes_aegypti = round(mean(Aeae), 2),
        Median_Aedes_aegypti = round(median(Aeae), 2),
        Total_Aedes_albopictus = sum(Aealb),
        Mean_Aedes_albopictus = round(mean(Aealb), 2),
        Median_Aedes_albopictus = round(median(Aealb), 2),
        Total_Culex_quinquefasciatus = sum(Quinx),
        Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
        Median_Culex_quinquefasciatus = round(median(Quinx), 2),
        Total_Culex_nigripalpus = sum(Cxn),
        Mean_Culex_nigripalpus = round(mean(Cxn), 2),
        Median_Culex_nigripalpus = round(median(Cxn), 2),
        Total_Aedes_mediovittatus = sum(Aem),
        Mean_Aedes_mediovittatus = round(mean(Aem), 2),
        Median_Aedes_mediovittatus = round(median(Aem), 2),
        Total_Psorophora_columbiae = sum(Psc),
        Mean_Psorophora_columbiae = round(mean(Psc), 2),
        Median_Psorophora_columbiae = round(median(Psc), 2)
      )
    
    # Calculate overall totals, means, and medians
    total_row <- HCM_Full_Aeae_renamed %>%
      summarise(
        Trap_Type = "Total",
        Total_Aedes_aegypti = sum(Aeae),
        Mean_Aedes_aegypti = round(mean(Aeae), 2),
        Median_Aedes_aegypti = round(median(Aeae), 2),
        Total_Aedes_albopictus = sum(Aealb),
        Mean_Aedes_albopictus = round(mean(Aealb), 2),
        Median_Aedes_albopictus = round(median(Aealb), 2),
        Total_Culex_quinquefasciatus = sum(Quinx),
        Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
        Median_Culex_quinquefasciatus = round(median(Quinx), 2),
        Total_Culex_nigripalpus = sum(Cxn),
        Mean_Culex_nigripalpus = round(mean(Cxn), 2),
        Median_Culex_nigripalpus = round(median(Cxn), 2),
        Total_Aedes_mediovittatus = sum(Aem),
        Mean_Aedes_mediovittatus = round(mean(Aem), 2),
        Median_Aedes_mediovittatus = round(median(Aem), 2),
        Total_Psorophora_columbiae = sum(Psc),
        Mean_Psorophora_columbiae = round(mean(Psc), 2),
        Median_Psorophora_columbiae = round(median(Psc), 2)
      )
  
  
  # Combine summary table with total row
  final_table <- bind_rows(summary_table, total_row)
  
  # Create a beautiful table
  kable(final_table, format = "html", escape = FALSE, col.names = c(
    "Trap Type", 
    "Total", "Mean", "Median", 
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median",
    "Total", "Mean", "Median"
  )) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                  full_width = F) %>%
    add_header_above(c(" " = 1, 
                       "<i>Aedes aegypti</i>" = 3, 
                       "<i>Aedes albopictus</i>" = 3, 
                       "<i>Culex quinquefasciatus</i>" = 3,
                       "<i>Culex nigripalpus</i>" = 3,
                       "<i>Aedes mediovittatus</i>" = 3,
                       "<i>Psorophora columbiae</i>" = 3), escape = FALSE) %>%
    row_spec(nrow(final_table), bold = TRUE, background = "lightgray")
  
  
  # Add a new variable for the total counts of all species per observation
  HCM_Full_Aeae_renamed <- HCM_Full_Aeae_renamed %>%
    mutate(Total_Counts = Aeae + Aealb + Quinx + Cxn + Aem + Psc)
  
  # Summary statistics calculation for each species and the new total column
  summary_table <- HCM_Full_Aeae_renamed %>%
    group_by(Trap_Type) %>%
    summarise(
      Total_Aedes_aegypti = sum(Aeae),
      Mean_Aedes_aegypti = round(mean(Aeae), 2),
      Median_Aedes_aegypti = round(median(Aeae), 2),
      Total_Aedes_albopictus = sum(Aealb),
      Mean_Aedes_albopictus = round(mean(Aealb), 2),
      Median_Aedes_albopictus = round(median(Aealb), 2),
      Total_Culex_quinquefasciatus = sum(Quinx),
      Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
      Median_Culex_quinquefasciatus = round(median(Quinx), 2),
      Total_Culex_nigripalpus = sum(Cxn),
      Mean_Culex_nigripalpus = round(mean(Cxn), 2),
      Median_Culex_nigripalpus = round(median(Cxn), 2),
      Total_Aedes_mediovittatus = sum(Aem),
      Mean_Aedes_mediovittatus = round(mean(Aem), 2),
      Median_Aedes_mediovittatus = round(median(Aem), 2),
      Total_Psorophora_columbiae = sum(Psc),
      Mean_Psorophora_columbiae = round(mean(Psc), 2),
      Median_Psorophora_columbiae = round(median(Psc), 2),
      Total_All_Species = sum(Total_Counts),
      Mean_All_Species = round(mean(Total_Counts), 2),
      Median_All_Species = round(median(Total_Counts), 2)
    ) %>%
    pivot_longer(cols = -Trap_Type, names_to = "Species_Metric", values_to = "Value") %>%
    separate(Species_Metric, into = c("Metric", "Species"), sep = "_", extra = "merge") %>%
    pivot_wider(names_from = c(Trap_Type, Metric), values_from = Value)
  
  # Calculate overall totals, means, and medians across all trap types for each species
  total_row <- HCM_Full_Aeae_renamed %>%
    summarise(
      Species = "All Species",
      Total_Aedes_aegypti = sum(Aeae),
      Mean_Aedes_aegypti = round(mean(Aeae), 2),
      Median_Aedes_aegypti = round(median(Aeae), 2),
      Total_Aedes_albopictus = sum(Aealb),
      Mean_Aedes_albopictus = round(mean(Aealb), 2),
      Median_Aedes_albopictus = round(median(Aealb), 2),
      Total_Culex_quinquefasciatus = sum(Quinx),
      Mean_Culex_quinquefasciatus = round(mean(Quinx), 2),
      Median_Culex_quinquefasciatus = round(median(Quinx), 2),
      Total_Culex_nigripalpus = sum(Cxn),
      Mean_Culex_nigripalpus = round(mean(Cxn), 2),
      Median_Culex_nigripalpus = round(median(Cxn), 2),
      Total_Aedes_mediovittatus = sum(Aem),
      Mean_Aedes_mediovittatus = round(mean(Aem), 2),
      Median_Aedes_mediovittatus = round(median(Aem), 2),
      Total_Psorophora_columbiae = sum(Psc),
      Mean_Psorophora_columbiae = round(mean(Psc), 2),
      Median_Psorophora_columbiae = round(median(Psc), 2),
      Total_All_Species = sum(Total_Counts),
      Mean_All_Species = round(mean(Total_Counts), 2),
      Median_All_Species = round(median(Total_Counts), 2)
    ) %>%
    pivot_longer(cols = -Species, names_to = "Metric_Species", values_to = "Value") %>%
    separate(Metric_Species, into = c("Metric", "Species"), sep = "_", extra = "merge") %>%
    pivot_wider(names_from = Metric, values_from = Value)
  
  # Combine summary table with total row
  final_table <- bind_rows(summary_table, total_row)
  
  # Create a beautiful table with species as rows and trap types as columns
  kable(final_table, format = "html", escape = FALSE, col.names = c(
    "Species",
    rep(c("Total", "Mean", "Median"), times = 4)  # Adjusted to 4 for three trap types + overall
  )) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                  full_width = F) %>%
    add_header_above(c(" " = 1, 
                       "BG Sentinel" = 3, 
                       "CDC Light Trap" = 3, 
                       "Gravid Trap" = 3,
                       "Total" = 3)) %>%
    row_spec(nrow(final_table), bold = TRUE, background = "lightgray") %>%
    column_spec(1, bold = TRUE, italic = TRUE)

```



```{r VIF Test}

  GLM_Full <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + grassland + cropland + built + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_FullVIF <- car::vif(GLM_Full)
  print(GLM_FullVIF)
  max(GLM_FullVIF)

  # Remove Built (VIF > 50K)
  GLM_Step2 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + grassland + cropland + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step2VIF <- car::vif(GLM_Step2)
  print(GLM_Step2VIF)
  max(GLM_Step2VIF)
  
  # Remove Grassland (VIF > 50)
  GLM_Step3 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + water + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step3VIF <- car::vif(GLM_Step3)
  print(GLM_Step3VIF)
  max(GLM_Step3VIF)
  
  # Remove Water (VIF > 30)
  GLM_Step4 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland + NDVI + WindMean, data = HCM_Full_Aeae)
  GLM_Step4VIF <- car::vif(GLM_Step4)
  print(GLM_Step4VIF)
  max(GLM_Step4VIF)

  # Remove NDVI (VIF > 10)    
    GLM_Step5 <- glm(Aeae ~ Precip + TMean + nightlight + Elevation + trees + cropland + wetland + WindMean, data = HCM_Full_Aealb)
  GLM_Step5VIF <- car::vif(GLM_Step5)
  print(GLM_Step5VIF)
  max(GLM_Step5VIF)
  
    AeaeHurd <- pscl::hurdle(
      Aeae ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland | Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )
    
    AealbHurd <- pscl::hurdle(
      Aealb ~ Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland | Precip + TMean + nightlight + Elevation + trees + shrubs + cropland + wetland, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )
    
    summary(AeaeHurd)
    summary(AealbHurd)
```



```{r Code for boosted regression trees}

library(pROC)
library(caret)
library(purrr)
library(dplyr)
library(dismo)
library(gbm)
library(parallel)

# =============================================================================
# BOOTSTRAP BRT MODELING FOR ROBUST UNCERTAINTY ESTIMATION
# =============================================================================
# Fits multiple BRT models on bootstrap samples to assess model consensus
# Provides true prediction uncertainty, not approximations
# =============================================================================

cat("\n=======================================================================\n")
cat("  BOOTSTRAP BRT MODELING SYSTEM\n")
cat("  For Robust Uncertainty Estimation\n")
cat("=======================================================================\n\n")

# ---------------------------
# Configuration
# ---------------------------

# Base covariates (adjust based on your choice)
base_covariates <- c("Precip", "TMean", "WindMean", "Elevation")

# Land cover variables (set to empty vector if not using)
all_lc_variables <- c("LC_trees", "LC_shrubs", "LC_grassland", "LC_cropland", 
                      "LC_wetland", "LC_built")

# Number of bootstrap iterations (recommend 25-100)
# More = better uncertainty estimates but slower
n_bootstrap <- 50  # Good balance of speed and accuracy

# Use parallel processing?
use_parallel <- TRUE
n_cores <- detectCores() - 4  # Leave four cores free

# Define species and their datasets
species_list <- c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc")
dataset_names <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq",
                   "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")

cat("Bootstrap settings:\n")
cat("  Iterations:", n_bootstrap, "\n")
cat("  Parallel processing:", use_parallel, "\n")
if (use_parallel) {
  cat("  Cores:", n_cores, "\n")
}
cat("\n")

# ---------------------------
# Helper Functions
# ---------------------------

get_tree_complexity <- function(n_present) {
  if (n_present < 100) return(2)
  else if (n_present < 300) return(3)
  else return(5)
}

get_covariates_for_dataset <- function(dataset_name, stack_name = "AverageStack_updated") {
  df <- get(dataset_name, envir = .GlobalEnv)
  dataset_vars <- names(df)
  
  stack <- get(stack_name, envir = .GlobalEnv)
  stack_vars <- names(stack)
  
  dataset_lc <- intersect(all_lc_variables, dataset_vars)
  stack_lc <- intersect(all_lc_variables, stack_vars)
  usable_lc <- intersect(dataset_lc, stack_lc)
  
  all_covariates <- c(base_covariates, usable_lc)
  final_covariates <- intersect(all_covariates, dataset_vars)
  final_covariates <- intersect(final_covariates, stack_vars)
  
  return(final_covariates)
}

# =============================================================================
# SINGLE BOOTSTRAP ITERATION
# =============================================================================

fit_single_bootstrap_brt <- function(species, dataset, covariates, 
                                    iteration, family = "bernoulli") {
  
  # Prepare data based on family
  if (family == "bernoulli") {
    data_full <- dataset %>%
      mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
      dplyr::select(SpeciesBin, all_of(covariates)) %>%
      na.omit()
    response_var <- "SpeciesBin"
  } else {  # poisson
    data_full <- dataset %>%
      filter(.data[[species]] >= 1) %>%
      dplyr::select(all_of(species), all_of(covariates)) %>%
      na.omit()
    response_var <- species
  }
  
  # Bootstrap sample (with replacement)
  n <- nrow(data_full)
  boot_indices <- sample(1:n, size = n, replace = TRUE)
  data_boot <- data_full[boot_indices, ]
  
  # Determine tree complexity
  if (family == "bernoulli") {
    n_present <- sum(data_boot[[response_var]] == 1)
  } else {
    n_present <- nrow(data_boot)
  }
  tree_comp <- get_tree_complexity(n_present)
  
  # Fit model
  model <- tryCatch({
    gbm.step(
      data = data_boot,
      gbm.x = covariates,
      gbm.y = response_var,
      family = family,
      tree.complexity = tree_comp,
      learning.rate = 0.01,
      bag.fraction = 0.75,
      silent = TRUE,
      plot.main = FALSE
    )
  }, error = function(e) NULL)
  
  return(model)
}

# =============================================================================
# BOOTSTRAP ENSEMBLE FOR ONE SPECIES
# =============================================================================

fit_bootstrap_ensemble <- function(species, dataset_name, 
                                  n_boot = n_bootstrap,
                                  family = "bernoulli") {
  
  cat("\n=======================================================================\n")
  cat("  BOOTSTRAP ENSEMBLE:", species, "(", family, ")\n")
  cat("=======================================================================\n\n")
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  covariates <- get_covariates_for_dataset(dataset_name)
  
  # Check for sufficient data
  if (family == "bernoulli") {
    n_present <- sum(dataset[[species]] >= 1)
  } else {
    n_present <- sum(dataset[[species]] >= 1)
  }
  
  cat("Sample size:", n_present, "presences\n")
  
  if (n_present < 20) {
    cat("SKIPPED: Insufficient data\n")
    return(NULL)
  }
  
  cat("Fitting", n_boot, "bootstrap models...\n")
  
  start_time <- Sys.time()
  
  # Fit bootstrap models (parallel or serial)
  if (use_parallel) {
    cl <- makeCluster(n_cores)
    clusterExport(cl, c("fit_single_bootstrap_brt", "get_tree_complexity",
                       "species", "dataset", "covariates", "family"),
                 envir = environment())
    clusterEvalQ(cl, {
      library(dismo)
      library(gbm)
      library(dplyr)
    })
    
    bootstrap_models <- parLapply(cl, 1:n_boot, function(i) {
      fit_single_bootstrap_brt(species, dataset, covariates, i, family)
    })
    
    stopCluster(cl)
  } else {
    bootstrap_models <- lapply(1:n_boot, function(i) {
      if (i %% 10 == 0) cat("  Iteration", i, "/", n_boot, "\n")
      fit_single_bootstrap_brt(species, dataset, covariates, i, family)
    })
  }
  
  # Remove failed models
  successful <- !sapply(bootstrap_models, is.null)
  bootstrap_models <- bootstrap_models[successful]
  n_successful <- length(bootstrap_models)
  
  elapsed <- difftime(Sys.time(), start_time, units = "secs")
  
  cat("\nBootstrap complete:\n")
  cat("  Successful models:", n_successful, "/", n_boot, "\n")
  cat("  Time:", round(elapsed, 1), "seconds\n")
  cat("  Average per model:", round(elapsed / n_boot, 2), "seconds\n")
  
  if (n_successful < n_boot * 0.5) {
    cat("  WARNING: Low success rate (<50%)\n")
  }
  
  # Calculate consensus variable importance
  if (n_successful > 0) {
    cat("\nCalculating consensus variable importance...\n")
    
    var_imp_list <- lapply(bootstrap_models, function(m) {
      summary(m, plotit = FALSE)
    })
    
    # Average variable importance across models
    all_vars <- unique(unlist(lapply(var_imp_list, function(x) x$var)))
    consensus_imp <- data.frame(var = all_vars)
    
    for (v in all_vars) {
      imps <- sapply(var_imp_list, function(vi) {
        idx <- which(vi$var == v)
        if (length(idx) > 0) vi$rel.inf[idx] else 0
      })
      consensus_imp$mean[consensus_imp$var == v] <- mean(imps)
      consensus_imp$sd[consensus_imp$var == v] <- sd(imps)
      consensus_imp$cv[consensus_imp$var == v] <- sd(imps) / mean(imps)
    }
    
    consensus_imp <- consensus_imp[order(-consensus_imp$mean), ]
    
    cat("\nConsensus Variable Importance:\n")
    for (i in 1:nrow(consensus_imp)) {
      cat(sprintf("  %s: %.2f%% ± %.2f%% (CV=%.2f)\n",
                  consensus_imp$var[i],
                  consensus_imp$mean[i],
                  consensus_imp$sd[i],
                  consensus_imp$cv[i]))
    }
  }
  
  # Store metadata
  result <- list(
    species = species,
    family = family,
    models = bootstrap_models,
    n_bootstrap = n_boot,
    n_successful = n_successful,
    success_rate = n_successful / n_boot,
    covariates = covariates,
    consensus_importance = if (n_successful > 0) consensus_imp else NULL
  )
  
  class(result) <- c("bootstrap_brt", class(result))
  
  return(result)
}

# =============================================================================
# PREDICT WITH BOOTSTRAP ENSEMBLE
# =============================================================================

predict_bootstrap_ensemble <- function(bootstrap_ensemble, newdata, 
                                      type = "response") {
  
  if (is.null(bootstrap_ensemble) || bootstrap_ensemble$n_successful == 0) {
    return(NULL)
  }
  
  models <- bootstrap_ensemble$models
  n_models <- length(models)
  
  # Get predictions from each model
  predictions_matrix <- sapply(models, function(m) {
    predict(m, newdata, n.trees = m$gbm.call$best.trees, type = type)
  })
  
  # Calculate statistics
  pred_mean <- rowMeans(predictions_matrix, na.rm = TRUE)
  pred_sd <- apply(predictions_matrix, 1, sd, na.rm = TRUE)
  pred_lower <- apply(predictions_matrix, 1, quantile, probs = 0.025, na.rm = TRUE)
  pred_upper <- apply(predictions_matrix, 1, quantile, probs = 0.975, na.rm = TRUE)
  pred_cv <- pred_sd / pred_mean  # Coefficient of variation
  
  result <- list(
    mean = pred_mean,
    sd = pred_sd,
    lower_ci = pred_lower,
    upper_ci = pred_upper,
    cv = pred_cv,
    n_models = n_models,
    all_predictions = predictions_matrix
  )
  
  return(result)
}

# =============================================================================
# FIT ALL BOOTSTRAP ENSEMBLES
# =============================================================================

cat("\n=======================================================================\n")
cat("  FITTING BOOTSTRAP ENSEMBLES FOR ALL SPECIES\n")
cat("=======================================================================\n\n")

set.seed(1999)

# Binary (presence/absence) models
cat("STEP 1: BINARY MODELS\n")
cat("-----------------------------------------------------------------------\n")

BRT_Bootstrap_Binary <- map2(species_list, dataset_names, 
                             ~fit_bootstrap_ensemble(.x, .y, n_bootstrap, "bernoulli")) %>%
  set_names(species_list)

# Count models
cat("\n\nSTEP 2: COUNT MODELS\n")
cat("-----------------------------------------------------------------------\n")

BRT_Bootstrap_Count <- map2(species_list, dataset_names,
                            ~fit_bootstrap_ensemble(.x, .y, n_bootstrap, "poisson")) %>%
  set_names(species_list)

# =============================================================================
# SUMMARY
# =============================================================================

cat("\n=======================================================================\n")
cat("  BOOTSTRAP ENSEMBLE SUMMARY\n")
cat("=======================================================================\n\n")

summary_table <- data.frame(
  Species = species_list,
  Binary_Success_Rate = sapply(BRT_Bootstrap_Binary, function(x) {
    if (is.null(x)) NA else x$success_rate
  }),
  Binary_N_Models = sapply(BRT_Bootstrap_Binary, function(x) {
    if (is.null(x)) 0 else x$n_successful
  }),
  Count_Success_Rate = sapply(BRT_Bootstrap_Count, function(x) {
    if (is.null(x)) NA else x$success_rate
  }),
  Count_N_Models = sapply(BRT_Bootstrap_Count, function(x) {
    if (is.null(x)) 0 else x$n_successful
  })
)

print(summary_table, row.names = FALSE)

cat("\n=======================================================================\n")
cat("  BOOTSTRAP MODELING COMPLETE\n")
cat("=======================================================================\n\n")

cat("Objects created:\n")
cat("  - BRT_Bootstrap_Binary: List of", length(BRT_Bootstrap_Binary), "bootstrap ensembles\n")
cat("  - BRT_Bootstrap_Count: List of", length(BRT_Bootstrap_Count), "bootstrap ensembles\n\n")

cat("Each ensemble contains:\n")
cat("  - models: List of", n_bootstrap, "bootstrap BRT models\n")
cat("  - consensus_importance: Average variable importance across models\n")
cat("  - Metadata: Success rate, covariates used, etc.\n\n")

cat("Next steps:\n")
cat("  1. Use bootstrap ensembles for predictions with true uncertainty\n")
cat("  2. Generate consensus habitat suitability maps\n")
cat("  3. Create uncertainty maps based on model agreement\n\n")

cat("Prediction function: predict_bootstrap_ensemble()\n")
cat("  Returns: mean, SD, 95% CI, coefficient of variation\n\n")
```



```{r Code for BRT Predictions w/ Landcover}
# =============================================================================
# MOSQUITO SPECIES INTERACTIVE MAP GENERATION
# =============================================================================
library(raster)
library(terra)
library(sf)
library(exactextractr)
library(leaflet)
library(leaflet.extras)
library(htmltools)
library(htmlwidgets)
library(viridis)
library(dplyr)

cat("\n=======================================================================\n")
cat("  MOSQUITO SPECIES INTERACTIVE MAP GENERATION\n")
cat("=======================================================================\n\n")

# Configuration
prediction_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"
output_dir <- file.path(prediction_base, "Interactive_Maps")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

species_mapping <- c(
  "Aedes_aegypti" = "Aeae",
  "Aedes_albopictus" = "Aealb",
  "Anopheles_albimanus" = "Aem",
  "Culex_nigripalpus" = "Cxn",
  "Culex_quinquefasciatus" = "Quinx",
  "Psorophora_columbiae" = "Psc"
)

cat("Species to process:", paste(names(species_mapping), collapse=", "), "\n\n")

# =============================================================================
# EXTRACT BASELINE STATISTICS
# =============================================================================
extract_baseline_stats <- function(species_name, shapefile) {
  cat("Extracting baseline statistics for", species_name, "\n")
  
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Baseline", dir_name)
  
  stats_df <- data.frame(
    ADM3_EN = shapefile$ADM3_EN,
    ADM3_PCODE = shapefile$ADM3_PCODE,
    ADM2_EN = shapefile$ADM2_EN,
    ADM1_EN = shapefile$ADM1_EN
  )
  
  # Extract presence mean
  presence_mean_path <- file.path(species_dir, paste0(dir_name, "_Presence_Mean.tif"))
  cat("  Processing:", basename(presence_mean_path), "\n")
  r <- rast(presence_mean_path)
  stats_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                         "mean", progress = FALSE)
  cat("    Range: [", round(min(stats_df$presence_mean, na.rm=TRUE), 4), ", ",
      round(max(stats_df$presence_mean, na.rm=TRUE), 4), "]\n", sep="")
  
  # Extract presence standard deviation
  presence_sd_path <- file.path(species_dir, paste0(dir_name, "_Presence_SD.tif"))
  if (file.exists(presence_sd_path)) {
    cat("  Processing:", basename(presence_sd_path), "\n")
    r <- rast(presence_sd_path)
    stats_df$presence_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                         "mean", progress = FALSE)
  }
  
  # Extract presence confidence intervals
  presence_lower_path <- file.path(species_dir, paste0(dir_name, "_Presence_Lower95.tif"))
  if (file.exists(presence_lower_path)) {
    cat("  Processing:", basename(presence_lower_path), "\n")
    r <- rast(presence_lower_path)
    stats_df$presence_lower <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
  }
  
  presence_upper_path <- file.path(species_dir, paste0(dir_name, "_Presence_Upper95.tif"))
  if (file.exists(presence_upper_path)) {
    cat("  Processing:", basename(presence_upper_path), "\n")
    r <- rast(presence_upper_path)
    stats_df$presence_upper <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
  }
  
  # Extract abundance statistics
  abundance_mean_path <- file.path(species_dir, paste0(dir_name, "_Abundance_Mean.tif"))
  if (file.exists(abundance_mean_path)) {
    cat("  Processing:", basename(abundance_mean_path), "\n")
    r <- rast(abundance_mean_path)
    stats_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
    cat("    Range: [", round(min(stats_df$abundance_mean, na.rm=TRUE), 2), ", ",
        round(max(stats_df$abundance_mean, na.rm=TRUE), 2), "]\n", sep="")
    
    abundance_sd_path <- file.path(species_dir, paste0(dir_name, "_Abundance_SD.tif"))
    if (file.exists(abundance_sd_path)) {
      cat("  Processing:", basename(abundance_sd_path), "\n")
      r <- rast(abundance_sd_path)
      stats_df$abundance_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
    }
  }
  
  cat("Baseline extraction complete\n\n")
  return(stats_df)
}

# =============================================================================
# EXTRACT MONTHLY STATISTICS
# =============================================================================
extract_monthly_stats <- function(species_name, shapefile) {
  cat("Extracting monthly statistics for", species_name, "\n")
  
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Monthly", dir_name)
  
  if (!dir.exists(species_dir)) {
    cat("Monthly directory not found\n\n")
    return(NULL)
  }
  
  monthly_stats <- list()
  
  for (month in month_names) {
    presence_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Presence.tif"))
    
    if (!file.exists(presence_path)) {
      cat("  ", month, ": file not found, skipping\n")
      next
    }
    
    cat("  Processing:", month, "\n")
    
    month_df <- data.frame(
      ADM3_EN = shapefile$ADM3_EN,
      ADM3_PCODE = shapefile$ADM3_PCODE,
      ADM2_EN = shapefile$ADM2_EN,
      ADM1_EN = shapefile$ADM1_EN,
      month = month
    )
    
    # Extract presence
    r <- rast(presence_path)
    month_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                           "mean", progress = FALSE)
    
    # Extract abundance if available
    abundance_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Abundance.tif"))
    if (file.exists(abundance_path)) {
      r <- rast(abundance_path)
      month_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                              "mean", progress = FALSE)
    }
    
    monthly_stats[[month]] <- month_df
  }
  
  cat("Monthly extraction complete (", length(monthly_stats), " months processed)\n\n", sep="")
  return(monthly_stats)
}

# =============================================================================
# CREATE INTERACTIVE MAP
# =============================================================================
create_interactive_map <- function(species_name, shapefile, baseline_stats,
                                  monthly_stats, output_path) {
  cat("Creating interactive map for", species_name, "\n")
  
  # Join baseline statistics to shapefile
  map_data <- shapefile %>%
    left_join(baseline_stats, by = c("ADM3_EN", "ADM3_PCODE"))
  
  # Log presence data range
  cat("  Presence range: [", round(min(map_data$presence_mean, na.rm=TRUE), 4), ", ",
      round(max(map_data$presence_mean, na.rm=TRUE), 4), "]\n", sep="")
  
  # Determine global maximum abundance for consistent scaling
  max_abundance_baseline <- if("abundance_mean" %in% names(map_data)) {
    max(map_data$abundance_mean, na.rm=TRUE)
  } else {
    0
  }
  
  max_abundance_monthly <- 0
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    for (month in names(monthly_stats)) {
      if ("abundance_mean" %in% names(monthly_stats[[month]])) {
        month_max <- max(monthly_stats[[month]]$abundance_mean, na.rm=TRUE)
        if (month_max > max_abundance_monthly) {
          max_abundance_monthly <- month_max
        }
      }
    }
  }
  
  max_abundance_global <- max(max_abundance_baseline, max_abundance_monthly)
  cat("  Global max abundance:", round(max_abundance_global, 2), "\n")
  
  # Define color palettes with fixed domains
  presence_pal <- colorNumeric("magma", domain = c(0, 1), na.color = "transparent")
  
  has_abundance <- "abundance_mean" %in% names(map_data)
  if (has_abundance) {
    abundance_pal <- colorNumeric("magma",
                                 domain = c(0, max_abundance_global),
                                 na.color = "transparent")
  }
  
  # Initialize leaflet map
  map <- leaflet(map_data) %>%
    addProviderTiles(providers$CartoDB.Positron, group = "Light") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "Satellite") %>%
    setView(lng = -72.3, lat = 19, zoom = 8)
  
  # Add baseline presence layer
  cat("  Adding baseline presence layer\n")
  map <- map %>%
    addPolygons(
      fillColor = ~presence_pal(presence_mean),
      fillOpacity = 0.7,
      color = "#666666",
      weight = 1,
      opacity = 0.5,
      smoothFactor = 0.5,
      layerId = ~ADM3_PCODE,
      group = "Baseline: Presence",
      highlightOptions = highlightOptions(
        weight = 2,
        color = "#333",
        fillOpacity = 0.9,
        bringToFront = TRUE
      ),
      popup = ~paste0(
        "<div style='font-family: Arial; font-size: 12px;'>",
        "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
        "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
        "<hr style='margin: 5px 0;'/>",
        "<b>Presence Probability:</b> ", round(presence_mean, 4),
        if("presence_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", round(presence_sd, 4)) else "",
        "</div>"
      )
    ) %>%
    addLegend(pal = presence_pal, values = c(0, 1),
             title = "Presence<br/>Probability", position = "bottomright",
             group = "Baseline: Presence", layerId = "legend_baseline_presence")
  
  # Add baseline abundance layer if available
  if (has_abundance) {
    cat("  Adding baseline abundance layer\n")
    map <- map %>%
      addPolygons(
        data = map_data,
        fillColor = ~abundance_pal(abundance_mean),
        fillOpacity = 0.7,
        color = "#666666",
        weight = 1,
        opacity = 0.5,
        smoothFactor = 0.5,
        layerId = ~paste0(ADM3_PCODE, "_abund"),
        group = "Baseline: Abundance",
        highlightOptions = highlightOptions(
          weight = 2,
          color = "#333",
          fillOpacity = 0.9,
          bringToFront = TRUE
        ),
        popup = ~paste0(
          "<div style='font-family: Arial; font-size: 12px;'>",
          "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
          "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
          "<hr style='margin: 5px 0;'/>",
          "<b>Expected Abundance:</b> ", round(abundance_mean, 2),
          if("abundance_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", round(abundance_sd, 2)) else "",
          "</div>"
        )
      ) %>%
      addLegend(pal = abundance_pal, values = c(0, max_abundance_global),
               title = "Expected<br/>Abundance", position = "bottomright",
               group = "Baseline: Abundance", layerId = "legend_baseline_abundance")
  }
  
  # Add monthly layers
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    cat("  Adding monthly layers (", length(monthly_stats), " months)\n", sep="")
    
    for (month in names(monthly_stats)) {
      month_data <- monthly_stats[[month]]
      month_map_data <- shapefile %>%
        left_join(month_data, by = c("ADM3_EN", "ADM3_PCODE"))
      
      has_monthly_abundance <- "abundance_mean" %in% names(month_map_data)
      
      # Add monthly presence layer
      map <- map %>%
        addPolygons(
          data = month_map_data,
          fillColor = ~presence_pal(presence_mean),
          fillOpacity = 0.7,
          color = "#666666",
          weight = 1,
          opacity = 0.5,
          smoothFactor = 0.5,
          layerId = ~paste0(ADM3_PCODE, "_", month, "_pres"),
          group = paste0("Monthly Presence: ", month),
          highlightOptions = highlightOptions(
            weight = 2,
            color = "#333",
            fillOpacity = 0.9,
            bringToFront = TRUE
          ),
          popup = ~paste0(
            "<div style='font-family: Arial; font-size: 12px;'>",
            "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
            "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
            "<b style='color: #e67e22;'>", month, " - Presence</b>",
            "<hr style='margin: 5px 0;'/>",
            "<b>Presence Probability:</b> ", round(presence_mean, 4),
            "</div>"
          )
        ) %>%
        addLegend(pal = presence_pal, values = c(0, 1),
                 title = paste0(month, "<br/>Presence"), position = "bottomright",
                 group = paste0("Monthly Presence: ", month),
                 layerId = paste0("legend_", month, "_pres"))
      
      # Add monthly abundance layer if available
      if (has_monthly_abundance) {
        map <- map %>%
          addPolygons(
            data = month_map_data,
            fillColor = ~abundance_pal(abundance_mean),
            fillOpacity = 0.7,
            color = "#666666",
            weight = 1,
            opacity = 0.5,
            smoothFactor = 0.5,
            layerId = ~paste0(ADM3_PCODE, "_", month, "_abund"),
            group = paste0("Monthly Abundance: ", month),
            highlightOptions = highlightOptions(
              weight = 2,
              color = "#333",
              fillOpacity = 0.9,
              bringToFront = TRUE
            ),
            popup = ~paste0(
              "<div style='font-family: Arial; font-size: 12px;'>",
              "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
              "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
              "<b style='color: #e67e22;'>", month, " - Abundance</b>",
              "<hr style='margin: 5px 0;'/>",
              "<b>Expected Abundance:</b> ", round(abundance_mean, 2),
              "</div>"
            )
          ) %>%
          addLegend(pal = abundance_pal, values = c(0, max_abundance_global),
                   title = paste0(month, "<br/>Abundance"), position = "bottomright",
                   group = paste0("Monthly Abundance: ", month),
                   layerId = paste0("legend_", month, "_abund"))
      }
    }
  }
  
  # Configure layer controls
  cat("  Configuring layer controls\n")
  base_groups <- c("Baseline: Presence")
  if (has_abundance) base_groups <- c(base_groups, "Baseline: Abundance")
  
  monthly_presence_groups <- paste0("Monthly Presence: ", names(monthly_stats))
  monthly_abundance_groups <- paste0("Monthly Abundance: ", names(monthly_stats))
  all_groups <- c(base_groups, monthly_presence_groups, monthly_abundance_groups)
  
  map <- map %>%
    addLayersControl(
      baseGroups = c("Light", "Satellite"),
      overlayGroups = all_groups,
      options = layersControlOptions(collapsed = FALSE),
      position = "topright"
    ) %>%
    hideGroup(c(monthly_presence_groups, monthly_abundance_groups)) %>%
    hideGroup(if(has_abundance) "Baseline: Abundance" else NULL)
  
  # Add title with italicized species name
  species_formatted <- gsub("_", " ", species_name)
  title_control <- tags$div(
    style = "margin: 10px; padding: 12px 20px; background: white;
             border-radius: 5px; box-shadow: 0 2px 6px rgba(0,0,0,0.2);
             display: inline-block;",
    tags$h3(
      style = "margin: 0; font-size: 18px; font-style: italic;",
      species_formatted
    )
  )
  
  map <- map %>%
    addControl(title_control, position = "topleft")
  
  # Save map to file
  cat("  Saving map to:", basename(output_path), "\n")
  saveWidget(map, output_path, selfcontained = TRUE)
  cat("Map creation complete for", species_name, "\n\n")
  
  return(map)
}

# =============================================================================
# PROCESS ALL SPECIES
# =============================================================================
cat("=======================================================================\n")
cat("PROCESSING ALL SPECIES\n")
cat("=======================================================================\n\n")

for (species_name in names(species_mapping)) {
  cat("-----------------------------------------------------------------------\n")
  cat("Species:", species_name, "\n")
  cat("-----------------------------------------------------------------------\n\n")
  
  # Extract baseline statistics
  cat("Step 1/3: Extracting baseline statistics\n")
  baseline_stats <- extract_baseline_stats(species_name, Haiti_adm3)
  
  # Extract monthly statistics
  cat("Step 2/3: Extracting monthly statistics\n")
  monthly_stats <- extract_monthly_stats(species_name, Haiti_adm3)
  
  # Create interactive map
  cat("Step 3/3: Creating interactive map\n")
  output_file <- file.path(output_dir, paste0(species_name, "_Interactive.html"))
  
  species_map <- create_interactive_map(
    species_name = species_name,
    shapefile = Haiti_adm3,
    baseline_stats = baseline_stats,
    monthly_stats = monthly_stats,
    output_path = output_file
  )
  
  cat(species_name, "processing complete\n")
  cat("Output saved to:", output_file, "\n\n")
}

cat("=======================================================================\n")
cat("ALL SPECIES PROCESSING COMPLETE\n")
cat("=======================================================================\n\n")
cat("Output directory:", output_dir, "\n")
cat("Total species processed:", length(species_mapping), "\n")
```



```{r Interactive Leaflet Maps with Zonal Statistics}
# =============================================================================
# MOSQUITO SPECIES INTERACTIVE MAP GENERATION - ALL SPECIES
# =============================================================================
library(raster)
library(terra)
library(sf)
library(exactextractr)
library(leaflet)
library(leaflet.extras)
library(htmltools)
library(htmlwidgets)
library(viridis)
library(dplyr)

cat("\n=======================================================================\n")
cat("  CREATING INTERACTIVE MAPS FOR ALL SPECIES\n")
cat("=======================================================================\n\n")

# Configuration
prediction_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"
output_dir <- file.path(prediction_base, "Interactive_Maps")
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

# CORRECTED: Aem is Aedes mediovittatus, not Anopheles
species_mapping <- c(
  "Aedes_aegypti" = "Aeae",
  "Aedes_albopictus" = "Aealb",
  "Aedes_mediovittatus" = "Aem",
  "Culex_nigripalpus" = "Cxn",
  "Culex_quinquefasciatus" = "Quinx",
  "Psorophora_columbiae" = "Psc"
)

cat("Species to process:\n")
for (i in 1:length(species_mapping)) {
  cat("  ", names(species_mapping)[i], "\n", sep="")
}
cat("\n")

# =============================================================================
# EXTRACT BASELINE STATISTICS
# =============================================================================
extract_baseline_stats <- function(species_name, shapefile) {
  cat("Extracting baseline statistics\n")
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Baseline", dir_name)
  
  stats_df <- data.frame(
    ADM3_EN = shapefile$ADM3_EN,
    ADM3_PCODE = shapefile$ADM3_PCODE,
    ADM2_EN = shapefile$ADM2_EN,
    ADM1_EN = shapefile$ADM1_EN
  )
  
  # PRESENCE FILES (use Presence_Mean.tif, NOT Combined_Mean.tif)
  presence_mean_path <- file.path(species_dir, paste0(dir_name, "_Presence_Mean.tif"))
  cat("  Extracting:", basename(presence_mean_path), "\n")
  r <- rast(presence_mean_path)
  stats_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                         "mean", progress = FALSE)
  cat("    Range: [", round(min(stats_df$presence_mean, na.rm=TRUE), 4), ", ",
      round(max(stats_df$presence_mean, na.rm=TRUE), 4), "]\n", sep="")
  
  # Presence SD
  presence_sd_path <- file.path(species_dir, paste0(dir_name, "_Presence_SD.tif"))
  if (file.exists(presence_sd_path)) {
    cat("  Extracting:", basename(presence_sd_path), "\n")
    r <- rast(presence_sd_path)
    stats_df$presence_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                         "mean", progress = FALSE)
  }
  
  # Presence CI
  presence_lower_path <- file.path(species_dir, paste0(dir_name, "_Presence_Lower95.tif"))
  if (file.exists(presence_lower_path)) {
    cat("  Extracting:", basename(presence_lower_path), "\n")
    r <- rast(presence_lower_path)
    stats_df$presence_lower <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
  }
  
  presence_upper_path <- file.path(species_dir, paste0(dir_name, "_Presence_Upper95.tif"))
  if (file.exists(presence_upper_path)) {
    cat("  Extracting:", basename(presence_upper_path), "\n")
    r <- rast(presence_upper_path)
    stats_df$presence_upper <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
  }
  
  # ABUNDANCE FILES
  abundance_mean_path <- file.path(species_dir, paste0(dir_name, "_Abundance_Mean.tif"))
  if (file.exists(abundance_mean_path)) {
    cat("  Extracting:", basename(abundance_mean_path), "\n")
    r <- rast(abundance_mean_path)
    stats_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
    cat("    Range: [", round(min(stats_df$abundance_mean, na.rm=TRUE), 2), ", ",
        round(max(stats_df$abundance_mean, na.rm=TRUE), 2), "]\n", sep="")
    
    abundance_sd_path <- file.path(species_dir, paste0(dir_name, "_Abundance_SD.tif"))
    if (file.exists(abundance_sd_path)) {
      cat("  Extracting:", basename(abundance_sd_path), "\n")
      r <- rast(abundance_sd_path)
      stats_df$abundance_sd <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                            "mean", progress = FALSE)
    }
  }
  
  cat("Baseline extraction complete\n\n")
  return(stats_df)
}

# =============================================================================
# EXTRACT MONTHLY STATISTICS
# =============================================================================
extract_monthly_stats <- function(species_name, shapefile) {
  cat("Extracting monthly statistics\n")
  dir_name <- species_mapping[species_name]
  species_dir <- file.path(prediction_base, "Monthly", dir_name)
  
  if (!dir.exists(species_dir)) {
    cat("Monthly directory not found\n")
    return(NULL)
  }
  
  monthly_stats <- list()
  
  for (month in month_names) {
    presence_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Presence.tif"))
    if (!file.exists(presence_path)) {
      cat("  ", month, ": file not found, skipping\n")
      next
    }
    
    cat("  ", month, "\n", sep="")
    
    month_df <- data.frame(
      ADM3_EN = shapefile$ADM3_EN,
      ADM3_PCODE = shapefile$ADM3_PCODE,
      ADM2_EN = shapefile$ADM2_EN,
      ADM1_EN = shapefile$ADM1_EN,
      month = month
    )
    
    r <- rast(presence_path)
    month_df$presence_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                           "mean", progress = FALSE)
    
    # Abundance
    abundance_path <- file.path(species_dir, paste0(dir_name, "_", month, "_Abundance.tif"))
    if (file.exists(abundance_path)) {
      r <- rast(abundance_path)
      month_df$abundance_mean <- exact_extract(r, st_transform(shapefile, st_crs(crs(r, proj=TRUE))),
                                              "mean", progress = FALSE)
    }
    
    monthly_stats[[month]] <- month_df
  }
  
  cat("Monthly extraction complete (", length(monthly_stats), " months)\n\n", sep="")
  return(monthly_stats)
}

# =============================================================================
# CREATE INTERACTIVE MAP
# =============================================================================
create_interactive_map <- function(species_name, shapefile, baseline_stats,
                                  monthly_stats, output_path) {
  cat("Creating interactive map\n")
  
  # Join baseline to shapefile
  map_data <- shapefile %>%
    left_join(baseline_stats, by = c("ADM3_EN", "ADM3_PCODE"))
  
  # Verify presence is valid probability
  cat("  Presence range: [", round(min(map_data$presence_mean, na.rm=TRUE), 4), ", ",
      round(max(map_data$presence_mean, na.rm=TRUE), 4), "]\n", sep="")
  
  # Determine global max abundance for consistent scaling
  max_abundance_baseline <- if("abundance_mean" %in% names(map_data)) {
    max(map_data$abundance_mean, na.rm=TRUE)
  } else {
    0
  }
  
  max_abundance_monthly <- 0
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    for (month in names(monthly_stats)) {
      if ("abundance_mean" %in% names(monthly_stats[[month]])) {
        month_max <- max(monthly_stats[[month]]$abundance_mean, na.rm=TRUE)
        if (month_max > max_abundance_monthly) {
          max_abundance_monthly <- month_max
        }
      }
    }
  }
  
  max_abundance_global <- max(max_abundance_baseline, max_abundance_monthly)
  cat("  Global max abundance:", round(max_abundance_global, 2), "\n")
  
  # Color palettes - ALL USE MAGMA, with fixed domains
  presence_pal <- colorNumeric("magma", domain = c(0, 1), na.color = "transparent")
  
  has_abundance <- "abundance_mean" %in% names(map_data)
  if (has_abundance) {
    abundance_pal <- colorNumeric("magma",
                                 domain = c(0, max_abundance_global),
                                 na.color = "transparent")
  }
  
  # Initialize map
  map <- leaflet(map_data) %>%
    addProviderTiles(providers$CartoDB.Positron, group = "Light") %>%
    addProviderTiles(providers$Esri.WorldImagery, group = "Satellite") %>%
    setView(lng = -72.3, lat = 19, zoom = 8)
  
  # Baseline Presence
  cat("  Adding baseline presence layer\n")
  map <- map %>%
    addPolygons(
      fillColor = ~presence_pal(presence_mean),
      fillOpacity = 0.7,
      color = "#666666",
      weight = 1,
      opacity = 0.5,
      smoothFactor = 0.5,
      layerId = ~ADM3_PCODE,
      group = "Baseline: Presence",
      highlightOptions = highlightOptions(
        weight = 2,
        color = "#333",
        fillOpacity = 0.9,
        bringToFront = TRUE
      ),
      popup = ~paste0(
        "<div style='font-family: Arial; font-size: 12px;'>",
        "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
        "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
        "<hr style='margin: 5px 0;'/>",
        "<b>Presence Probability:</b> ", round(presence_mean, 4),
        if("presence_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", round(presence_sd, 4)) else "",
        "</div>"
      )
    ) %>%
    addLegend(pal = presence_pal, values = c(0, 1),
             title = "Presence<br/>Probability", position = "bottomright",
             group = "Baseline: Presence", layerId = "legend_baseline_presence")
  
  # Baseline Abundance
  if (has_abundance) {
    cat("  Adding baseline abundance layer\n")
    map <- map %>%
      addPolygons(
        data = map_data,
        fillColor = ~abundance_pal(abundance_mean),
        fillOpacity = 0.7,
        color = "#666666",
        weight = 1,
        opacity = 0.5,
        smoothFactor = 0.5,
        layerId = ~paste0(ADM3_PCODE, "_abund"),
        group = "Baseline: Abundance",
        highlightOptions = highlightOptions(
          weight = 2,
          color = "#333",
          fillOpacity = 0.9,
          bringToFront = TRUE
        ),
        popup = ~paste0(
          "<div style='font-family: Arial; font-size: 12px;'>",
          "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
          "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span>",
          "<hr style='margin: 5px 0;'/>",
          "<b>Expected Abundance:</b> ", round(abundance_mean, 2),
          if("abundance_sd" %in% names(map_data)) paste0("<br/><b>SD:</b> ± ", round(abundance_sd, 2)) else "",
          "</div>"
        )
      ) %>%
      addLegend(pal = abundance_pal, values = c(0, max_abundance_global),
               title = "Expected<br/>Abundance", position = "bottomright",
               group = "Baseline: Abundance", layerId = "legend_baseline_abundance")
  }
  
  # Monthly Layers
  if (!is.null(monthly_stats) && length(monthly_stats) > 0) {
    cat("  Adding monthly layers (", length(monthly_stats), " months)\n", sep="")
    
    for (month in names(monthly_stats)) {
      month_data <- monthly_stats[[month]]
      month_map_data <- shapefile %>%
        left_join(month_data, by = c("ADM3_EN", "ADM3_PCODE"))
      
      has_monthly_abundance <- "abundance_mean" %in% names(month_map_data)
      
      # Monthly Presence
      map <- map %>%
        addPolygons(
          data = month_map_data,
          fillColor = ~presence_pal(presence_mean),
          fillOpacity = 0.7,
          color = "#666666",
          weight = 1,
          opacity = 0.5,
          smoothFactor = 0.5,
          layerId = ~paste0(ADM3_PCODE, "_", month, "_pres"),
          group = paste0("Monthly Presence: ", month),
          highlightOptions = highlightOptions(
            weight = 2,
            color = "#333",
            fillOpacity = 0.9,
            bringToFront = TRUE
          ),
          popup = ~paste0(
            "<div style='font-family: Arial; font-size: 12px;'>",
            "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
            "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
            "<b style='color: #e67e22;'>", month, " - Presence</b>",
            "<hr style='margin: 5px 0;'/>",
            "<b>Presence Probability:</b> ", round(presence_mean, 4),
            "</div>"
          )
        ) %>%
        addLegend(pal = presence_pal, values = c(0, 1),
                 title = paste0(month, "<br/>Presence"), position = "bottomright",
                 group = paste0("Monthly Presence: ", month),
                 layerId = paste0("legend_", month, "_pres"))
      
      # Monthly Abundance (if available)
      if (has_monthly_abundance) {
        map <- map %>%
          addPolygons(
            data = month_map_data,
            fillColor = ~abundance_pal(abundance_mean),
            fillOpacity = 0.7,
            color = "#666666",
            weight = 1,
            opacity = 0.5,
            smoothFactor = 0.5,
            layerId = ~paste0(ADM3_PCODE, "_", month, "_abund"),
            group = paste0("Monthly Abundance: ", month),
            highlightOptions = highlightOptions(
              weight = 2,
              color = "#333",
              fillOpacity = 0.9,
              bringToFront = TRUE
            ),
            popup = ~paste0(
              "<div style='font-family: Arial; font-size: 12px;'>",
              "<b style='font-size: 14px;'>", ADM3_EN, "</b><br/>",
              "<span style='color: #666; font-size: 11px;'>", ADM2_EN.x, ", ", ADM1_EN.x, "</span><br/>",
              "<b style='color: #e67e22;'>", month, " - Abundance</b>",
              "<hr style='margin: 5px 0;'/>",
              "<b>Expected Abundance:</b> ", round(abundance_mean, 2),
              "</div>"
            )
          ) %>%
          addLegend(pal = abundance_pal, values = c(0, max_abundance_global),
                   title = paste0(month, "<br/>Abundance"), position = "bottomright",
                   group = paste0("Monthly Abundance: ", month),
                   layerId = paste0("legend_", month, "_abund"))
      }
    }
  }
  
  # Layer Controls
  cat("  Adding controls\n")
  base_groups <- c("Baseline: Presence")
  if (has_abundance) base_groups <- c(base_groups, "Baseline: Abundance")
  
  monthly_presence_groups <- paste0("Monthly Presence: ", names(monthly_stats))
  monthly_abundance_groups <- paste0("Monthly Abundance: ", names(monthly_stats))
  all_groups <- c(base_groups, monthly_presence_groups, monthly_abundance_groups)
  
  map <- map %>%
    addLayersControl(
      baseGroups = c("Light", "Satellite"),
      overlayGroups = all_groups,
      options = layersControlOptions(collapsed = FALSE),
      position = "topright"
    ) %>%
    hideGroup(c(monthly_presence_groups, monthly_abundance_groups)) %>%
    hideGroup(if(has_abundance) "Baseline: Abundance" else NULL)
  
  # Title - Using CSS font-style for italics
  species_formatted <- gsub("_", " ", species_name)
  title_control <- tags$div(
    style = "margin: 10px; padding: 12px 20px; background: white;
             border-radius: 5px; box-shadow: 0 2px 6px rgba(0,0,0,0.2);
             display: inline-block;",
    tags$h3(
      style = "margin: 0; font-size: 18px; font-style: italic;",
      species_formatted
    )
  )
  
  map <- map %>%
    addControl(title_control, position = "topleft")
  
  # Save
  cat("  Saving to:", basename(output_path), "\n")
  saveWidget(map, output_path, selfcontained = TRUE)
  cat("Map created successfully\n\n")
  
  return(map)
}

# =============================================================================
# PROCESS ALL SPECIES
# =============================================================================
cat("=======================================================================\n")
cat("PROCESSING ALL SPECIES\n")
cat("=======================================================================\n\n")

species_count <- 0
species_total <- length(species_mapping)

for (species_name in names(species_mapping)) {
  species_count <- species_count + 1
  
  cat("=======================================================================\n")
  cat("STEP ", species_count, " OF ", species_total, ": ", species_name, "\n", sep="")
  cat("=======================================================================\n\n")
  
  # Step 1: Extract baseline statistics
  cat("STEP 1: Extract baseline statistics\n")
  cat("-----------------------------------------------------------------------\n")
  baseline_stats <- extract_baseline_stats(species_name, Haiti_adm3)
  
  # Step 2: Extract monthly statistics
  cat("STEP 2: Extract monthly statistics\n")
  cat("-----------------------------------------------------------------------\n")
  monthly_stats <- extract_monthly_stats(species_name, Haiti_adm3)
  
  # Step 3: Create interactive map
  cat("STEP 3: Create interactive map\n")
  cat("-----------------------------------------------------------------------\n")
  output_file <- file.path(output_dir, paste0(species_name, "_Interactive.html"))
  
  species_map <- create_interactive_map(
    species_name = species_name,
    shapefile = Haiti_adm3,
    baseline_stats = baseline_stats,
    monthly_stats = monthly_stats,
    output_path = output_file
  )
  
  cat("COMPLETED: ", species_name, "\n", sep="")
  cat("Output file: ", output_file, "\n\n", sep="")
}

cat("=======================================================================\n")
cat("ALL SPECIES PROCESSING COMPLETE\n")
cat("=======================================================================\n\n")
cat("Output directory: ", output_dir, "\n", sep="")
cat("Total species processed: ", species_total, "\n", sep="")

```



```{r Code for hurdle models}

  # Fit the global hurdle models
    Glob.Hurd.Aeae <- pscl::hurdle(
      Aeae ~ Precip + TMean + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )
  
    Glob.Hurd.Aealb <- hurdle(
      Aealb ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )  
  
    Glob.Hurd.Quinx <- hurdle(
      Quinx ~ Precip + TMean + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Cxq, 
      dist = "negbin"
    )
  
    Glob.Hurd.Cxn <- hurdle(
      Cxn ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Cxn, 
      dist = "negbin"
    )

    Glob.Hurd.Aem <- hurdle(
      Aem ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Aem, 
      dist = "negbin"
    )
  
    Glob.Hurd.Psc <- hurdle(
      Psc ~ Precip + TMean  + nightlight + Elevation | Precip + TMean + nightlight + Elevation, 
      data = HCM_Full_Psc, 
      dist = "negbin"
    )    
      
  # Prepare for dredging
    options(na.action = "na.fail")
  
  # Create a cluster for parallel processing
    cl <- makeCluster(detectCores() - 1)
    clusterEvalQ(cl, {
      library(MuMIn)
      library(countreg)
      library(sp)
      library(parallel)
    })
    
    clusterExport(cl, list("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq", "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc", 
                           "Glob.Hurd.Aeae", "Glob.Hurd.Aealb", "Glob.Hurd.Quinx", "Glob.Hurd.Cxn", "Glob.Hurd.Aem", "Glob.Hurd.Psc"))
  

  # Perform the dredge operation, excluding models with both count_Precip and count_TMean
    Dredge.Aeae <- dredge(Glob.Hurd.Aeae, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Aealb <- dredge(Glob.Hurd.Aealb, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Quinx <- dredge(Glob.Hurd.Quinx, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Cxn <- dredge(Glob.Hurd.Cxn, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Aem <- dredge(Glob.Hurd.Aem, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)
    Dredge.Psc <- dredge(Glob.Hurd.Psc, subset = !(count_Precip & count_TMean) & !(zero_Precip & zero_TMean), cluster = "cl", trace = TRUE)  
    
  # Stop the cluster after dredging
    stopCluster(cl)
  
  # Reset the NA action to omit missing values
    options(na.action = "na.omit")
  
  # "Best" Aeae Model
    Aeae_Top10 <- get.models(Dredge.Aeae, subset = 1:10)
    View(Aeae_Top10)
  
  # "Best" Aealb Model
    Aealb_Top10 <- get.models(Dredge.Aealb, subset = 1:10)
    View(Aealb_Top10)
  
  # "Best" Quinx Model
    Quinx_Top10 <- get.models(Dredge.Quinx, subset = 1:10)
    View(Quinx_Top10)
  
  # "Best" Cxn Model
    Cxn_Top10 <- get.models(Dredge.Cxn, subset = 1:10)
    View(Cxn_Top10)
  
  # "Best" Aem Model
    Aem_Top10 <- get.models(Dredge.Aem, subset = 1:10)
    View(Aem_Top10)
  
  # "Best" Psc Model
    Psc_Top10 <- get.models(Dredge.Psc, subset = 1:10)
    View(Psc_Top10)
  
  # Extract the "best" model for each species
    Best.Aeae <- get.models(Dredge.Aeae, subset = 1)[[1]]
    Best.Aealb <- get.models(Dredge.Aealb, subset = 1)[[1]]
    Best.Quinx <- get.models(Dredge.Quinx, subset = 1)[[1]]
    Best.Cxn <- get.models(Dredge.Cxn, subset = 1)[[1]]
    Best.Aem <- get.models(Dredge.Aem, subset = 1)[[1]]
    Best.Psc <- get.models(Dredge.Psc, subset = 1)[[1]]
    
  # Summarize the "best" models for each species
    summary(Best.Aeae)
    summary(Best.Aealb)
    summary(Best.Quinx)
    summary(Best.Aem)
    summary(Best.Cxn)
    summary(Best.Psc)


  # Aedes aegypti Model
    Best.Aeae <- pscl::hurdle(
      Aeae ~ Elevation + nightlight + Precip | Elevation + nightlight + Precip, 
      data = HCM_Full_Aeae, 
      dist = "negbin"
    )

  # Aedes albopictus Model
    Best.Aealb <- pscl::hurdle(
      Aealb ~ Elevation + nightlight + Precip | Elevation + nightlight + TMean, 
      data = HCM_Full_Aealb, 
      dist = "negbin"
    )

  # Culex quinquefasciatus Model
    Best.Quinx <- pscl::hurdle(
      Quinx ~ TMean | Elevation + nightlight + Precip, 
      data = HCM_Full_Cxq, 
      dist = "negbin"
    )

  # Culex nigripalpus Model
    Best.Cxn <- pscl::hurdle(
      Cxn ~ Precip | Elevation + nightlight + Precip, 
      data = HCM_Full_Cxn, 
      dist = "negbin"
    )    
      
  # Aedes mediovittatus Model
    Best.Aem <- pscl::hurdle(
      Aem ~ Precip | Elevation + nightlight, 
      data = HCM_Full_Aem, 
      dist = "negbin"
    )  
    
  # Psorophora columbiae Model      
    Best.Psc <- pscl::hurdle(
      Psc ~ Elevation + nightlight + TMean | TMean + nightlight + Elevation, 
      data = HCM_Full_Psc, 
      dist = "negbin"
    )  


```



```{r BRT Code w/o landcover}

library(pROC)
library(caret)
library(purrr)
library(dplyr)
library(dismo)
library(gbm)

# ---------------------------
# Variable Configuration
# ---------------------------

# Climate and environmental covariates (NO land cover variables)
covariates <- c("Precip", "TMean", "WindMean", "nightlight", "Elevation")

# Define species and their datasets
species_list <- c("Aeae", "Aealb", "Quinx", "Aem", "Cxn", "Psc")
dataset_names <- c("HCM_Full_Aeae", "HCM_Full_Aealb", "HCM_Full_Cxq",
                   "HCM_Full_Aem", "HCM_Full_Cxn", "HCM_Full_Psc")

# ---------------------------
# Function to determine appropriate tree complexity based on sample size
# ---------------------------
get_tree_complexity <- function(n_present) {
  if (n_present < 100) return(2)       # Very limited data
  else if (n_present < 300) return(3)  # Limited data
  else return(5)                        # Sufficient data
}

# ---------------------------
# Verify covariate availability
# ---------------------------
cat("\n========================================")
cat("\n   CHECKING VARIABLE AVAILABILITY")
cat("\n========================================\n")

# Check if all datasets have required covariates
for (dataset_name in dataset_names) {
  df <- get(dataset_name, envir = .GlobalEnv)
  dataset_vars <- names(df)
  
  missing_vars <- setdiff(covariates, dataset_vars)
  
  cat("\n", dataset_name, ":\n", sep = "")
  if (length(missing_vars) == 0) {
    cat("  All required covariates present\n")
  } else {
    cat("  WARNING: Missing variables:", paste(missing_vars, collapse = ", "), "\n")
  }
}

cat("\n")
cat("Using", length(covariates), "covariates for all models:\n")
cat("  ", paste(covariates, collapse = ", "), "\n\n")

# ---------------------------
# Robust fitting function with retry logic
# ---------------------------
fit_binary_brt_adaptive <- function(species, dataset_name, max_attempts = 3) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Binary <- dataset %>%
    mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
    dplyr::select(SpeciesBin, all_of(covariates)) %>%
    na.omit()
  
  n_present <- sum(HCM_Binary$SpeciesBin == 1)
  n_absent <- sum(HCM_Binary$SpeciesBin == 0)
  tree_comp <- get_tree_complexity(n_present)
  
  cat("\n=== Fitting binary model for", species, "===")
  cat("\n    Dataset:", dataset_name)
  cat("\n    N present:", n_present, "| N absent:", n_absent)
  cat("\n    Prevalence:", round(n_present / nrow(HCM_Binary), 3))
  cat("\n    Tree complexity:", tree_comp)
  cat("\n    Covariates:", length(covariates), "\n")
  
  # Check for sufficient data
  if (n_present < 20) {
    cat("    SKIPPED: Insufficient presences (<20)\n")
    return(NULL)
  }
  
  # Try fitting with multiple attempts
  for (attempt in 1:max_attempts) {
    model <- tryCatch({
      gbm.step(
        data = HCM_Binary,
        gbm.x = covariates,
        gbm.y = "SpeciesBin",
        family = "bernoulli",
        tree.complexity = tree_comp,
        learning.rate = 0.01,
        bag.fraction = 0.75,
        silent = FALSE,
        plot.main = FALSE
      )
    }, error = function(e) {
      cat("    Attempt", attempt, "failed:", e$message, "\n")
      return(NULL)
    })
    
    if (!is.null(model)) {
      cat("    SUCCESS on attempt", attempt, "\n")
      # Store covariates used in model for later prediction
      model$covariates_used <- covariates
      return(model)
    }
  }
  
  cat("    FAILED after", max_attempts, "attempts\n")
  return(NULL)
}

# ---------------------------
# Count model fitting function
# ---------------------------
fit_count_brt_adaptive <- function(species, dataset_name, max_attempts = 3) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Count <- dataset %>%
    filter(.data[[species]] >= 1) %>%
    dplyr::select(all_of(species), all_of(covariates)) %>%
    na.omit()
  
  if (nrow(HCM_Count) == 0) {
    cat("\n=== Count model for", species, "===")
    cat("\n    SKIPPED: No presence records\n")
    return(NULL)
  }
  
  if (nrow(HCM_Count) < 20) {
    cat("\n=== Count model for", species, "===")
    cat("\n    SKIPPED: Insufficient observations (<20)\n")
    return(NULL)
  }
  
  n_present <- nrow(HCM_Count)
  tree_comp <- get_tree_complexity(n_present)
  
  cat("\n=== Fitting count model for", species, "===")
  cat("\n    Dataset:", dataset_name)
  cat("\n    N observations:", n_present)
  cat("\n    Count range:", min(HCM_Count[[species]]), "to", max(HCM_Count[[species]]))
  cat("\n    Mean count:", round(mean(HCM_Count[[species]]), 2))
  cat("\n    Tree complexity:", tree_comp)
  cat("\n    Covariates:", length(covariates), "\n")
  
  # Try fitting with multiple learning rates if needed
  learning_rates <- c(0.01, 0.005, 0.001)
  
  for (attempt in 1:max_attempts) {
    lr <- learning_rates[min(attempt, length(learning_rates))]
    cat("    Attempt", attempt, "with learning rate", lr, "\n")
    
    model <- tryCatch({
      gbm.step(
        data = HCM_Count,
        gbm.x = covariates,
        gbm.y = species,
        family = "poisson",
        tree.complexity = tree_comp,
        learning.rate = lr,
        bag.fraction = 0.75,
        silent = FALSE,
        plot.main = FALSE,
        max.trees = 10000,
        n.minobsinnode = 10
      )
    }, error = function(e) {
      cat("    Attempt", attempt, "failed:", e$message, "\n")
      return(NULL)
    })
    
    if (!is.null(model)) {
      cat("    SUCCESS on attempt", attempt, "\n")
      cat("    Final trees:", model$n.trees, "\n")
      # Store covariates used
      model$covariates_used <- covariates
      return(model)
    }
  }
  
  cat("    FAILED after", max_attempts, "attempts\n")
  return(NULL)
}

# ---------------------------
# Safe assessment functions
# ---------------------------
assess_binary_performance_safe <- function(model, species, dataset_name) {
  if (is.null(model)) {
    return(data.frame(
      Species = species,
      N_Covariates = NA,
      AUC = NA,
      Optimal_Threshold = NA,
      Sensitivity = NA,
      Specificity = NA,
      Accuracy = NA,
      Kappa = NA,
      CV_Correlation = NA,
      CV_Deviance = NA,
      Status = "FAILED"
    ))
  }
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Binary <- dataset %>%
    mutate(SpeciesBin = ifelse(.data[[species]] >= 1, 1, 0)) %>%
    dplyr::select(SpeciesBin, all_of(covariates)) %>%
    na.omit()
  
  pred_prob <- predict(model, HCM_Binary, n.trees = model$gbm.call$best.trees, type = "response")
  
  roc_obj <- roc(HCM_Binary$SpeciesBin, pred_prob)
  coords_best <- coords(roc_obj, "best", best.method = "youden")
  
  pred_class <- ifelse(pred_prob >= coords_best$threshold, 1, 0)
  cm <- confusionMatrix(factor(pred_class, levels = c(0, 1)), 
                        factor(HCM_Binary$SpeciesBin, levels = c(0, 1)))
  
  data.frame(
    Species = species,
    N_Covariates = length(covariates),
    AUC = as.numeric(auc(roc_obj)),
    Optimal_Threshold = coords_best$threshold,
    Sensitivity = coords_best$sensitivity,
    Specificity = coords_best$specificity,
    Accuracy = cm$overall["Accuracy"],
    Kappa = cm$overall["Kappa"],
    CV_Correlation = model$cv.statistics$correlation.mean,
    CV_Deviance = model$cv.statistics$deviance.mean,
    Status = "SUCCESS"
  )
}

assess_count_performance_safe <- function(model, species, dataset_name) {
  if (is.null(model)) {
    return(data.frame(
      Species = species,
      N_Obs = NA,
      N_Covariates = NA,
      Correlation = NA,
      RMSE = NA,
      MAE = NA,
      CV_Correlation = NA,
      CV_Deviance = NA,
      Status = "FAILED"
    ))
  }
  
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  HCM_Count <- dataset %>%
    filter(.data[[species]] >= 1) %>%
    dplyr::select(all_of(species), all_of(covariates)) %>%
    na.omit()
  
  pred_count <- predict(model, HCM_Count, n.trees = model$gbm.call$best.trees, type = "response")
  actual_count <- HCM_Count[[species]]
  
  data.frame(
    Species = species,
    N_Obs = nrow(HCM_Count),
    N_Covariates = length(covariates),
    Correlation = cor(actual_count, pred_count),
    RMSE = sqrt(mean((actual_count - pred_count)^2)),
    MAE = mean(abs(actual_count - pred_count)),
    CV_Correlation = model$cv.statistics$correlation.mean,
    CV_Deviance = model$cv.statistics$deviance.mean,
    Status = "SUCCESS"
  )
}

# ---------------------------
# Fit all models
# ---------------------------
set.seed(1999)

cat("\n========================================")
cat("\n   FITTING BINARY MODELS")
cat("\n========================================\n")

BRT_Binary_models <- map2(species_list, dataset_names, fit_binary_brt_adaptive) %>%
  set_names(species_list)

cat("\n========================================")
cat("\n   FITTING COUNT MODELS")
cat("\n========================================\n")

BRT_Count_models <- map2(species_list, dataset_names, fit_count_brt_adaptive) %>%
  set_names(species_list)

# ---------------------------
# Generate performance tables
# ---------------------------
binary_performance <- pmap_dfr(
  list(BRT_Binary_models, species_list, dataset_names),
  assess_binary_performance_safe
)

count_performance <- pmap_dfr(
  list(BRT_Count_models, species_list, dataset_names),
  assess_count_performance_safe
)

# Sample diagnostics table
sample_diagnostics <- map2_dfr(species_list, dataset_names, function(species, dataset_name) {
  dataset <- get(dataset_name, envir = .GlobalEnv)
  
  data.frame(
    Species = species,
    Total_Obs = nrow(dataset),
    N_Present = sum(dataset[[species]] >= 1),
    N_Absent = sum(dataset[[species]] == 0),
    Prevalence = round(mean(dataset[[species]] >= 1), 3),
    Mean_Count_When_Present = round(mean(dataset[[species]][dataset[[species]] >= 1]), 2)
  )
})

# ---------------------------
# Display results
# ---------------------------
cat("\n========================================")
cat("\n   RESULTS SUMMARY")
cat("\n========================================\n")

cat("\n=== SAMPLE DIAGNOSTICS ===\n")
print(sample_diagnostics, row.names = FALSE)

cat("\n=== BINARY MODEL PERFORMANCE ===\n")
print(binary_performance, row.names = FALSE)

cat("\n=== COUNT MODEL PERFORMANCE ===\n")
print(count_performance, row.names = FALSE)

# Model success summary
cat("\n=== MODEL FITTING SUMMARY ===\n")
binary_success <- sum(!sapply(BRT_Binary_models, is.null))
count_success <- sum(!sapply(BRT_Count_models, is.null))

cat("Binary models successful:", binary_success, "/", length(species_list), "\n")
cat("Count models successful:", count_success, "/", length(species_list), "\n")

if (binary_success < length(species_list)) {
  cat("\nFailed binary models:", 
      paste(species_list[sapply(BRT_Binary_models, is.null)], collapse = ", "), "\n")
}

if (count_success < length(species_list)) {
  cat("Failed count models:", 
      paste(species_list[sapply(BRT_Count_models, is.null)], collapse = ", "), "\n")
}

# ---------------------------
# Variable importance summary
# ---------------------------
cat("\n=== VARIABLE IMPORTANCE ===\n")

for (species in species_list) {
  model <- BRT_Binary_models[[species]]
  if (!is.null(model)) {
    var_imp <- summary(model, plotit = FALSE)
    
    cat("\n", species, ":\n", sep = "")
    var_imp <- var_imp[order(-var_imp$rel.inf), ]
    for (i in 1:nrow(var_imp)) {
      cat(sprintf("  %s: %.2f%%\n", var_imp$var[i], var_imp$rel.inf[i]))
    }
  } else {
    cat("\n", species, ": Model fitting failed\n", sep = "")
  }
}

cat("\n========================================")
cat("\n   MODELING COMPLETE")
cat("\n========================================\n\n")

# Save model objects for predictions
cat("Model objects saved in environment:\n")
cat("  - BRT_Binary_models (list of", length(BRT_Binary_models), "models)\n")
cat("  - BRT_Count_models (list of", length(BRT_Count_models), "models)\n")
cat("  - binary_performance (performance metrics)\n")
cat("  - count_performance (performance metrics)\n\n")

cat("Ready for predictions!\n")

```



```{r Code for new hurdle models}
# ==============================================================================
# HURDLE MODEL FOR SPATIAL PREDICTION - FIXED
# Location-blocked CV for honest performance estimation
# ==============================================================================
library(xgboost)
library(purrr)
library(dplyr)
library(pROC)

# ------------------------------------------------------------------------------
# Configuration
# ------------------------------------------------------------------------------
species_config <- list(
    Aeae  = list(data = "HCM_Full_Aeae",  outcome = "Aeae"),
    Aealb = list(data = "HCM_Full_Aealb", outcome = "Aealb"),
    Cxq   = list(data = "HCM_Full_Cxq",   outcome = "Quinx"),
    Aem   = list(data = "HCM_Full_Aem",   outcome = "Aem"),
    Cxn   = list(data = "HCM_Full_Cxn",   outcome = "Cxn"),
    Psc   = list(data = "HCM_Full_Psc",   outcome = "Psc")
)

model_covariates <- c(
    "Precip", "TMean", "WindMean",
    "nightlight", "Elevation",
    "trees", "shrubs", "cropland", "wetland"
)

# ------------------------------------------------------------------------------
# Hyperparameters
# ------------------------------------------------------------------------------
params_presence <- list(
    objective        = "binary:logistic",
    eval_metric      = "auc",
    max_depth        = 4,
    eta              = 0.02,
    subsample        = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 5,
    lambda           = 1,
    alpha            = 0.1
)

params_abundance <- list(
    objective        = "count:poisson",
    max_depth        = 4,
    eta              = 0.02,
    subsample        = 0.8,
    colsample_bytree = 0.8,
    min_child_weight = 5,
    lambda           = 1,
    alpha            = 0.1
)

# ------------------------------------------------------------------------------
# Location-blocked fold creation
# ------------------------------------------------------------------------------
create_location_folds <- function(df, location_col = "Location", n_folds = 5, seed = 42) {
    locations <- unique(df[[location_col]])
    n_locs <- length(locations)
    
    set.seed(seed)
    loc_assignments <- sample(rep(1:n_folds, length.out = n_locs))
    names(loc_assignments) <- locations
    
    folds <- lapply(1:n_folds, function(f) {
        test_locs <- names(loc_assignments)[loc_assignments == f]
        list(
            train = which(!df[[location_col]] %in% test_locs),
            test  = which(df[[location_col]] %in% test_locs)
        )
    })
    
    return(folds)
}

# ------------------------------------------------------------------------------
# Metrics calculation - FIXED
# ------------------------------------------------------------------------------
calc_presence_metrics <- function(actual, predicted_prob) {
    # Check if we have both classes
    if (length(unique(actual)) < 2) {
        return(list(
            auc = NA,
            threshold = NA,
            sensitivity = NA,
            specificity = NA,
            precision = NA,
            f1 = NA,
            valid = FALSE
        ))
    }
    
    tryCatch({
        roc_obj <- roc(actual, predicted_prob, quiet = TRUE)
        auc_val <- as.numeric(auc(roc_obj))
        
        # Optimal threshold via Youden - extract as numeric
        coords_best <- coords(roc_obj, "best", best.method = "youden",
                              ret = c("threshold", "sensitivity", "specificity"))
        
        # Extract values properly (coords returns a data frame)
        threshold_val <- as.numeric(coords_best[1, "threshold"])
        sensitivity_val <- as.numeric(coords_best[1, "sensitivity"])
        specificity_val <- as.numeric(coords_best[1, "specificity"])
        
        # Metrics at optimal threshold
        pred_class <- as.integer(predicted_prob >= threshold_val)
        tp <- sum(actual == 1 & pred_class == 1)
        tn <- sum(actual == 0 & pred_class == 0)
        fp <- sum(actual == 0 & pred_class == 1)
        fn <- sum(actual == 1 & pred_class == 0)
        
        precision <- ifelse(tp + fp > 0, tp / (tp + fp), 0)
        f1 <- ifelse(precision + sensitivity_val > 0,
                     2 * precision * sensitivity_val / (precision + sensitivity_val), 0)
        
        list(
            auc         = auc_val,
            threshold   = threshold_val,
            sensitivity = sensitivity_val,
            specificity = specificity_val,
            precision   = precision,
            f1          = f1,
            valid       = TRUE
        )
    }, error = function(e) {
        list(
            auc = NA,
            threshold = NA,
            sensitivity = NA,
            specificity = NA,
            precision = NA,
            f1 = NA,
            valid = FALSE
        )
    })
}

calc_abundance_metrics <- function(actual, predicted) {
    if (length(actual) < 3) {
        return(list(
            mae = NA,
            rmse = NA,
            correlation = NA,
            rank_cor = NA,
            valid = FALSE
        ))
    }
    
    mae  <- mean(abs(actual - predicted))
    rmse <- sqrt(mean((actual - predicted)^2))
    cor_val <- cor(actual, predicted, use = "complete.obs")
    cor_spearman <- cor(actual, predicted, method = "spearman", use = "complete.obs")
    
    list(
        mae          = mae,
        rmse         = rmse,
        correlation  = cor_val,
        rank_cor     = cor_spearman,
        valid        = TRUE
    )
}

# ------------------------------------------------------------------------------
# Main training function
# ------------------------------------------------------------------------------
train_hurdle_model <- function(species_name, config, covariates) {
    message("\n", strrep("=", 60))
    message("SPECIES: ", species_name)
    message(strrep("=", 60))
    
    tryCatch({
        # Load data
        df <- get(config$data, envir = .GlobalEnv)
        outcome_col <- config$outcome
        
        # Validate columns
        missing <- setdiff(c(covariates, outcome_col, "Location"), names(df))
        if (length(missing) > 0) {
            stop("Missing columns: ", paste(missing, collapse = ", "))
        }
        
        # Prepare matrices
        X <- as.matrix(df[, covariates])
        y <- df[[outcome_col]]
        
        # Remove incomplete cases
        complete_idx <- complete.cases(X, y)
        X <- X[complete_idx, ]
        y <- y[complete_idx]
        df_complete <- df[complete_idx, ]
        
        message("\nData: ", length(y), " obs, ", sum(y == 0), " zeros (",
                round(100 * mean(y == 0), 1), "%)")
        message("Unique locations: ", n_distinct(df_complete$Location))
        
        # Create location-blocked folds
        folds <- create_location_folds(df_complete, "Location", n_folds = 5)
        
        # ======================================================================
        # PRESENCE MODEL - Location-blocked CV
        # ======================================================================
        message("\n--- PRESENCE MODEL ---")
        presence <- as.integer(y > 0)
        
        # Add class weight for imbalance
        params_p <- params_presence
        params_p$scale_pos_weight <- sum(presence == 0) / sum(presence == 1)
        
        # Cross-validation
        cv_metrics_p <- list()
        cv_rounds_p <- numeric(length(folds))
        
        for (i in seq_along(folds)) {
            idx_train <- folds[[i]]$train
            idx_test  <- folds[[i]]$test
            
            # Check if test fold has both classes
            if (length(unique(presence[idx_test])) < 2) {
                message("  Fold ", i, ": Skipping (only one class in test set)")
                cv_rounds_p[i] <- NA
                cv_metrics_p[[i]] <- list(valid = FALSE)
                next
            }
            
            dtrain <- xgb.DMatrix(X[idx_train, ], label = presence[idx_train])
            dtest  <- xgb.DMatrix(X[idx_test, ], label = presence[idx_test])
            
            # Train with early stopping
            fold_model <- xgb.train(
                params    = params_p,
                data      = dtrain,
                nrounds   = 1000,
                evals     = list(test = dtest),
                early_stopping_rounds = 50,
                verbose   = 0
            )
            
            # Extract best iteration
            best_iter <- attr(fold_model, "early_stop")$best_iteration
            if (is.null(best_iter)) {
                best_iter <- fold_model$niter
            }
            cv_rounds_p[i] <- best_iter
            
            # Evaluate
            pred_prob <- predict(fold_model, dtest)
            cv_metrics_p[[i]] <- calc_presence_metrics(presence[idx_test], pred_prob)
        }
        
        # Filter valid folds
        valid_folds_p <- sapply(cv_metrics_p, function(x) isTRUE(x$valid))
        
        if (sum(valid_folds_p) == 0) {
            warning("No valid CV folds for presence model - results unreliable")
            cv_auc <- NA
            cv_auc_sd <- NA
            cv_threshold <- 0.5
            cv_sens <- NA
            cv_spec <- NA
        } else {
            cv_auc <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "auc"), na.rm = TRUE)
            cv_auc_sd <- sd(sapply(cv_metrics_p[valid_folds_p], `[[`, "auc"), na.rm = TRUE)
            cv_threshold <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "threshold"), na.rm = TRUE)
            cv_sens <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "sensitivity"), na.rm = TRUE)
            cv_spec <- mean(sapply(cv_metrics_p[valid_folds_p], `[[`, "specificity"), na.rm = TRUE)
        }
        
        message("  Valid folds: ", sum(valid_folds_p), "/", length(folds))
        message("  CV AUC: ", round(cv_auc, 4), " ± ", round(cv_auc_sd, 4))
        message("  Optimal threshold: ", round(cv_threshold, 3))
        message("  Sensitivity: ", round(cv_sens, 3), ", Specificity: ", round(cv_spec, 3))
        
        # Train final model on all data
        dtrain_full <- xgb.DMatrix(X, label = presence)
        final_rounds_p <- round(median(cv_rounds_p[!is.na(cv_rounds_p)]))
        
        model_presence <- xgb.train(
            params  = params_p,
            data    = dtrain_full,
            nrounds = final_rounds_p,
            verbose = 0
        )
        
        message("  Final model: ", final_rounds_p, " rounds")
        
        # ======================================================================
        # ABUNDANCE MODEL - Location-blocked CV (positive counts only)
        # ======================================================================
        message("\n--- ABUNDANCE MODEL ---")
        pos_idx <- which(y > 0)
        X_pos <- X[pos_idx, ]
        y_pos <- y[pos_idx]
        df_pos <- df_complete[pos_idx, ]
        
        message("  Positive obs: ", length(y_pos))
        message("  Range: ", min(y_pos), "-", max(y_pos),
                ", Mean: ", round(mean(y_pos), 1),
                ", Var/Mean: ", round(var(y_pos)/mean(y_pos), 1))
        
        # Check for overdispersion
        params_a <- params_abundance
        if (var(y_pos) / mean(y_pos) > 10) {
            message("  High overdispersion - using Tweedie")
            params_a$objective <- "reg:tweedie"
            params_a$tweedie_variance_power <- 1.5
        }
        
        # Create folds for positive data
        folds_pos <- create_location_folds(df_pos, "Location", n_folds = 5)
        
        # Cross-validation
        cv_metrics_a <- list()
        cv_rounds_a <- numeric(length(folds_pos))
        
        for (i in seq_along(folds_pos)) {
            idx_train <- folds_pos[[i]]$train
            idx_test  <- folds_pos[[i]]$test
            
            if (length(idx_test) < 3) {
                message("  Fold ", i, ": Skipping (too few test samples)")
                cv_rounds_a[i] <- NA
                cv_metrics_a[[i]] <- list(valid = FALSE)
                next
            }
            
            dtrain <- xgb.DMatrix(X_pos[idx_train, ], label = y_pos[idx_train])
            dtest  <- xgb.DMatrix(X_pos[idx_test, ], label = y_pos[idx_test])
            
            fold_model <- xgb.train(
                params    = params_a,
                data      = dtrain,
                nrounds   = 1000,
                evals     = list(test = dtest),
                early_stopping_rounds = 50,
                verbose   = 0
            )
            
            # Extract best iteration
            best_iter <- attr(fold_model, "early_stop")$best_iteration
            if (is.null(best_iter)) {
                best_iter <- fold_model$niter
            }
            cv_rounds_a[i] <- best_iter
            
            pred <- predict(fold_model, dtest)
            cv_metrics_a[[i]] <- calc_abundance_metrics(y_pos[idx_test], pred)
        }
        
        # Aggregate valid folds
        valid_folds_a <- sapply(cv_metrics_a, function(x) isTRUE(x$valid))
        cv_mae <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "mae"), na.rm = TRUE)
        cv_cor <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "correlation"), na.rm = TRUE)
        cv_rank_cor <- mean(sapply(cv_metrics_a[valid_folds_a], `[[`, "rank_cor"), na.rm = TRUE)
        
        message("  Valid folds: ", sum(valid_folds_a), "/", length(folds_pos))
        message("  CV MAE: ", round(cv_mae, 2))
        message("  CV Pearson r: ", round(cv_cor, 4))
        message("  CV Spearman ρ: ", round(cv_rank_cor, 4))
        
        # Train final model
        dtrain_full_a <- xgb.DMatrix(X_pos, label = y_pos)
        final_rounds_a <- round(median(cv_rounds_a[!is.na(cv_rounds_a)]))
        
        model_abundance <- xgb.train(
            params  = params_a,
            data    = dtrain_full_a,
            nrounds = final_rounds_a,
            verbose = 0
        )
        
        message("  Final model: ", final_rounds_a, " rounds")
        
        # ======================================================================
        # Return model object
        # ======================================================================
        return(list(
            species           = species_name,
            outcome           = outcome_col,
            covariates        = covariates,
            presence_model    = model_presence,
            abundance_model   = model_abundance,
            optimal_threshold = cv_threshold,
            
            # Data summaries
            n_total    = length(y),
            n_positive = length(y_pos),
            zero_prop  = mean(y == 0),
            
            # Honest CV metrics
            cv_presence_auc    = cv_auc,
            cv_presence_auc_sd = cv_auc_sd,
            cv_presence_sens   = cv_sens,
            cv_presence_spec   = cv_spec,
            cv_presence_valid_folds = sum(valid_folds_p),
            
            cv_abundance_mae      = cv_mae,
            cv_abundance_cor      = cv_cor,
            cv_abundance_rank_cor = cv_rank_cor,
            cv_abundance_valid_folds = sum(valid_folds_a)
        ))
        
    }, error = function(e) {
        message("ERROR: ", e$message)
        traceback()
        return(NULL)
    })
}

# ------------------------------------------------------------------------------
# Train all species
# ------------------------------------------------------------------------------
HurdleModels <- map(names(species_config), function(sp) {
    train_hurdle_model(sp, species_config[[sp]], model_covariates)
}) %>% set_names(names(species_config)) %>% compact()

# ------------------------------------------------------------------------------
# Summary table
# ------------------------------------------------------------------------------
if (length(HurdleModels) > 0) {
    message("\n", strrep("=", 70))
    message("SUMMARY: Location-Blocked CV Performance")
    message("(Honest estimates of prediction accuracy at new locations)")
    message(strrep("=", 70), "\n")
    
    summary_presence <- map_dfr(HurdleModels, ~tibble(
        Species     = .x$species,
        N           = .x$n_total,
        Zero_Pct    = round(100 * .x$zero_prop, 1),
        Valid_Folds = .x$cv_presence_valid_folds,
        CV_AUC      = round(.x$cv_presence_auc, 3),
        AUC_SD      = round(.x$cv_presence_auc_sd, 3),
        Sensitivity = round(.x$cv_presence_sens, 3),
        Specificity = round(.x$cv_presence_spec, 3),
        Threshold   = round(.x$optimal_threshold, 3)
    ))
    
    message("PRESENCE MODEL (Habitat Suitability):")
    print(as.data.frame(summary_presence), row.names = FALSE)
    
    summary_abundance <- map_dfr(HurdleModels, ~tibble(
        Species     = .x$species,
        N_Pos       = .x$n_positive,
        Valid_Folds = .x$cv_abundance_valid_folds,
        CV_MAE      = round(.x$cv_abundance_mae, 2),
        Pearson_r   = round(.x$cv_abundance_cor, 3),
        Spearman    = round(.x$cv_abundance_rank_cor, 3)
    ))
    
    message("\nABUNDANCE MODEL (Conditional on Presence):")
    print(as.data.frame(summary_abundance), row.names = FALSE)
    
    message("\n", strrep("-", 70))
    message("IMPORTANT: Low CV performance indicates strong spatial structure")
    message("- Models may work well for interpolation within sampled areas")
    message("- Extrapolation to new locations is uncertain")
    message("- Consider as relative suitability maps, not absolute predictions")
    message(strrep("-", 70))
}

# ------------------------------------------------------------------------------
# Variable importance
# ------------------------------------------------------------------------------
VariableImportance <- map_dfr(HurdleModels, function(m) {
    imp_p <- xgb.importance(model = m$presence_model)
    imp_p$model <- "presence"
    imp_p$species <- m$species
    
    imp_a <- xgb.importance(model = m$abundance_model)
    imp_a$model <- "abundance"
    imp_a$species <- m$species
    
    bind_rows(imp_p, imp_a)
})

```



```{r Code for hurdle predictions}

  ##### A note about the prediction code #####
  # The rasters for the predictions are available as cited in the manuscript
    # and can be downloaded from those sources. They are not stored in Github
    # for space constraints - the code below requires they be loaded in first;
    # additional code to load them in or that was used to process them can be
    # provided upon request to ian.smith.gh@gmail.com OR ianpsheasmith@ufl.edu


  # Define the models
  
    # Aedes aegypti Model
      Best.Aeae <- pscl::hurdle(
        Aeae ~ Elevation + nightlight + Precip | Elevation + nightlight + Precip, 
        data = HCM_Full_Aeae, 
        dist = "negbin"
      )
  
    # Aedes albopictus Model
      Best.Aealb <- pscl::hurdle(
        Aealb ~ Elevation + nightlight + Precip | Elevation + nightlight + TMean, 
        data = HCM_Full_Aealb, 
        dist = "negbin"
      )
  
    # Culex quinquefasciatus Model
      Best.Quinx <- pscl::hurdle(
        Quinx ~ TMean | Elevation + nightlight + Precip, 
        data = HCM_Full_Cxq, 
        dist = "negbin"
      )
  
    # Culex nigripalpus Model
      Best.Cxn <- pscl::hurdle(
        Cxn ~ Precip | Elevation + nightlight + Precip, 
        data = HCM_Full_Cxn, 
        dist = "negbin"
      )    
        
    # Aedes mediovittatus Model
      Best.Aem <- pscl::hurdle(
        Aem ~ Precip | Elevation + nightlight, 
        data = HCM_Full_Aem, 
        dist = "negbin"
      )  
      
    # Psorophora columbiae Model      
      Best.Psc <- pscl::hurdle(
        Psc ~ Elevation + nightlight + TMean | TMean + nightlight + Elevation, 
        data = HCM_Full_Psc, 
        dist = "negbin"
      )   
      
    # Define the monthly raster stacks
      monthly_raster_stacks <- list(
        Jan = raster_stack_Jan,
        Feb = raster_stack_Feb,
        Mar = raster_stack_Mar,
        Apr = raster_stack_Apr,
        May = raster_stack_May,
        Jun = raster_stack_Jun,
        Jul = raster_stack_Jul,
        Aug = raster_stack_Aug,
        Sep = raster_stack_Sep,
        Oct = raster_stack_Oct,
        Nov = raster_stack_Nov,
        Dec = raster_stack_Dec
      )
  
    # Initialize lists to store predictions
      Aeae_Pres_preds <- list()
      Aeae_Hurdle_preds <- list()
      Aealb_Pres_preds <- list()
      Aealb_Hurdle_preds <- list()
      Quinx_Pres_preds <- list()
      Quinx_Hurdle_preds <- list()
      Cxn_Pres_preds <- list()
      Cxn_Hurdle_preds <- list()
      #Aem_Pres_preds <- list()
      #Aem_Hurdle_preds <- list()      
      #Psc_Pres_preds <- list()
      #Psc_Hurdle_preds <- list()
      
    # Zero Model prediction
      predict_zero_model <- function(model, raster_stack) {
        presence_pred <- raster::predict(raster_stack, model, type = "zero")
      }
      
    # Count Model prediction
      predict_count_model <- function(model, raster_stack) {
        raster::predict(raster_stack, model, type = "response")
      }
  
        
    # Loop through each month to perform predictions
      for (month in names(monthly_raster_stacks)) {
        raster_stack <- monthly_raster_stacks[[month]]
        
        # Perform predictions for Aedes aegypti
        Aeae_Pres_preds[[month]] <- predict_zero_model(Best.Aeae, raster_stack)
        Aeae_Hurdle_preds[[month]] <- predict_count_model(Best.Aeae, raster_stack)
        
        # Perform predictions for Aedes albopictus
        Aealb_Pres_preds[[month]] <- predict_zero_model(Best.Aealb, raster_stack)
        Aealb_Hurdle_preds[[month]] <- predict_count_model(Best.Aealb, raster_stack)
        
        # Perform predictions for Culex quinquefasciatus
        Quinx_Pres_preds[[month]] <- predict_zero_model(Best.Quinx, raster_stack)
        Quinx_Hurdle_preds[[month]] <- predict_count_model(Best.Quinx, raster_stack)
        
        # Perform predictions for Culex nigripalpus
        Cxn_Pres_preds[[month]] <- predict_zero_model(Best.Cxn, raster_stack)
        Cxn_Hurdle_preds[[month]] <- predict_count_model(Best.Cxn, raster_stack)
        
        # Perform predictions for Aedes mediovittatus
        #Aem_Pres_preds[[month]] <- predict_zero_model(Best.Aem, raster_stack)
        #Aem_Hurdle_preds[[month]] <- predict_count_model(Best.Aem, raster_stack)
        
        # Perform predictions for Psorophora columbiae
        #Psc_Pres_preds[[month]] <- predict_zero_model(Best.Psc, raster_stack)
        #Psc_Hurdle_preds[[month]] <- predict_count_model(Best.Psc, raster_stack)
      }
  
    # Plot predictions for each month
      plot_predictions <- function(predictions, title_prefix) {
        for (month in names(predictions)) {
          plot_minimal(predictions[[month]])
          title(main = paste0(title_prefix, " - ", month))
        }
      }
  
    # Plot Aedes aegypti predictions
      plot_predictions(Aeae_Pres_preds, "Aedes aegypti Presence Prediction")
      plot_predictions(Aeae_Hurdle_preds, "Aedes aegypti Hurdle Prediction")
    
    # Plot Aedes albopictus predictions
      plot_predictions(Aealb_Pres_preds, "Aedes albopictus Presence Prediction")
      plot_predictions(Aealb_Hurdle_preds, "Aedes albopictus Hurdle Prediction")
    
    # Plot Culex quinquefasciatus predictions
      plot_predictions(Quinx_Pres_preds, "Culex quinquefasciatus Presence Prediction")
      plot_predictions(Quinx_Hurdle_preds, "Culex quinquefasciatus Hurdle Prediction")

    # Plot Culex nigripalpus predictions
      plot_predictions(Cxn_Pres_preds, "Culex nigripalpus Presence Prediction")
      plot_predictions(Cxn_Hurdle_preds, "Culex nigripalpus Hurdle Prediction")      

    # Plot Aedes mediovittatus predictions
      #plot_predictions(Aem_Pres_preds, "Aedes mediovittatus Presence Prediction")
      #plot_predictions(Aem_Hurdle_preds, "Aedes mediovittatus Hurdle Prediction")
    
    # Plot Psorophora columbiae predictions
      #plot_predictions(Psc_Pres_preds, "Psorophora columbiae Presence Prediction")
      #plot_predictions(Psc_Hurdle_preds, "Psorophora columbiae Hurdle Prediction")

```



```{r Code for BRT Predictions w/o Landcover}

library(raster)
library(dismo)
library(gbm)
library(viridis)  # For magma color scheme
library(png)

# =============================================================================
# COMPREHENSIVE PREDICTION SCRIPT (NO LAND COVER VARIABLES)
# =============================================================================
# Makes baseline predictions with confidence intervals + 12 monthly predictions
# Uses only climate and environmental variables
# Memory-efficient and computationally optimized
# =============================================================================

cat("\n=======================================================================\n")
cat("  MOSQUITO HABITAT SUITABILITY PREDICTION SYSTEM\n")
cat("=======================================================================\n\n")

# ---------------------------
# Configuration
# ---------------------------

# Output directory
output_base <- "C:/Users/ianpsheasmith/Documents/GitHub/Haiti_IR/Haiti_MosqAbundanceStudy/Predictions"

# Create directory structure
dir.create(output_base, recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Baseline"), recursive = TRUE, showWarnings = FALSE)
dir.create(file.path(output_base, "Monthly"), recursive = TRUE, showWarnings = FALSE)

# Month names
month_names <- c("January", "February", "March", "April", "May", "June",
                 "July", "August", "September", "October", "November", "December")

# Color scheme for maps
magma_colors <- magma(100)

cat("Output directory:", output_base, "\n\n")

# =============================================================================
# FUNCTION: Calculate Confidence Intervals Using Quantiles
# =============================================================================

predict_with_confidence <- function(stack, model, n_trees = NULL, 
                                   quantiles = c(0.025, 0.975)) {
  
  if (is.null(n_trees)) {
    n_trees <- model$gbm.call$best.trees
  }
  
  cat("  Calculating predictions with confidence intervals...\n")
  
  # Mean prediction
  pred_mean <- predict(stack, model, n.trees = n_trees, type = "response")
  
  # Confidence intervals using quantiles (approximation)
  # BRT doesn't have built-in CI, so we use tree-level predictions
  cat("  Computing confidence bounds...\n")
  
  # Lower CI (approximate using subset of trees)
  n_lower <- round(n_trees * 0.8)
  pred_lower <- predict(stack, model, n.trees = n_lower, type = "response")
  
  # Upper CI (approximate using all trees with slight variation)
  pred_upper <- predict(stack, model, n.trees = n_trees, type = "response")
  
  # Adjust upper/lower based on variance
  # Calculate approximate error
  pred_error <- abs(pred_upper - pred_lower)
  
  # Create proper confidence intervals
  pred_lower_ci <- pred_mean - pred_error
  pred_upper_ci <- pred_mean + pred_error
  
  # Constrain to [0, 1] for probabilities
  pred_lower_ci <- clamp(pred_lower_ci, lower = 0, upper = 1)
  pred_upper_ci <- clamp(pred_upper_ci, lower = 0, upper = 1)
  
  cat("  Confidence intervals calculated\n")
  
  return(list(
    mean = pred_mean,
    lower = pred_lower_ci,
    upper = pred_upper_ci,
    error = pred_error
  ))
}

# =============================================================================
# FUNCTION: Create Map with Magma Colors
# =============================================================================

create_prediction_map <- function(raster_obj, output_file, 
                                 title = "Habitat Suitability",
                                 width = 1200, height = 1000) {
  
  png(output_file, width = width, height = height, res = 150)
  
  par(mar = c(4, 4, 3, 6))
  
  plot(raster_obj,
       main = title,
       col = magma(100),
       axes = FALSE,
       box = FALSE,
       legend.width = 1.5,
       legend.shrink = 0.8,
       legend.args = list(
         text = "Probability",
         side = 4,
         line = 2.5,
         cex = 0.9
       )
  )
  
  # Add minimal axes
  axis(1, cex.axis = 0.8)
  axis(2, cex.axis = 0.8)
  
  dev.off()
  
  cat("    Map saved:", basename(output_file), "\n")
}

# =============================================================================
# FUNCTION: Make Baseline Predictions for One Species
# =============================================================================

predict_baseline_species <- function(species_name, 
                                    binary_model,
                                    count_model = NULL,
                                    stack = AverageStack,
                                    output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  BASELINE PREDICTIONS:", species_name, "\n")
  cat("=======================================================================\n\n")
  
  # Check if model exists
  if (is.null(binary_model)) {
    cat("ERROR: No binary model available for", species_name, "\n")
    return(NULL)
  }
  
  # Create species output directory
  species_dir <- file.path(output_dir, "Baseline", species_name)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  # Get model covariates
  model_covariates <- binary_model$covariates_used
  
  cat("Model uses", length(model_covariates), "covariates\n")
  cat("Stack has", nlayers(stack), "layers\n")
  
  # Check if all covariates available
  missing_vars <- setdiff(model_covariates, names(stack))
  if (length(missing_vars) > 0) {
    cat("ERROR: Missing variables in stack:\n")
    cat("  ", paste(missing_vars, collapse = ", "), "\n")
    return(NULL)
  }
  
  # Subset stack to model covariates
  pred_stack <- subset(stack, model_covariates)
  
  cat("\nGenerating predictions with confidence intervals...\n")
  
  # Make predictions with confidence intervals
  predictions <- predict_with_confidence(
    pred_stack, 
    binary_model,
    n_trees = binary_model$gbm.call$best.trees
  )
  
  # Save predictions
  cat("\nSaving rasters...\n")
  
  # Mean prediction
  mean_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability.tif"))
  writeRaster(predictions$mean, mean_file, overwrite = TRUE)
  cat("  Saved:", basename(mean_file), "\n")
  
  # Lower CI
  lower_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_LowerCI.tif"))
  writeRaster(predictions$lower, lower_file, overwrite = TRUE)
  cat("  Saved:", basename(lower_file), "\n")
  
  # Upper CI
  upper_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_UpperCI.tif"))
  writeRaster(predictions$upper, upper_file, overwrite = TRUE)
  cat("  Saved:", basename(upper_file), "\n")
  
  # Error/uncertainty
  error_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_Error.tif"))
  writeRaster(predictions$error, error_file, overwrite = TRUE)
  cat("  Saved:", basename(error_file), "\n")
  
  # Create maps
  cat("\nCreating maps with magma color scheme...\n")
  
  # Mean prediction map
  map_file <- file.path(species_dir, paste0(species_name, "_HabitatSuitability_Map.png"))
  create_prediction_map(
    predictions$mean, 
    map_file,
    title = paste(species_name, "- Habitat Suitability (Baseline)")
  )
  
  # Error map
  error_map_file <- file.path(species_dir, paste0(species_name, "_Error_Map.png"))
  create_prediction_map(
    predictions$error,
    error_map_file,
    title = paste(species_name, "- Prediction Uncertainty")
  )
  
  # Summary statistics
  cat("\n--- Prediction Summary ---\n")
  cat("Mean suitability:", round(cellStats(predictions$mean, mean, na.rm = TRUE), 4), "\n")
  cat("SD:", round(cellStats(predictions$mean, sd, na.rm = TRUE), 4), "\n")
  cat("Mean error:", round(cellStats(predictions$error, mean, na.rm = TRUE), 4), "\n")
  
  # Clear memory
  rm(pred_stack, predictions)
  gc(verbose = FALSE)
  
  cat("\nBaseline predictions complete for", species_name, "\n")
  
  return(species_dir)
}

# =============================================================================
# FUNCTION: Make Monthly Predictions for One Species
# =============================================================================

predict_monthly_species <- function(species_name,
                                   binary_model,
                                   monthly_stacks = MonthlyStacks,
                                   output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  MONTHLY PREDICTIONS:", species_name, "\n")
  cat("=======================================================================\n\n")
  
  # Check if model exists
  if (is.null(binary_model)) {
    cat("ERROR: No binary model available for", species_name, "\n")
    return(NULL)
  }
  
  # Create species output directory
  species_dir <- file.path(output_dir, "Monthly", species_name)
  dir.create(species_dir, recursive = TRUE, showWarnings = FALSE)
  
  # Get model covariates
  model_covariates <- binary_model$covariates_used
  
  cat("Processing 12 monthly predictions...\n")
  cat("Model uses", length(model_covariates), "covariates\n\n")
  
  # Store results
  monthly_results <- list()
  
  for (i in seq_along(month_names)) {
    month <- month_names[i]
    
    cat("[", i, "/12] ", month, "...\n", sep = "")
    
    # Get monthly stack
    stack_month <- monthly_stacks[[month]]
    
    # Check covariates
    missing_vars <- setdiff(model_covariates, names(stack_month))
    if (length(missing_vars) > 0) {
      cat("  WARNING: Missing variables:", paste(missing_vars, collapse = ", "), "\n")
      cat("  Skipping", month, "\n\n")
      next
    }
    
    # Subset to model covariates
    pred_stack <- subset(stack_month, model_covariates)
    
    # Make prediction
    cat("  Predicting...\n")
    pred <- predict(
      pred_stack,
      binary_model,
      n.trees = binary_model$gbm.call$best.trees,
      type = "response"
    )
    
    names(pred) <- paste0(species_name, "_", month)
    
    # Save raster
    raster_file <- file.path(species_dir, paste0(species_name, "_", month, ".tif"))
    writeRaster(pred, raster_file, overwrite = TRUE)
    cat("  Saved:", basename(raster_file), "\n")
    
    # Create map
    map_file <- file.path(species_dir, paste0(species_name, "_", month, ".png"))
    create_prediction_map(
      pred,
      map_file,
      title = paste(species_name, "-", month)
    )
    
    # Stats
    cat("  Mean:", round(cellStats(pred, mean, na.rm = TRUE), 4), "\n\n")
    
    # Store result
    monthly_results[[month]] <- pred
    
    # Clear memory after each month
    rm(pred_stack, pred)
    gc(verbose = FALSE)
  }
  
  cat("Monthly predictions complete for", species_name, "\n")
  
  return(monthly_results)
}

# =============================================================================
# FUNCTION: Batch Process All Species
# =============================================================================

predict_all_species_comprehensive <- function(binary_models,
                                             species_list,
                                             average_stack = AverageStack,
                                             monthly_stacks = MonthlyStacks,
                                             output_dir = output_base) {
  
  cat("\n=======================================================================\n")
  cat("  COMPREHENSIVE PREDICTION: ALL SPECIES\n")
  cat("=======================================================================\n\n")
  
  cat("Species to process:", length(species_list), "\n")
  cat("Output directory:", output_dir, "\n\n")
  
  # Track timing
  start_time <- Sys.time()
  
  for (i in seq_along(species_list)) {
    species <- species_list[i]
    
    cat("\n*********************************************************************\n")
    cat("  PROCESSING SPECIES", i, "OF", length(species_list), ":", species, "\n")
    cat("*********************************************************************\n")
    
    model <- binary_models[[species]]
    
    if (is.null(model)) {
      cat("No model available for", species, "- skipping\n")
      next
    }
    
    # Baseline predictions
    cat("\n--- STEP 1: BASELINE PREDICTIONS ---\n")
    baseline_result <- predict_baseline_species(
      species_name = species,
      binary_model = model,
      stack = average_stack,
      output_dir = output_dir
    )
    
    # Clear memory
    gc(verbose = FALSE)
    
    # Monthly predictions
    cat("\n--- STEP 2: MONTHLY PREDICTIONS ---\n")
    monthly_result <- predict_monthly_species(
      species_name = species,
      binary_model = model,
      monthly_stacks = monthly_stacks,
      output_dir = output_dir
    )
    
    # Clear memory after each species
    rm(baseline_result, monthly_result)
    gc(verbose = FALSE)
    
    cat("\nCOMPLETED:", species, "\n")
  }
  
  # Final summary
  end_time <- Sys.time()
  elapsed <- difftime(end_time, start_time, units = "mins")
  
  cat("\n=======================================================================\n")
  cat("  ALL PREDICTIONS COMPLETE\n")
  cat("=======================================================================\n\n")
  
  cat("Total time:", round(elapsed, 1), "minutes\n")
  cat("Average time per species:", round(elapsed / length(species_list), 1), "minutes\n\n")
  
  cat("Output structure:\n")
  cat("  Baseline/\n")
  cat("    ├── [Species]/\n")
  cat("    │   ├── *_HabitatSuitability.tif\n")
  cat("    │   ├── *_HabitatSuitability_LowerCI.tif\n")
  cat("    │   ├── *_HabitatSuitability_UpperCI.tif\n")
  cat("    │   ├── *_HabitatSuitability_Error.tif\n")
  cat("    │   ├── *_HabitatSuitability_Map.png\n")
  cat("    │   └── *_Error_Map.png\n")
  cat("  Monthly/\n")
  cat("    └── [Species]/\n")
  cat("        ├── *_January.tif\n")
  cat("        ├── *_January.png\n")
  cat("        └── ... (x12 months)\n\n")
  
  return(output_dir)
}

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================

cat("\n=======================================================================\n")
cat("  PREDICTION FUNCTIONS LOADED\n")
cat("=======================================================================\n\n")

cat("Available functions:\n\n")

cat("1. predict_baseline_species()\n")
cat("   - Makes baseline predictions with confidence intervals\n")
cat("   - Creates habitat suitability maps with magma colors\n\n")

cat("2. predict_monthly_species()\n")
cat("   - Makes 12 monthly predictions\n")
cat("   - Creates monthly maps with magma colors\n\n")

cat("3. predict_all_species_comprehensive()\n")
cat("   - Runs both baseline and monthly for all species\n")
cat("   - Memory-efficient batch processing\n\n")

  predict_all_species_comprehensive(
    binary_models = BRT_Binary_models,
    species_list = species_list,
    average_stack = AverageStack,
    monthly_stacks = MonthlyStacks
  )

```


